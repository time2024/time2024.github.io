[{"title":"AutoDL介绍","url":"/2025/08/07/AutoDL/","content":"前言：由于本地轻薄本算力不够，跑一些复杂的对显存要求高的模型比较困难，因此需要租服务器提高速度，根据推荐就选用 AutoDL ，本教程是一边学一边做一边写的，作为记录，希望在未来忘记如何进行操作时能根据自己的教程很快回忆起流程。\n\n\n一、注册与认证首先进入AutoDL官网，完成个人注册，如果是学生的话可以进行学生认证，认证后可享 GPU 折扣价。\n二、创建实例（租用服务器）\n进入算力市场\n\n登录后点击顶部 算力市场 → 选择 按量计费（适合短期使用）。\n\n\n选择配置\n\nGPU 型号：根据需求选择（如 RTX 5090 适合中小模型，A100 适合大模型）。\n\nGPU 数量：初学者选 1 卡即可（多卡需代码适配）。\n\n硬盘：\n\n系统盘：默认 30GB（存放系统镜像，不可扩容）。\n数据盘：默认 50GB 按需扩容（存放代码&#x2F;数据）。\n\n\n镜像：选择预装环境（如 PyTorch 2.0.1 + Python 3.10(ubuntu22.04)）。\n\n\n\n创建实例\n\n点击 立即创建 → 等待 1~3 分钟初始化完成。\n提示：创建后先关机（避免空跑计费），传文件时再开无卡模式（控制台右侧按钮）。\n\n\n\n三、文件传输（建议使用 WinScp 或者 Xftp 或者 FileZilla ，此处以 FileZilla 为例）\n获取连接信息\n在实例控制台查看 SSH 登录指令（含 IP、端口、用户名）。\n示例：ssh -p 37176 root@region-42.autodl.com\n\n\n配置 FileZilla\n打开 FileZilla → 顶部输入框依次填写：\n主机：region-42.autodl.com（替换为你的 IP）\n用户名：root\n密码：控制台显示的密码\n端口：37176（替换为你的端口）\n\n\n点击 快速连接 → 左侧为本地文件，右侧为服务器文件。\n\n\n传输文件\n上传：本地文件拖拽至右侧 /root/autodl-tmp（数据盘路径）。\n下载：服务器文件拖拽至左侧本地目录。\n\n\n\n四、运行代码的两种方式方式 1：通过 JupyterLab（推荐新手）( AutoDL 平台提供的 JupyterLab 是一个基于 Web 的交互式开发环境，专为深度学习和科学计算设计，主要服务于用户在该平台上进行模型开发、数据分析和实验管理)\n\n实例控制台点击 JupyterLab → 输入密码（默认为创建时设置的密码）。\n\n左侧文件栏进入 /root/autodl-tmp → 上传代码&#x2F;数据（支持拖拽）。\n\n新建终端（Terminal）→ 执行命令：\ncd /root/autodl-tmp  # 进入代码目录  python train.py      # 运行你的程序  \n\n\n优点：无需配置，网页直接操作。\n注意：关闭浏览器不会停止程序（需在终端用 Ctrl+C 结束）。\n\n\n\n方式 2：通过 PyCharm 远程连接（适合本地开发）\n配置远程解释器\nPyCharm 打开项目 → File &gt; Settings &gt; Python Interpreter → 点击 Add Interpreter → SSH Interpreter。\n填写服务器信息：\nHost：region-42.autodl.com\nPort：37176\nUsername：root\nPassword：控制台密码\n\n\n选择远程 Python 路径：/root/miniconda3/bin/python（镜像默认路径）。\n\n\n映射项目路径\n在 Path Mappings 中设置：\n本地项目路径 → 服务器路径（如 /root/autodl-tmp/project）。\n\n\n\n\n运行代码\n然后在PyCharm中使用终端连接到服务器的终端，同样可以进行终端的操作。\n右键代码文件 → Run → 程序将在服务器执行，结果输出到 PyCharm 控制台。\n\n\n\n五、附实际上以上只是运行简单项目的步骤，还需要配置各种各样的环境，这些才是真正令人头大的地方……\n","categories":["学习"],"tags":["介绍"]},{"title":"2024-2025年度总结","url":"/2025/01/01/2024-2025/","content":"时间过得真快，2024也过去了\n浅浅总结一下2024吧\nTo be continue !\n\n\n\n“历史不是文学家笔下的修辞，而是无数重复又动人的真实故事：虽说前途未卜，但总怀着懵懂的希望。”\n过去的一年是难以忘怀的一年，似乎总在相遇，也总在告别。\n和朋友们同游了重庆、长沙、南京，一同参加了大大小小难以忘怀的比赛，遇到了很多非常好的老师，以及很优秀的学长和同学，拿到了国家奖学金和一些小奖，搭建了自己的网站，给学弟学妹们完整上了节课，以及，迈出了许多第一步，虽然不是都能走下去，但是至少，是鼓足勇气迈出了第一步。\n相遇的同时也伴随着告别，每一段旅程都有它的起点与终点，每一种选择都意味着放弃其他可能，每一次出发都是一次离别。以为来日方长，人心不变，却终是败给了时间。十年之约也许是太长了些。\n正是预见了未来的告别，更珍惜现在的相遇。怀着懵懂的希望，试图望穿雾霭，那些未走完的路，未实现的梦，未重逢的人，像远山的轮廓，不知能否遇见，却依然在心底留着一盏灯，为未竟的故事照亮归途。愿我们在新的旅程中，即使前途未卜，也依然怀着懵懂的希望，勇敢地迈出每一步。\n新年的阳光会如约而至，祝：新年快乐！\n","categories":["记录生活"],"tags":["杂谈"]},{"title":"Debian 常用命令","url":"/2025/01/19/Debian%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"以下是 Debian 系统（包括 Raspberry Pi OS 等基于 Debian 的发行版）中一些常用命令的总结，涵盖了文件操作、系统管理、网络配置等方面：\n文件与目录操作\n列出目录内容：\nlsls -l  # 详细列表ls -a  # 显示隐藏文件\n\n切换目录：\ncd &lt;目录路径&gt;cd ..  # 返回上一级目录cd ~   # 返回用户主目录\n\n创建目录：\nmkdir &lt;目录名&gt;mkdir -p &lt;路径/目录名&gt;  # 递归创建目录\n\n删除文件或目录：\nrm &lt;文件名&gt;  # 删除文件rm -r &lt;目录名&gt;  # 递归删除目录rm -f &lt;文件名&gt;  # 强制删除\n\n复制文件或目录：\ncp &lt;源文件&gt; &lt;目标文件&gt;cp -r &lt;源目录&gt; &lt;目标目录&gt;  # 递归复制目录\n\n移动或重命名文件：\nmv &lt;源文件&gt; &lt;目标文件&gt;\n\n查看文件内容：\ncat &lt;文件名&gt;less &lt;文件名&gt;  # 分页查看head &lt;文件名&gt;  # 查看文件开头tail &lt;文件名&gt;  # 查看文件末尾tail -f &lt;文件名&gt;  # 实时查看文件更新\n\n查找文件：\nfind &lt;目录&gt; -name &lt;文件名&gt;\n\n压缩与解压：\ntar -czvf &lt;压缩文件名.tar.gz&gt; &lt;目录&gt;  # 压缩tar -xzvf &lt;压缩文件名.tar.gz&gt;  # 解压\n\n系统信息与管理\n查看系统信息：\nuname -a  # 查看内核信息cat /etc/os-release  # 查看系统版本\n\n查看磁盘空间：\ndf -h  # 查看磁盘使用情况du -sh &lt;目录&gt;  # 查看目录大小\n\n查看内存与 CPU 使用：\nfree -h  # 查看内存使用top  # 实时查看系统资源占用\n\n查看进程：\nps aux  # 查看所有进程ps aux | grep &lt;进程名&gt;  # 查找特定进程\n\n杀死进程：\nkill &lt;进程ID&gt;kill -9 &lt;进程ID&gt;  # 强制杀死进程\n\n关机与重启：\nsudo shutdown now  # 立即关机sudo reboot  # 重启\n\n查看系统日志：\njournalctl  # 查看系统日志journalctl -f  # 实时查看日志\n\n包管理​\t使用 APT（Advanced Package Tool）作为包管理工具\n\n更新包列表：\nsudo apt update\n\n安装软件包：\nsudo apt install &lt;软件包名&gt;\n\n卸载软件包：\nsudo apt remove &lt;软件包名&gt;sudo apt purge &lt;软件包名&gt;  # 同时删除配置文件\n\n升级已安装的软件包：\nsudo apt upgrade\n\n搜索软件包：\napt search &lt;关键字&gt;\n\n清理缓存：\nsudo apt clean  # 清理所有缓存sudo apt autoremove  # 删除不需要的依赖\n\n用户与权限管理\n切换用户：\nsu &lt;用户名&gt;  # 切换用户sudo -i  # 切换到 root 用户\n\n添加用户：\nsudo adduser &lt;用户名&gt;\n\n删除用户：\nsudo deluser &lt;用户名&gt;\n\n修改文件权限：\nchmod &lt;权限&gt; &lt;文件名&gt;  # 修改权限chmod 755 &lt;文件名&gt;  # 示例：设置可执行权限\n\n修改文件所有者：\nsudo chown &lt;用户&gt;:&lt;组&gt; &lt;文件名&gt;\n\n网络管理\n查看网络接口：\nifconfig  # 查看网络接口信息ip addr  # 查看 IP 地址\n\n测试网络连接：\nping &lt;目标地址&gt;\n\n查看网络状态：\nnetstat -tuln  # 查看端口监听状态ss -tuln  # 更现代的替代工具\n\n下载文件：\nwget &lt;URL&gt;curl -O &lt;URL&gt;\n\n配置网络：\n\n编辑网络配置文件：sudo nano /etc/network/interfaces\n重启网络服务：sudo systemctl restart networking\n\n\n\n服务管理\n启动服务：\nsudo systemctl start &lt;服务名&gt;\n\n停止服务：\nsudo systemctl stop &lt;服务名&gt;\n\n重启服务：\nsudo systemctl restart &lt;服务名&gt;\n\n查看服务状态：\nsudo systemctl status &lt;服务名&gt;\n\n启用开机自启动：\nsudo systemctl enable &lt;服务名&gt;\n\n禁用开机自启动：\nsudo systemctl disable &lt;服务名&gt;\n\n其他常用命令\n查看命令帮助：\nman &lt;命令&gt;  # 查看手册&lt;命令&gt; --help  # 查看简要帮助\n\n查看环境变量：\necho $PATH\n\n设置别名：\nalias ll=&#x27;ls -l&#x27;  # 设置别名unalias ll  # 取消别名\n\n定时任务：\n\n编辑定时任务：crontab -e\n查看定时任务：crontab -l\n\n\n\n","categories":["学习"],"tags":["Linux","Debian","知识总结"]},{"title":"OurEDA例会-C语言知识点总结","url":"/2024/11/17/C/","content":"这是我主持的OurEDA例会的内容整理\n\n\n点击 下载 本次沙龙 PPT\n推荐 STL进阶教程\n变量常用变量表（看看就好有个印象就行）\n\n\n类型\n含义\n32位编译器中大小(一般)\n64位编译器中大小(一般)\n最小值(32位)\n最大值(32位)\n\n\n\nbool\n布尔类型\n1byte\n1byte\nfalse\ntrue\n\n\nchar\n单个字符\n1byte\n1byte\n-2^7^\n2^7^-1\n\n\nshort\n短整形\n2byte\n2byte\n-2^15^\n2^15^-1\n\n\nint\n整形\n4byte\n4byte\n-2^31^\n2^31^-1\n\n\nlong\n长整形\n4byte4byte\n8byte\n-2^31^\n2^31^-1\n\n\nlong long\n长整形\n8byte\n8byte\n-2^63^\n2^63^-1\n\n\nfloat\n单精度浮点数\n4byte\n4byte\n-2^127^\n2^128^\n\n\ndouble\n双精度浮点数\n8byte\n8byte\n-2^1023^\n2^1024^\n\n\nlong double\n扩展精度浮点数\n12byte\n16byte\n-2^16383^\n2^16384^\n\n\nchar*\n字符常量或字符串常量\n4byte\n8byte\n无意义\n无意义\n\n\n\n\n\n类型\n有效位数计算\n有效位数\n\n\n\nfloat\n223+1&#x3D;16,777,216\n8-1&#x3D;7\n\n\ndouble\n252+1&#x3D;9,007,199,254,740,992‬\n16-1&#x3D;15\n\n\nlong double\n280+1&#x3D;2.410 24 &#x2F; 2112+1&#x3D;1.0381034\n25-1&#x3D;24 &#x2F; 35-1&#x3D;34\n\n\n一些注意事项\n\n数字默认是 double\n字符串默认是const char*\n\n特殊前缀extern int a;  // 声明一个int类型的变量a，一般用在.h文件中声明项目全局变量const int b=1;  // 定义一个不可变的变量b，使用const关键字都要赋初值static int c=1;  // 在函数中使用，只在第一次使用时初始化，相当于作用域在函数内的全局变量typedef long long int;  // 把long long当作int使用\n\n变量作用域\n局部变量\n\n全局变量\n\n\n字符串字符串在c语言中有两种形式char*和char[]，这里简单分辨下两者之间的不同。\n“HelloWorld!”是字符串常量，不可修改。\n\nchar* c1&#x3D;”HelloWorld!”中，c1指向代码段中的常量，只读不写，且常量相同，指向的地址也相同。\nchar c2[]&#x3D;”HelloWorld!”中，c2指向堆栈段中的数据，可读可写，相当于把代码端的数据拷贝了出来。\n\n结构体结构体可以看作是一种几个基础类型复合的类型。\n语句条件语句\nif - else - if else\nif依据后面的条件语句的结果进行判断，非0为真，0为假\nif会优先和近的else组合\nif()    //...else if()    //...else    //...\n\n\n\nif()    //...if()    //...else    //...\n\n\n\nswitch - case - default\n注意：每种情况下都要有break，否则将会持续执行。\nswitch(ch)&#123;  \tcase &#x27;a&#x27;:\t\t//...\t\tbreak;\tcase &#x27;b&#x27;:\t\t//...\t\tbreak;\tdefault:\t\t//...&#125;\n\n循环语句\nwhile\n先判断，再执行\nwhile 依据后面语句的结果进行判断，非0为真，0为假\n\ndo while（见得较少）\n不判断，先执行一次\n\nfor\n先判断，再执行\n适用于控制执行的次数\n\n\n跳转语句\nbreak\n跳出当前语句（{}）\n\ncontinue\n在 条件语句 中表示什么都不做（替代空语句）；\n在 迭代语句 中表示 直接进入下一轮循环，不执行完当前循环 。\n\ngoto（非常非常不建议，不过学的时候可以试着玩一下）\ngoto任意位置\nfor (int i=0; i&lt;n; i++) &#123;\tfor (int j=0; j&lt;m; j++) &#123;\t\tfor (int k=0; k&lt;o; k++) &#123;\t\t\tif (跳出条件) &#123;\t\t\t\tgoto end;\t\t\t&#125;\t\t&#125;\t&#125;&#125;end://...\n\n函数\n函数结果\n返回类型 函数名（形式传入参数）\n{\n​    函数体;\n​    return ()；\n}\n\nreturn 在 dfs 等算法中用于回溯\n\n内联函数 inline\n提高程序执行效率（整体代换而不是用函数调用)\ninline char *dbtest(int a)&#123;    return (a % 2 &gt; 0 ? &quot;奇&quot; : &quot;偶&quot;);&#125;\n\n指针\n\n\n\n\n&amp;\n\n常量指针（不能修改指针指向地址中的值）\n\n指针常量（不能修改指针的值）\n\n常量指针常量（既不能修改指针指向地址中的值，又不能修改指针的值）\n\n结构体指针变量（ . &#x2F; -&gt; ）\n\n数组与指针\n数组的变量名就是该数组的首地址\n数组的下标就是地址的位移量\n\n\nscanf 与 printf\nscanf(“输入格式”，变量地址);\nprintf(“输出格式”，变量);\n\n","categories":["学习"],"tags":["知识总结","C语言","OurEDA"]},{"title":"stm32f407驱动BMX055芯片记录","url":"/2024/11/14/BMX055/","content":"前两天BOSS交给我一个BMX055芯片让我试试能不能用\n\n\n真的就一个芯片\n\n长下面这样\n\n刚好学习一下如何使用没有模块化的芯片\n首先是接线问题，在网络上找不到现成的BMX055芯片连线连到stm32的接线图，在询问多个学长后得知有以下几种途径\n\n查技术手册\n在各个平台上搜索有用到这个芯片的模块\n\n技术手册首先可以在半导小芯等多个平台搜索这个芯片找到这个芯片的技术手册，中英文都可以，尽量看英文手册。\n为了方便可以直接在此下载 BMX055 技术手册\n然后找到你需要的接线，比如我需要用iic与之通讯，则找到iic的接线图如下：\n\n同时可以参考引脚定义来辅助接线\n\n在刚接线时别急着一次性就把他用好，而是先把基本的接线连好（可以先不连中断），然后先读chip id，确定基本的硬件连线没有问题，芯片上电之后可以工作，再去连中断线\n是的，我这个芯片连线就连了，拔了，连了，拔了重复了好几次，所以不要放弃，多试试吧\n\n\n接线完成了\n然后就是配置stm32f407的iic了\n网上搜到的大部分都是stm32f1的，所以我稍作修改，并添加了一些我自己写的函数，附在下面供大家取用\n\n&#x2F;&#x2F;myiic.c\n//myiic.c#include &quot;myiic.h&quot;#include &quot;delay.h&quot;//初始化IICvoid IIC_Init(void)&#123;\t\t\t  GPIO_InitTypeDef  GPIO_InitStructure;  RCC_AHB1PeriphClockCmd(RCC_AHB1Periph_GPIOB, ENABLE);//使能GPIOB时钟  //GPIOB8,B9初始化设置  GPIO_InitStructure.GPIO_Pin = GPIO_Pin_8 | GPIO_Pin_9;  GPIO_InitStructure.GPIO_Mode = GPIO_Mode_OUT;//普通输出模式  GPIO_InitStructure.GPIO_OType = GPIO_OType_PP;//推挽输出  GPIO_InitStructure.GPIO_Speed = GPIO_Speed_100MHz;//100MHz  GPIO_InitStructure.GPIO_PuPd = GPIO_PuPd_UP;//上拉  GPIO_Init(GPIOB, &amp;GPIO_InitStructure);//初始化\tIIC_SCL=1;\tIIC_SDA=1;&#125;//产生IIC起始信号void IIC_Start(void)&#123;\tSDA_OUT();     //sda线输出\tIIC_SDA=1;\t  \t  \tIIC_SCL=1;\tdelay_us(4); \tIIC_SDA=0;//START:when CLK is high,DATA change form high to low \tdelay_us(4);\tIIC_SCL=0;//钳住I2C总线，准备发送或接收数据 &#125;\t  //产生IIC停止信号void IIC_Stop(void)&#123;\tSDA_OUT();//sda线输出\tIIC_SCL=0;\tIIC_SDA=0;//STOP:when CLK is high DATA change form low to high \tdelay_us(4);\tIIC_SCL=1; \tIIC_SDA=1;//发送I2C总线结束信号\tdelay_us(4);\t\t\t\t\t\t\t   \t&#125;//等待应答信号到来//返回值：1，接收应答失败//        0，接收应答成功u8 IIC_Wait_Ack(void)&#123;\tu8 ucErrTime=0;\tSDA_IN();      //SDA设置为输入  \tIIC_SDA=1;delay_us(1);\t   \tIIC_SCL=1;delay_us(1);\t \twhile(READ_SDA)\t&#123;\t\tucErrTime++;\t\tif(ucErrTime&gt;250)\t\t&#123;\t\t\tIIC_Stop();\t\t\treturn 1;\t\t&#125;\t&#125;\tIIC_SCL=0;//时钟输出0 \t   \treturn 0;  &#125; //产生ACK应答void IIC_Ack(void)&#123;\tIIC_SCL=0;\tSDA_OUT();\tIIC_SDA=0;\tdelay_us(2);\tIIC_SCL=1;\tdelay_us(2);\tIIC_SCL=0;&#125;//不产生ACK应答\t\t    void IIC_NAck(void)&#123;\tIIC_SCL=0;\tSDA_OUT();\tIIC_SDA=1;\tdelay_us(2);\tIIC_SCL=1;\tdelay_us(2);\tIIC_SCL=0;&#125;\t\t\t\t\t \t\t\t\t     //IIC发送一个字节//返回从机有无应答//1，有应答//0，无应答\t\t\t  void IIC_Send_Byte(u8 txd)&#123;                            u8 t;   \tSDA_OUT(); \t        IIC_SCL=0;//拉低时钟开始数据传输    for(t=0;t&lt;8;t++)    &#123;                      IIC_SDA=(txd&amp;0x80)&gt;&gt;7;        txd&lt;&lt;=1; \t  \t\tdelay_us(2);   //对TEA5767这三个延时都是必须的\t\tIIC_SCL=1;\t\tdelay_us(2); \t\tIIC_SCL=0;\t\t\tdelay_us(2);    &#125;\t &#125; \t    //读1个字节，ack=1时，发送ACK，ack=0，发送nACK   u8 IIC_Read_Byte(unsigned char ack)&#123;\tunsigned char i,receive=0;\tSDA_IN();//SDA设置为输入    for(i=0;i&lt;8;i++ )\t&#123;        IIC_SCL=0;         delay_us(2);\t\tIIC_SCL=1;        receive&lt;&lt;=1;        if(READ_SDA)receive++;   \t\tdelay_us(1);     &#125;\t\t\t\t\t     if (!ack)        IIC_NAck();//发送nACK    else        IIC_Ack(); //发送ACK       return receive;&#125;void WriteData(u8 DevID,u8 Addr,u8 Dat)&#123;\tIIC_Start();\tIIC_Send_Byte(DevID &lt;&lt; 1| 0);\t//发送设备地址和写信号\tIIC_Wait_Ack();\tIIC_Send_Byte(Addr);\tIIC_Wait_Ack();\tIIC_Send_Byte(Dat);\tIIC_Wait_Ack();\tIIC_Stop();\tdelay_ms(10);&#125;void ReadData(u8 DevID,u8 Addr,u8 *Pbuf,u8 Num)&#123;\tu8 i;\tIIC_Start();\tIIC_Send_Byte(DevID &lt;&lt; 1 | 0);\t//发送设备地址和写信号\tIIC_Wait_Ack();\tIIC_Send_Byte(Addr);\tIIC_Wait_Ack();\tIIC_Start();\tIIC_Send_Byte(DevID &lt;&lt; 1 | 1);\t//发送设备地址和读信号\tIIC_Wait_Ack();\tfor(i = 0;i &lt; (Num - 1);i ++)\t&#123;\t\tPbuf[i] = IIC_Read_Byte(1);\t&#125;\tPbuf[i] = IIC_Read_Byte(0);\tIIC_Stop();\tdelay_ms(5);&#125;\n\n\n&#x2F;&#x2F;myiic.h\n//myiic.h#ifndef __MYIIC_H#define __MYIIC_H#include &quot;sys.h&quot;    \t   \t\t   //IO方向设置#define SDA_IN()  &#123;GPIOB-&gt;MODER&amp;=~(3&lt;&lt;(9*2));GPIOB-&gt;MODER|=0&lt;&lt;9*2;&#125;\t//PB9输入模式#define SDA_OUT() &#123;GPIOB-&gt;MODER&amp;=~(3&lt;&lt;(9*2));GPIOB-&gt;MODER|=1&lt;&lt;9*2;&#125; //PB9输出模式//IO操作函数\t #define IIC_SCL    PBout(8) //SCL#define IIC_SDA    PBout(9) //SDA\t #define READ_SDA   PBin(9)  //输入SDA //IIC所有操作函数void IIC_Init(void);                //初始化IIC的IO口\t\t\t\t void IIC_Start(void);\t\t\t\t//发送IIC开始信号void IIC_Stop(void);\t  \t\t\t//发送IIC停止信号void IIC_Send_Byte(u8 txd);\t\t\t//IIC发送一个字节u8 IIC_Read_Byte(unsigned char ack);//IIC读取一个字节u8 IIC_Wait_Ack(void); \t\t\t\t//IIC等待ACK信号void IIC_Ack(void);\t\t\t\t\t//IIC发送ACK信号void IIC_NAck(void);\t\t\t\t//IIC不发送ACK信号void IIC_Write_One_Byte(u8 daddr,u8 addr,u8 data);u8 IIC_Read_One_Byte(u8 daddr,u8 addr);\t  void WriteData(u8 DevID,u8 Addr,u8 Dat);void ReadData(u8 DevID,u8 Addr,u8 *Pbuf,u8 Num);#endif\n\n\n接下来就是参考芯片技术手册，编写初始化函数等，通过iic与之通讯\n&#x2F;&#x2F;BMX055.c\n//BMX055.c#include &quot;usart.h&quot;#include &quot;BMX055.h&quot;#include &quot;myiic.h&quot;void IMU_Init(void)&#123;\tWriteData(Acc_addr,0x0F, 0x03);//reset \t\t复位acc\tWriteData(Acc_addr,0x10, 0x08);//+/- 16g\t设置acc的测量范围\tWriteData(Acc_addr,0x11, 0x00);\tdelay_us(100);\tWriteData(Gyro_addr,0x0F, 0x04);\tWriteData(Gyro_addr,0x10, 0x07);// 500\tWriteData(Gyro_addr,0x11, 0x00);\tdelay_us(100);\tWriteData(Mag_addr,0x4B, 0x83);\tdelay_us(100);\tWriteData(Mag_addr,0x4B, 0x01);\tdelay_us(100);\tWriteData(Mag_addr, 0x4c, 0x00); //00000000\t\t将mag由sleep mode切换到normal mode（active）\tWriteData(Mag_addr, 0x4E, 0x84);\tWriteData(Mag_addr, 0x51, 0x04);\tWriteData(Mag_addr, 0x52, 0x16);\tdelay_us(100);&#125;// 初始化BMX055加速度计void BMX055_Init_Accelerometer() &#123; WriteData(Acc_addr, 0x0F, 0x03); // 设置范围为±2g WriteData(Acc_addr, 0x10, 0x08); // 设置带宽为7.81 Hz WriteData(Acc_addr, 0x11, 0x00); // 正常模式，睡眠时长0.5ms delay_us(100000); // 延迟等待配置生效&#125;// 初始化BMX055陀螺仪void BMX055_Init_Gyroscope() &#123; WriteData(Gyro_addr, 0x0F, 0x04); // 设置范围为±125度/秒 WriteData(Gyro_addr, 0x10, 0x07); // 设置输出数据速率为100 Hz WriteData(Gyro_addr, 0x11, 0x00); // 正常模式，睡眠时长2msdelay_us(100000); // 延迟等待配置生效&#125;// 初始化BMX055磁力计void BMX055_Init_Magnetometer() &#123; WriteData(Mag_addr, 0x4B, 0x83); // 软复位 WriteData(Mag_addr, 0x4C, 0x00); // 正常模式，输出数据速率为10 Hz WriteData(Mag_addr, 0x4E, 0x84); // 启用X、Y、Z轴 WriteData(Mag_addr, 0x51, 0x04); // 设置X-Y轴重复次数为9 WriteData(Mag_addr, 0x52, 0x0F); // 设置Z轴重复次数为15delay_us(100000); // 延迟等待配置生效&#125;// 读取加速度计数据void BMX055_Read_Accelerometer(int16_t *x, int16_t *y, int16_t *z) &#123; uint8_t data[6]; ReadData(Acc_addr, 0x02, data, 6); *x = (int16_t)((data[1] &lt;&lt; 8) | (data[0] &amp; 0xF0)) &gt;&gt; 4; // X轴数据 *y = (int16_t)((data[3] &lt;&lt; 8) | (data[2] &amp; 0xF0)) &gt;&gt; 4; // Y轴数据 *z = (int16_t)((data[5] &lt;&lt; 8) | (data[4] &amp; 0xF0)) &gt;&gt; 4; // Z轴数据 if (*x &gt; 2047) *x -= 4096; // 负值处理 if (*y &gt; 2047) *y -= 4096; if (*z &gt; 2047) *z -= 4096;&#125;// 读取陀螺仪数据void BMX055_Read_Gyroscope(int16_t *x, int16_t *y, int16_t *z) &#123; uint8_t data[6]; ReadData(Gyro_addr, 0x02, data, 6); *x = (int16_t)((data[1] &lt;&lt; 8) | data[0]); // X轴数据 *y = (int16_t)((data[3] &lt;&lt; 8) | data[2]); // Y轴数据 *z = (int16_t)((data[5] &lt;&lt; 8) | data[4]); // Z轴数据 if (*x &gt; 32767) *x -= 65536; // 负值处理 if (*y &gt; 32767) *y -= 65536; if (*z &gt; 32767) *z -= 65536;&#125;// 读取磁力计数据void BMX055_Read_Magnetometer(int16_t *x, int16_t *y, int16_t *z) &#123; uint8_t data[6]; ReadData(Mag_addr, 0x42, data, 6); *x = (int16_t)((data[1] &lt;&lt; 5) | (data[0] &gt;&gt; 3)); // X轴数据 *y = (int16_t)((data[3] &lt;&lt; 5) | (data[2] &gt;&gt; 3)); // Y轴数据 *z = (int16_t)((data[5] &lt;&lt; 7) | (data[4] &gt;&gt; 1)); // Z轴数据 if (*x &gt; 4095) *x -= 8192;  // 负值处理 if (*y &gt; 4095) *y -= 8192; if (*z &gt; 16383) *z -= 32768;&#125;// 读取所有传感器数据的示例void BMX055_Read_All() &#123; int16_t xAccl, yAccl, zAccl; int16_t xGyro, yGyro, zGyro; int16_t xMag, yMag, zMag; BMX055_Read_Accelerometer(&amp;xAccl, &amp;yAccl, &amp;zAccl); // 读取加速度计数据 BMX055_Read_Gyroscope(&amp;xGyro, &amp;yGyro, &amp;zGyro); // 读取陀螺仪数据 BMX055_Read_Magnetometer(&amp;xMag, &amp;yMag, &amp;zMag); // 读取磁力计数据 printf(&quot;加速度 X: %d, Y: %d, Z: %d\\n&quot;, xAccl, yAccl, zAccl); printf(&quot;陀螺仪 X: %d, Y: %d, Z: %d\\n&quot;, xGyro, yGyro, zGyro); printf(&quot;磁场 X: %d, Y: %d, Z: %d\\n&quot;, xMag, yMag, zMag);&#125;// 读取chip idvoid BMX055_Read_Chip_Id() &#123; uint8_t data; ReadData(Acc_addr, 0x00, &amp;data, 1);  // 使用指针传递data printf(&quot;Acc_addr chip_id:%d\\n&quot;, data); ReadData(Gyro_addr, 0x00, &amp;data, 1); printf(&quot;Gyro_addr chip_id:%d\\n&quot;, data); ReadData(Mag_addr, 0x40, &amp;data, 1); printf(&quot;Mag_addr chip_id:%d\\n&quot;, data);&#125;\n\n\n&#x2F;&#x2F;BMX055.h\n//BMX055.h#ifndef __BMX055_H#define __BMX055_H#include &quot;stm32f4xx.h&quot;#include &quot;sys.h&quot; #define AccSen\t\t\t\t\t\t\t0.0078125\t//g/lsb @ +/- 16g#define GyroSen\t\t\t\t\t\t\t0.01524\t\t//°/s/lsb @ 500#define TempSen\t\t\t\t\t\t\t0.5\t\t\t//K/LSB center temperature is 23℃#define MagxySen\t\t\t\t\t\t0.3\t\t\t//uT/lsb#define MagzSen\t\t\t\t\t\t\t0.15\t\t//uT/lsb//SDO1 SDO2 CSB3 pulled to GND#define Acc_addr\t\t\t\t\t\t0x18 #define Gyro_addr\t\t\t\t\t\t0x68 #define Mag_addr\t\t\t\t\t\t0x10 /* BMX055 Register Map *///ACC define#define\tACC_ID\t\t\t\t\t\t\t0x00\t//OXFA#define\tACC_XL\t\t\t\t\t\t\t0x02#define\tACC_XM\t\t\t\t\t\t\t0x03#define\tACC_YL\t\t\t\t\t\t\t0x04#define\tACC_YM\t\t\t\t\t\t\t0x05#define\tACC_ZL\t\t\t\t\t\t\t0x06#define\tACC_ZM\t\t\t\t\t\t\t0x07#define\tTemp\t\t\t\t\t\t\t0x08#define ACC_range\t\t\t\t\t\t0x0f\t//1100b --&gt; +/- 16g#define Shasow_dis\t\t\t\t\t\t0x13#define ACC_ret\t\t\t\t\t\t\t0x14\t//write 0xb6//Gyro define#define\tGYRO_ID\t\t\t\t\t\t\t0x00\t//OXOF#define\tGYRO_XL\t\t\t\t\t\t\t0x02#define\tGYRO_XM\t\t\t\t\t\t\t0x03#define\tGYRO_YL\t\t\t\t\t\t\t0x04#define\tGYRO_YM\t\t\t\t\t\t\t0x05#define\tGYRO_ZL\t\t\t\t\t\t\t0x06#define\tGYRO_ZM\t\t\t\t\t\t\t0x07#define GYRO_range\t\t\t\t\t\t0x0f\t//010b --&gt; +/- 500°/s#define GYRO_ret\t\t\t\t\t\t0x14\t//write 0xb6#define GYRO_OFFSET_reset\t\t\t\t0x21\t//writing 1 to the (0x21) offset_reset bit, all dynamic offset compensation register are reset to zero#define GYRO_SLOW_OFFSET_EN\t\t\t\t0x31\t//EN: &lt;0:2&gt; x/y/z Adjustable rate: &lt;7:6&gt; Time_period &lt;5:3&gt;#define GYRO_SLOW_OFFSET_UNFILT\t\t\t0x1A\t//&lt;5&gt;#define GYRO_FAST_OFFSET_EN\t\t\t\t0x32\t//EN: &lt;0:2&gt; x/y/z Cancellation Start: &lt;3&gt; (if the algorithm finished, &lt;3&gt;will reset to 0) Time_period &lt;5:3&gt;#define GYRO_FAST_OFFSET_UNFILT\t\t\t0x1A\t//&lt;5&gt;#define GYRO_X_OFFSET\t\t\t\t\t0x36#define GYRO_Y_OFFSET\t\t\t\t\t0x37#define GYRO_Z_OFFSET\t\t\t\t\t0x38//MAG define 8bits register 0x40 - 0x71// 0X40 - 0X4A read only#define\tMAG_ID\t\t\t\t\t\t\t0x40\t//OX32#define\tMAG_XL\t\t\t\t\t\t\t0x42\t//read only: data x[4:0]  lsb #define\tMAG_XM\t\t\t\t\t\t\t0x43\t//read only: data x[12:5] msb  x-self-test#define\tMAG_YL\t\t\t\t\t\t\t0x44\t//read only: data x[4:0]  lsb #define\tMAG_YM\t\t\t\t\t\t\t0x45\t//read only: data x[12:5] msb  Y-self-test#define\tMAG_ZL\t\t\t\t\t\t\t0x46\t//read only: data x[4:0]  lsb#define\tMAG_ZM\t\t\t\t\t\t\t0x47\t//read only: data x[12:5] msb  Z-self-test#define\tMAG_RHAL\t\t\t\t\t\t0x48#define\tMAG_RHAM\t\t\t\t\t\t0x49#define MAG_ret\t\t\t\t\t\t\t0x4b\t//1000 0001b bring the device into sleep mode, 操作完成后，自动变为00#define MAG_OPC\t\t\t\t\t\t\t0x4Cvoid IMU_Init(void);void BMX055_Init_Accelerometer();void BMX055_Init_Gyroscope();void BMX055_Init_Magnetometer();void BMX055_Read_Accelerometer(int16_t *x, int16_t *y, int16_t *z);void BMX055_Read_Gyroscope(int16_t *x, int16_t *y, int16_t *z);void BMX055_Read_Magnetometer(int16_t *x, int16_t *y, int16_t *z);void BMX055_Read_All();void BMX055_Read_Chip_Id();#endif\n\n\n\n然后就可以通过stm32f407与bmx055进行iic通讯了\n先试试chip id能不能读出来，能读出来再去读取其他的数据\n用到芯片的模块如果实在不会接线或者希望更快的使用这个芯片，可以找找有用到这个芯片的模块\n例如下面这个模块\n\n可以直接参考这个模块的接线方式进行\n然后先把程序在这个模块上跑跑能不能成功运行\n可以的话再在自己接好线的芯片上试试\n","categories":["学习"],"tags":["硬件","stm32f407"]},{"title":"Linux 常用命令","url":"/2024/11/19/Linux/","content":"本文介绍了Linux的一些常用的命令，推荐在实践中学\nLinux 常用命令汇总基本命令关机和重启\n关机：\nshutdown ‐h now          #立刻关机 shutdown ‐h 5         #5分钟后关机 poweroff            #立刻关机 \n\n重启\nshutdown ‐r now          #立刻重启 shutdown ‐r 5         #5分钟后重启 reboot              #立刻重启 \n\n帮助命令\n帮助\nshutdown –help          #查看关机命令帮助信息 ifconfig    ‐‐help          #查看网卡信息 man              #（命令说明书） man shutdown \n\n注意：man shutdown 打开命令说明书之后，使用按键 q 退出 \n\n目录操作命令目录切换命令\ncd\ncd /              #切换到根目录 cd /usr              #切换到根目录下的 usr 目录 cd ../              #切换到上一级目录  或者    cd .. cd ~              #切换到 home 目录 cd ‐              #切换到上次访问的目录 \n\n\n目录查看命令\nls\nLs            #查看当前目录下的所有目录和文件 ls ‐a          #查看当前目录下的所有目录和文件（包括隐藏的文件） ls ‐l  或  ll        #列表查看当前目录下的所有目录和文件（显示更多信息） ls /dir          #查看指定目录下的所有目录和文件      如：ls /usr \n\n目录操作命令创建目录\nmkdir\nmkdir        aaa     #  在当前目录下创建一个名为 aaa 的目录 mkdir        /usr/aaa    #  在指定目录下创建一个名为 aaa 的目录 \n\n删除目录或文件\nrm\nrm  文件        #删除当前目录下的文件 rm ‐f  文件          #删除当前目录的的文件（不询问） #删除目录： rm ‐r aaa          #递归删除当前目录下的 aaa 目录 rm ‐rf aaa          #递归删除当前目录下的 aaa 目录（不询问） #全部删除： rm ‐rf *            #将当前目录下的所有目录和文件全部删除 rm ‐rf /*         #【慎用！】将根目录下的所有文件全部删除 \n\n注意：rm 不仅可以删除目录，也可以删除其他文件或压缩包，为了方便大家的记忆，无论删 除任何目录或文件，都直接使用 rm ‐rf 目录&#x2F;文件&#x2F;压缩包 \n\n目录修改\n重命名目录\n命令：mv 当前目录 新目录 示例：mv aaa bbb    #将目录 aaa 改为 bbb    \n\n注意：mv 的语法不仅可以对目录进行重命名而且也可以对各种文件，压缩包等进行重命名的操作。 \n\n\n剪切目录     \n命令：mv 目录名称 目录的新位置示例：mv /usr/tmp/aaa /usr  #将/usr/tmp 目录下的 aaa 目录剪切到 /usr 目录下面   \n\n注意：mv 语法不仅可以对目录进行剪切操作，对文件和压缩包等都可执行剪切操作。\n\n\n拷贝目录\n&gt;命令：cp ‐r  目录名称  目录拷贝的目标位置      ‐r 代表递归 &gt;示例：cp /usr/tmp/aaa    /usr   #将/usr/tmp 目录下的 aaa 目录复制到  /usr 目录下面 \n\n注意：cp 命令不仅可以拷贝目录还可以拷贝文件，压缩包等，拷贝文件和压缩包时不用 写‐r 递归。 \n\n目录检索\n命令：find  目录  参数  文件名称 示例：find /usr/tmp ‐name &#x27;a*&#x27;        #查找/usr/tmp 目录下的所有以 a 开头的目录或文件\n\n文件操作命令新建文件\n命令：touch  文件名 示例：touch    aa.txt      #在当前目录创建一个名为 aa.txt 的文件 \n\n删除文件\n命令：rm ‐rf  文件名 \n\n修改文件\n打开文件\nvi  文件名 示例：vi aa.txt  或者  vim aa.txt      #打开当前目录下的 aa.txt 文件 \n\n若文件不存在则新建文件并打开 \n注意：使用 vi 编辑器打开文件后，并不能编辑，因为此时处于命令模式，点击键盘 i&#x2F;a&#x2F;o 进入 编辑模式。 \n\n编辑文件\n使用 vi 编辑器打开文件后点击按键：i ，a 或者 o 即可进入编辑模式。\ni：在光标所在字符前开始插入\na：在光标所在字符后开始插入 \no：在光标所在行的下面另起一新行插入\n\n保存文件\n第一步：ESC  进入命令行模式 \n第二步：：进入底行模式 \n第三步：wq!  #保存并退出编辑 \n\n取消编辑\n第一步：ESC  进入命令行模式 \n第二步：：进入底行模式 \n第三步：q!   #撤销本次修改并退出编辑\n\n\n\n查看文件\n文件的查看命令：cat&#x2F;more&#x2F;less&#x2F;tail \ncat：看最后一屏 示例：使用 cat 查看/etc/sudo.conf 文件，只能显示最后一屏内容。 cat sudo.conf \n\nmore：百分比显示 示例：使用 more 查看/etc/sudo.conf 文件，可以显示百分比，回车可以向下一行，空格可以向下一页，q 可以退出查看 more sudo.conf \n\nless：翻页查看 示例：使用 less 查看/etc/sudo.conf 文件，可以使用键盘上的 PgUp 和 PgDn 向上和向下翻页，q 结束查看 less sudo.conf \n\ntail：指定行数或者动态查看 示例：使用 tail ‐10  查看/etc/sudo.conf 文件的后 10 行，Ctrl+C 结束     tail ‐10 sudo.conf \n\n","categories":["学习"],"tags":["Linux","知识总结"]},{"title":"R语言总结","url":"/2025/09/14/R/","content":"R语言是一种编程语言和环境，专门用于统计计算和图形绘制。它是“引擎”，负责执行所有计算任务。\n为了有更好的编写R语言的体验，我们可以下载RStudio，它是一个**集成开发环境(IDE)**。它本身不执行计算，而是为 R 提供一个更好用、更强大的用户界面，包含代码编辑器、调试工具、图形显示窗口等，让你用 R 编程更加高效舒适。\n首先先从安装R以及RStudio开始吧\n安装R语言访问 官网 The Comprehensive R Archive Network\n根据你的操作系统选择下载安装程序，这里以windows为例\n点击页首的 “Download R for Windows”。\n点击 “install R for the first time” （首次安装 R）。\n点击页面顶部的 “Download R X.X.X for Windows” （X.X.X 是当前最新版本号）开始下载安装程序（一个 .exe 文件）。\n双击下载好的 .exe 文件。\n安装过程中基本一直点击 “下一步” 即可，所有默认设置对新手都很友好。\n语言选择：可以选择中文，也可以使用英文。\n安装位置：不建议更改，使用默认路径 C:\\Program Files\\R\\。\n组件选择：保持全选默认状态。\n启动选项：选择“No（接受自定义）”即可。\n完成安装。\n可以在系统变量路径中添加 bin 路径就可以全局使用 R 了\n安装RStudio安装完 R 之后，再来安装更好用的界面 RStudio。\n访问 RStudio 官网\n选择对应操作系统的安装程序，点击 “Download RStudio Desktop for windows”\n双击下载的 .exe 文件，同样一路“下一步”即可，无需更改默认设置。\n启动 RStudio，会自动匹配到你安装好的R，如果找不到，你也可以手动关联\n之后就能在Console中编写代码来测试环境是否配置完成了\n下载ISLR2数据集建议您访问书籍的官方网站，上面有最权威的下载链接和安装指南\n在网站上，你可以找到：\n\n电子书下载（免费）。\n实验手册（Labs）的R和Python代码。\n数据集的直接下载链接（如果需要手动下载）。\n以及其他更新信息。\n\n你也可以编写R语言来通过命令下载ISLR2数据集：\n选择File&gt;New File&gt;R Script新建一个文件，在其中编写代码如下：\ninstall.packages(&quot;ISLR2&quot;)library(ISLR2)data()\n\n选中代码，点击右上角的Run，运行成功后会显示R data sets，内容如下：\nData sets in package ‘datasets’:AirPassengers        Monthly Airline Passenger Numbers                     1949-1960BJsales              Sales Data with Leading IndicatorBJsales.lead (BJsales)                     Sales Data with Leading IndicatorBOD                  Biochemical Oxygen DemandCO2                  Carbon Dioxide Uptake in Grass PlantsChickWeight          Weight versus age of chicks on different                     dietsDNase                Elisa assay of DNaseEuStockMarkets       Daily Closing Prices of Major European                     Stock Indices, 1991-1998Formaldehyde         Determination of FormaldehydeHairEyeColor         Hair and Eye Color of Statistics StudentsHarman23.cor         Harman Example 2.3Harman74.cor         Harman Example 7.4Indometh             Pharmacokinetics of IndomethacinInsectSprays         Effectiveness of Insect SpraysJohnsonJohnson       Quarterly Earnings per Johnson &amp; Johnson                     ShareLakeHuron            Level of Lake Huron 1875-1972LifeCycleSavings     Intercountry Life-Cycle Savings DataLoblolly             Growth of Loblolly Pine TreesNile                 Flow of the River NileOrange               Growth of Orange TreesOrchardSprays        Potency of Orchard SpraysPlantGrowth          Results from an Experiment on Plant GrowthPuromycin            Reaction Velocity of an Enzymatic ReactionSeatbelts            Road Casualties in Great Britain 1969-84Theoph               Pharmacokinetics of TheophyllineTitanic              Survival of passengers on the TitanicToothGrowth          The Effect of Vitamin C on Tooth Growth in                     Guinea PigsUCBAdmissions        Student Admissions at UC BerkeleyUKDriverDeaths       Road Casualties in Great Britain 1969-84UKgas                UK Quarterly Gas ConsumptionUSAccDeaths          Accidental Deaths in the US 1973-1978USArrests            Violent Crime Rates by US StateUSJudgeRatings       Lawyers&#x27; Ratings of State Judges in the US                     Superior CourtUSPersonalExpenditure                     Personal Expenditure DataUScitiesD            Distances Between European Cities and                     Between US CitiesVADeaths             Death Rates in Virginia (1940)WWWusage             Internet Usage per MinuteWorldPhones          The World&#x27;s Telephonesability.cov          Ability and Intelligence Testsairmiles             Passenger Miles on Commercial US Airlines,                     1937-1960airquality           New York Air Quality Measurementsanscombe             Anscombe&#x27;s Quartet of &#x27;Identical&#x27; Simple                     Linear Regressionsattenu               The Joyner-Boore Attenuation Dataattitude             The Chatterjee-Price Attitude Dataaustres              Quarterly Time Series of the Number of                     Australian Residentsbeaver1 (beavers)    Body Temperature Series of Two Beaversbeaver2 (beavers)    Body Temperature Series of Two Beaverscars                 Speed and Stopping Distances of Carschickwts             Chicken Weights by Feed Typeco2                  Mauna Loa Atmospheric CO2 Concentrationcrimtab              Student&#x27;s 3000 Criminals Datadiscoveries          Yearly Numbers of Important Discoveriesesoph                Smoking, Alcohol and (O)esophageal Cancereuro                 Conversion Rates of Euro Currencieseuro.cross (euro)    Conversion Rates of Euro Currencieseurodist             Distances Between European Cities and                     Between US Citiesfaithful             Old Faithful Geyser Datafdeaths (UKLungDeaths)                     Monthly Deaths from Lung Diseases in the                     UKfreeny               Freeny&#x27;s Revenue Datafreeny.x (freeny)    Freeny&#x27;s Revenue Datafreeny.y (freeny)    Freeny&#x27;s Revenue Datagait                 Hip and Knee Angle while Walkinginfert               Infertility after Spontaneous and Induced                     Abortioniris                 Edgar Anderson&#x27;s Iris Datairis3                Edgar Anderson&#x27;s Iris Dataislands              Areas of the World&#x27;s Major Landmassesldeaths (UKLungDeaths)                     Monthly Deaths from Lung Diseases in the                     UKlh                   Luteinizing Hormone in Blood Sampleslongley              Longley&#x27;s Economic Regression Datalynx                 Annual Canadian Lynx trappings 1821-1934mdeaths (UKLungDeaths)                     Monthly Deaths from Lung Diseases in the                     UKmorley               Michelson Speed of Light Datamtcars               Motor Trend Car Road Testsnhtemp               Average Yearly Temperatures in New Havennottem               Average Monthly Temperatures at                     Nottingham, 1920-1939npk                  Classical N, P, K Factorial ExperimentoccupationalStatus   Occupational Status of Fathers and their                     Sonspenguins             Measurements of Penguins near Palmer                     Station, Antarcticapenguins_raw (penguins)                     Measurements of Penguins near Palmer                     Station, Antarcticaprecip               Annual Precipitation in Selected US Citiespresidents           Quarterly Approval Ratings of US                     Presidentspressure             Vapor Pressure of Mercury as a Function of                     Temperaturequakes               Locations of Earthquakes off Fijirandu                Random Numbers from Congruential Generator                     RANDUrivers               Lengths of Major North American Riversrock                 Measurements on Petroleum Rock Samplessleep                Student&#x27;s Sleep Datastack.loss (stackloss)                     Brownlee&#x27;s Stack Loss Plant Datastack.x (stackloss)                     Brownlee&#x27;s Stack Loss Plant Datastackloss            Brownlee&#x27;s Stack Loss Plant Datastate.abb (state)    US State Facts and Figuresstate.area (state)   US State Facts and Figuresstate.center (state)                     US State Facts and Figuresstate.division (state)                     US State Facts and Figuresstate.name (state)   US State Facts and Figuresstate.region (state)                     US State Facts and Figuresstate.x77 (state)    US State Facts and Figuressunspot.m2014 (sunspot.month)                     Monthly Sunspot Data, from 1749 to                     &quot;Present&quot;sunspot.month        Monthly Sunspot Data, from 1749 to                     &quot;Present&quot;sunspot.year         Yearly Sunspot Data, 1700-1988sunspots             Monthly Sunspot Numbers, 1749-1983swiss                Swiss Fertility and Socioeconomic                     Indicators (1888) Datatreering             Yearly Tree-Ring Data, -6000-1979trees                Diameter, Height and Volume for Black                     Cherry Treesuspop                Populations Recorded by the US Censusvolcano              Topographic Information on Auckland&#x27;s                     Maunga Whau Volcanowarpbreaks           The Number of Breaks in Yarn during                     Weavingwomen                Average Heights and Weights for American                     WomenData sets in package ‘ISLR2’:Auto                 Auto Data SetBikeshare            Bike sharing dataBoston               Boston DataBrainCancer          Brain Cancer DataCaravan              The Insurance Company (TIC) BenchmarkCarseats             Sales of Child Car SeatsCollege              U.S. News and World Report&#x27;s College DataCredit               Credit Card Balance DataDefault              Credit Card Default DataFund                 Fund Manager DataHitters              Baseball DataKhan                 Khan Gene DataNCI60                NCI 60 DataNYSE                 New York Stock Exchange DataOJ                   Orange Juice DataPortfolio            Portfolio DataPublication          Time-to-Publication DataSmarket              S&amp;P Stock Market DataWage                 Mid-Atlantic Wage DataWeekly               Weekly S&amp;P Stock Market DataUse ‘data(package = .packages(all.available = TRUE))’to list the data sets in all *available* packages.\n\n这个列表中包含书中使用的所有经典数据集，如 Auto, Boston, Carseats, Credit, Wage 等。\nR语言基础现在让我们开始学习R语言的基础知识。R语言就像一个强大的计算器，但它能做的远不止简单运算。我们将从最基本的概念开始，逐步建立起对R语言的理解。\n1. R作为计算器打开RStudio，在Console窗口中，你可以直接输入数学表达式。R会立即计算并返回结果。\n# 基本算术运算2 + 3        # 加法：返回 510 - 4       # 减法：返回 63 * 4        # 乘法：返回 1215 / 3       # 除法：返回 52^3          # 幂运算：2的3次方，返回 817 %% 5      # 取余数：17除以5的余数，返回 217 %/% 5     # 整除：17除以5的商，返回 3# 数学函数sqrt(16)     # 平方根：返回 4abs(-5)      # 绝对值：返回 5exp(1)       # e的1次方：返回 2.718282log(10)      # 自然对数：返回 2.302585log10(100)   # 以10为底的对数：返回 2\n\n2. 变量和赋值在R中，我们使用箭头 &lt;- 或等号 = 来给变量赋值。箭头是R的传统写法，更受推荐，因为它清楚地表示了”将右边的值赋给左边的变量”这个方向性。\n# 创建变量x &lt;- 5                    # 将5赋值给变量xy &lt;- 10                   # 将10赋值给变量yresult &lt;- x + y           # 将x和y的和赋值给resultprint(result)             # 显示result的值：15# 变量命名规则my_variable &lt;- 100        # 使用下划线myVariable &lt;- 200         # 使用驼峰命名法data.2024 &lt;- 300         # 可以包含点和数字# 2data &lt;- 400            # 错误！不能以数字开头# my-var &lt;- 500           # 错误！不能使用连字符# 查看和管理变量ls()                      # 列出当前环境中的所有变量rm(x)                     # 删除变量xrm(list = ls())           # 清空所有变量（慎用）\n\n3. 数据类型R有几种基本的数据类型，理解它们是掌握R语言的关键。每种类型都有其特定用途。\n# 数值型（numeric）- 用于存储数字age &lt;- 25                 height &lt;- 175.5           class(age)                # 查看类型：&quot;numeric&quot;# 字符型（character）- 用于存储文本name &lt;- &quot;张三&quot;            city &lt;- &#x27;Beijing&#x27;         # 单引号或双引号都可以class(name)               # 返回 &quot;character&quot;# 逻辑型（logical）- 用于存储真/假值is_student &lt;- TRUE        # 或写作 Tis_married &lt;- FALSE       # 或写作 Fclass(is_student)         # 返回 &quot;logical&quot;# 类型转换num_str &lt;- &quot;123&quot;          # 这是字符串num_val &lt;- as.numeric(num_str)  # 转换为数值：123str_val &lt;- as.character(456)    # 数值转字符串：&quot;456&quot;bool_val &lt;- as.logical(1)       # 1转为TRUE，0转为FALSE# 检查数据类型is.numeric(age)           # 返回 TRUEis.character(name)        # 返回 TRUEis.logical(is_student)    # 返回 TRUE\n\n4. 向量（Vector）向量是R中最基本的数据结构，可以理解为一组相同类型元素的有序集合。在R中，即使单个数值也被视为长度为1的向量。\n# 创建向量numbers &lt;- c(1, 2, 3, 4, 5)     # c()函数用于组合元素fruits &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;)scores &lt;- c(85, 92, 78, 95, 88)# 创建序列seq1 &lt;- 1:10                     # 创建1到10的整数序列seq2 &lt;- seq(0, 100, by=10)      # 从0到100，步长为10seq3 &lt;- seq(0, 1, length.out=5) # 从0到1，等分为5个数# 重复元素rep1 &lt;- rep(0, times=5)          # 将0重复5次：0 0 0 0 0rep2 &lt;- rep(c(1,2), times=3)     # 重复整个向量3次：1 2 1 2 1 2rep3 &lt;- rep(c(1,2), each=3)      # 每个元素重复3次：1 1 1 2 2 2# 向量运算（向量化运算是R的强大特性）v1 &lt;- c(1, 2, 3, 4)v2 &lt;- c(5, 6, 7, 8)v1 + v2                          # 对应元素相加：6 8 10 12v1 * 2                           # 每个元素乘以2：2 4 6 8v1 &gt; 2                           # 返回逻辑向量：FALSE FALSE TRUE TRUE# 访问向量元素scores[1]                        # 第1个元素（R从1开始计数）：85scores[c(1, 3, 5)]              # 第1、3、5个元素：85 78 88scores[2:4]                      # 第2到第4个元素：92 78 95scores[-2]                       # 除了第2个元素外的所有元素scores[scores &gt; 90]             # 条件筛选：大于90的分数# 向量的基本函数length(scores)                   # 向量长度：5sum(scores)                      # 求和：438mean(scores)                     # 平均值：87.6median(scores)                   # 中位数：88sd(scores)                       # 标准差：6.580274min(scores)                      # 最小值：78max(scores)                      # 最大值：95\n\n5. 矩阵（Matrix）矩阵是二维的数据结构，所有元素必须是相同类型。在统计分析中，矩阵运算非常重要。\n# 创建矩阵# 方法1：使用matrix函数mat1 &lt;- matrix(1:12, nrow=3, ncol=4)  # 3行4列，按列填充mat2 &lt;- matrix(1:12, nrow=3, ncol=4, byrow=TRUE)  # 按行填充# 方法2：组合向量vec1 &lt;- c(1, 2, 3)vec2 &lt;- c(4, 5, 6)mat3 &lt;- cbind(vec1, vec2)       # 按列组合mat4 &lt;- rbind(vec1, vec2)       # 按行组合# 矩阵属性dim(mat1)                        # 维度：3 4nrow(mat1)                       # 行数：3ncol(mat1)                       # 列数：4# 访问矩阵元素mat1[2, 3]                       # 第2行第3列的元素mat1[2, ]                        # 第2行的所有元素mat1[, 3]                        # 第3列的所有元素mat1[1:2, 2:3]                   # 第1-2行，第2-3列的子矩阵# 矩阵运算A &lt;- matrix(c(1,2,3,4), nrow=2)B &lt;- matrix(c(5,6,7,8), nrow=2)A + B                            # 元素对应相加A * B                            # 元素对应相乘（不是矩阵乘法）A %*% B                          # 矩阵乘法t(A)                             # 转置solve(A)                         # 求逆矩阵（如果存在）\n\n6. 数据框（Data Frame）数据框是R中最重要的数据结构之一，类似于Excel表格。它可以存储不同类型的数据，每列可以是不同的数据类型，但每列内的数据类型必须相同。\n# 创建数据框student_data &lt;- data.frame(  name = c(&quot;Alice&quot;, &quot;Bob&quot;, &quot;Charlie&quot;, &quot;David&quot;),  age = c(20, 21, 19, 22),  score = c(85, 92, 78, 95),  passed = c(TRUE, TRUE, FALSE, TRUE))# 查看数据框print(student_data)              # 显示整个数据框head(student_data, 2)            # 显示前2行tail(student_data, 2)            # 显示后2行str(student_data)                # 显示结构信息summary(student_data)            # 显示统计摘要# 访问数据框student_data$name                # 访问name列（返回向量）student_data[, &quot;score&quot;]          # 另一种访问列的方式student_data[2, ]                 # 第2行student_data[2, 3]                # 第2行第3列student_data[1:2, c(&quot;name&quot;, &quot;age&quot;)]  # 前2行的name和age列# 条件筛选student_data[student_data$age &gt; 20, ]     # 年龄大于20的所有行student_data[student_data$passed == TRUE, &quot;name&quot;]  # 通过考试的学生姓名# 添加新列student_data$grade &lt;- c(&quot;B&quot;, &quot;A&quot;, &quot;C&quot;, &quot;A&quot;)  # 添加成绩等级列student_data$age_group &lt;- ifelse(student_data$age &gt;= 21, &quot;Adult&quot;, &quot;Young&quot;)# 修改数据student_data$score[3] &lt;- 80      # 修改第3个学生的分数student_data[student_data$name == &quot;Bob&quot;, &quot;age&quot;] &lt;- 22  # 修改Bob的年龄\n\n7. 列表（List）列表是R中最灵活的数据结构，可以包含任何类型的元素，包括向量、矩阵、数据框，甚至其他列表。\n# 创建列表my_list &lt;- list(  numbers = c(1, 2, 3),  name = &quot;R Programming&quot;,  matrix = matrix(1:4, nrow=2),  data = student_data)# 访问列表元素my_list$numbers                  # 使用$符号my_list[[1]]                      # 使用双方括号（返回元素本身）my_list[1]                        # 使用单方括号（返回子列表）my_list[[&quot;name&quot;]]                # 使用名称访问# 添加或修改元素my_list$new_element &lt;- &quot;New&quot;     # 添加新元素my_list[[2]] &lt;- &quot;Updated Name&quot;   # 修改第2个元素# 列表长度和名称length(my_list)                   # 列表中元素的个数names(my_list)                    # 元素的名称\n\n控制结构控制结构让我们能够控制代码的执行流程，这是编程的核心概念之一。\n1. 条件语句条件语句让程序可以根据不同的条件执行不同的代码。\n# if语句score &lt;- 85if (score &gt;= 90) &#123;  print(&quot;优秀&quot;)&#125; else if (score &gt;= 80) &#123;  print(&quot;良好&quot;)&#125; else if (score &gt;= 60) &#123;  print(&quot;及格&quot;)&#125; else &#123;  print(&quot;不及格&quot;)&#125;# ifelse函数（向量化的条件判断）scores &lt;- c(85, 92, 78, 95, 58)grades &lt;- ifelse(scores &gt;= 90, &quot;A&quot;,          ifelse(scores &gt;= 80, &quot;B&quot;,           ifelse(scores &gt;= 70, &quot;C&quot;,          ifelse(scores &gt;= 60, &quot;D&quot;, &quot;F&quot;))))print(grades)  # &quot;B&quot; &quot;A&quot; &quot;C&quot; &quot;A&quot; &quot;F&quot;# switch语句（多分支选择）day &lt;- 3day_name &lt;- switch(day,  &quot;Monday&quot;, &quot;Tuesday&quot;, &quot;Wednesday&quot;,   &quot;Thursday&quot;, &quot;Friday&quot;, &quot;Saturday&quot;, &quot;Sunday&quot;)print(day_name)  # &quot;Wednesday&quot;\n\n2. 循环结构循环让我们可以重复执行某段代码，这在处理大量数据时特别有用。\n# for循环# 示例1：遍历向量fruits &lt;- c(&quot;apple&quot;, &quot;banana&quot;, &quot;orange&quot;)for (fruit in fruits) &#123;  print(paste(&quot;I like&quot;, fruit))  # paste函数用于连接字符串&#125;# 示例2：使用序列total &lt;- 0for (i in 1:10) &#123;  total &lt;- total + i  # 累加1到10&#125;print(total)  # 55# 示例3：遍历数据框for (i in 1:nrow(student_data)) &#123;  cat(&quot;Student:&quot;, student_data$name[i],       &quot;Score:&quot;, student_data$score[i], &quot;\\n&quot;)&#125;# while循环count &lt;- 1while (count &lt;= 5) &#123;  print(paste(&quot;Count is&quot;, count))  count &lt;- count + 1  # 别忘了更新条件，避免无限循环&#125;# repeat循环（需要使用break跳出）x &lt;- 1repeat &#123;  print(x)  x &lt;- x + 1  if (x &gt; 5) &#123;    break  # 当x大于5时跳出循环  &#125;&#125;# 循环控制语句for (i in 1:10) &#123;  if (i == 5) &#123;    next  # 跳过当前迭代，继续下一次  &#125;  if (i == 8) &#123;    break  # 跳出整个循环  &#125;  print(i)&#125;  # 输出：1 2 3 4 6 7\n\n函数函数是组织代码的基本方式，让我们可以重复使用代码逻辑。R中有大量内置函数，我们也可以创建自己的函数。\n1. 创建函数# 基本函数定义calculate_area &lt;- function(radius) &#123;  area &lt;- pi * radius^2  return(area)  # return可以省略，R会返回最后一个表达式的值&#125;# 使用函数circle_area &lt;- calculate_area(5)print(circle_area)  # 78.53982# 带多个参数的函数calculate_bmi &lt;- function(weight, height) &#123;  # weight: 体重（kg）  # height: 身高（m）  bmi &lt;- weight / (height^2)    # 返回BMI值和健康状况  if (bmi &lt; 18.5) &#123;    status &lt;- &quot;偏瘦&quot;  &#125; else if (bmi &lt; 25) &#123;    status &lt;- &quot;正常&quot;  &#125; else if (bmi &lt; 30) &#123;    status &lt;- &quot;偏胖&quot;  &#125; else &#123;    status &lt;- &quot;肥胖&quot;  &#125;    # 返回列表  return(list(bmi = bmi, status = status))&#125;# 使用函数result &lt;- calculate_bmi(70, 1.75)print(paste(&quot;BMI:&quot;, round(result$bmi, 2)))  # BMI: 22.86print(paste(&quot;状态:&quot;, result$status))        # 状态: 正常# 带默认参数的函数greet &lt;- function(name, greeting = &quot;Hello&quot;) &#123;  message &lt;- paste(greeting, name)  return(message)&#125;print(greet(&quot;Alice&quot;))                # &quot;Hello Alice&quot;print(greet(&quot;Bob&quot;, &quot;Good morning&quot;))  # &quot;Good morning Bob&quot;\n\n2. 函数作用域理解作用域对于编写正确的函数非常重要。\n# 全局变量 vs 局部变量global_var &lt;- 100test_scope &lt;- function() &#123;  local_var &lt;- 50         # 局部变量，只在函数内可见  global_var &lt;- 200       # 创建了一个局部变量，不影响全局变量  print(paste(&quot;函数内 global_var:&quot;, global_var))  # 200  print(paste(&quot;函数内 local_var:&quot;, local_var))    # 50&#125;test_scope()print(paste(&quot;函数外 global_var:&quot;, global_var))    # 100# print(local_var)  # 错误！local_var在函数外不存在# 使用&lt;&lt;-修改全局变量（慎用）modify_global &lt;- function() &#123;  global_var &lt;&lt;- 300  # 使用&lt;&lt;-修改全局变量&#125;modify_global()print(global_var)  # 300\n\n3. 高阶函数R支持函数式编程，可以将函数作为参数传递。\n# apply系列函数# apply: 对矩阵的行或列应用函数mat &lt;- matrix(1:12, nrow=3)row_sums &lt;- apply(mat, 1, sum)    # 1表示行，计算每行的和col_means &lt;- apply(mat, 2, mean)  # 2表示列，计算每列的平均值# lapply: 对列表的每个元素应用函数，返回列表numbers_list &lt;- list(a = 1:5, b = 6:10, c = 11:15)means_list &lt;- lapply(numbers_list, mean)# sapply: 类似lapply，但尝试简化结果为向量或矩阵means_vector &lt;- sapply(numbers_list, mean)  # 返回向量# tapply: 按分组应用函数ages &lt;- c(23, 25, 27, 22, 24, 26)groups &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;B&quot;)group_means &lt;- tapply(ages, groups, mean)  # 计算每组的平均年龄\n\n数据导入与导出在实际工作中，我们经常需要从外部文件读取数据或将处理结果保存到文件。\n1. CSV文件CSV是最常用的数据交换格式之一。\n# 写入CSV文件# 创建示例数据sales_data &lt;- data.frame(  month = c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;),  revenue = c(10000, 12000, 15000, 13000),  profit = c(3000, 3500, 4500, 4000))# 保存为CSVwrite.csv(sales_data, &quot;sales_2024.csv&quot;, row.names = FALSE)# 读取CSV文件data_from_csv &lt;- read.csv(&quot;sales_2024.csv&quot;)print(data_from_csv)# 处理更复杂的CSV# 指定分隔符、编码、缺失值等data &lt;- read.csv(&quot;data.csv&quot;,                  sep = &quot;,&quot;,           # 分隔符                 header = TRUE,       # 第一行是否为列名                 na.strings = c(&quot;NA&quot;, &quot;N/A&quot;, &quot;&quot;),  # 缺失值标记                 stringsAsFactors = FALSE)  # 字符串不转为因子\n\n2. Excel文件处理Excel文件需要额外的包。\n# 安装和加载readxl包install.packages(&quot;readxl&quot;)library(readxl)# 读取Excel文件excel_data &lt;- read_excel(&quot;data.xlsx&quot;, sheet = 1)  # 读取第一个工作表# 或指定工作表名称excel_data &lt;- read_excel(&quot;data.xlsx&quot;, sheet = &quot;Sales&quot;)# 写入Excel（需要writexl包）install.packages(&quot;writexl&quot;)library(writexl)write_xlsx(sales_data, &quot;output.xlsx&quot;)\n\n3. R数据文件R有自己的数据格式，适合保存R对象。\n# 保存单个对象saveRDS(student_data, &quot;student_data.rds&quot;)# 读取RDS文件loaded_data &lt;- readRDS(&quot;student_data.rds&quot;)# 保存多个对象save(student_data, sales_data, file = &quot;my_data.RData&quot;)# 加载RData文件load(&quot;my_data.RData&quot;)  # 对象会自动加载到环境中# 保存整个工作空间save.image(&quot;workspace.RData&quot;)\n\n数据清洗与处理数据清洗是数据分析中最耗时但也最重要的步骤。真实世界的数据通常需要大量清理才能使用。\n1. 处理缺失值# 创建包含缺失值的数据test_data &lt;- data.frame(  id = 1:6,  value1 = c(10, NA, 30, 40, NA, 60),  value2 = c(100, 200, NA, 400, 500, NA))# 检测缺失值is.na(test_data)                    # 返回逻辑矩阵complete.cases(test_data)            # 检查完整的行sum(is.na(test_data))              # 缺失值总数# 处理缺失值# 方法1：删除包含NA的行clean_data1 &lt;- na.omit(test_data)# 方法2：用特定值填充test_data$value1[is.na(test_data$value1)] &lt;- 0# 方法3：用平均值填充mean_val &lt;- mean(test_data$value2, na.rm = TRUE)test_data$value2[is.na(test_data$value2)] &lt;- mean_val# 方法4：向前或向后填充（需要zoo包）install.packages(&quot;zoo&quot;)library(zoo)test_data$value1 &lt;- na.fill(test_data$value1, &quot;extend&quot;)\n\n2. 数据转换# 数据类型转换df &lt;- data.frame(  numbers = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;),  dates = c(&quot;2024-01-01&quot;, &quot;2024-02-01&quot;, &quot;2024-03-01&quot;),  categories = c(&quot;A&quot;, &quot;B&quot;, &quot;A&quot;))df$numbers &lt;- as.numeric(df$numbers)df$dates &lt;- as.Date(df$dates)df$categories &lt;- as.factor(df$categories)# 数据标准化和归一化# 标准化（z-score）standardize &lt;- function(x) &#123;  (x - mean(x, na.rm = TRUE)) / sd(x, na.rm = TRUE)&#125;# 归一化（0-1范围）normalize &lt;- function(x) &#123;  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))&#125;# 应用转换data &lt;- data.frame(  height = c(165, 170, 175, 180, 185),  weight = c(60, 65, 70, 75, 80))data$height_std &lt;- standardize(data$height)data$weight_norm &lt;- normalize(data$weight)\n\n3. 数据重塑# 宽格式转长格式（需要reshape2包）install.packages(&quot;reshape2&quot;)library(reshape2)# 宽格式数据wide_data &lt;- data.frame(  id = 1:3,  jan = c(100, 110, 120),  feb = c(105, 115, 125),  mar = c(110, 120, 130))# 转为长格式long_data &lt;- melt(wide_data,                   id.vars = &quot;id&quot;,                  variable.name = &quot;month&quot;,                  value.name = &quot;sales&quot;)# 长格式转宽格式wide_again &lt;- dcast(long_data, id ~ month, value.var = &quot;sales&quot;)\n\n数据可视化基础数据可视化是理解数据的重要工具。R提供了强大的绘图功能。\n1. 基础绘图# 准备数据x &lt;- 1:10y &lt;- x^2# 散点图plot(x, y,      main = &quot;二次函数图像&quot;,      # 标题     xlab = &quot;X轴&quot;,                # X轴标签     ylab = &quot;Y轴&quot;,                # Y轴标签     col = &quot;blue&quot;,                # 颜色     pch = 16)                    # 点的形状# 添加线条lines(x, y, col = &quot;red&quot;, lwd = 2)  # lwd是线宽# 直方图data &lt;- rnorm(1000, mean = 100, sd = 15)  # 生成正态分布数据hist(data,      breaks = 30,                 # 分组数     main = &quot;正态分布直方图&quot;,     xlab = &quot;值&quot;,     col = &quot;lightblue&quot;,     border = &quot;black&quot;)# 箱线图boxplot(data,         main = &quot;数据分布箱线图&quot;,        ylab = &quot;值&quot;,        col = &quot;lightgreen&quot;)# 条形图categories &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;D&quot;)values &lt;- c(25, 40, 35, 50)barplot(values,         names.arg = categories,        main = &quot;分类数据条形图&quot;,        xlab = &quot;类别&quot;,        ylab = &quot;数值&quot;,        col = rainbow(4))         # 使用彩虹色# 饼图pie(values,     labels = categories,    main = &quot;数据占比饼图&quot;,    col = c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;yellow&quot;))\n\n2. 多图布局# 设置图形布局par(mfrow = c(2, 2))  # 2行2列的布局# 绘制四个图plot(1:10, type = &quot;l&quot;, main = &quot;线图&quot;)hist(rnorm(100), main = &quot;直方图&quot;)boxplot(rnorm(100), main = &quot;箱线图&quot;)barplot(c(3, 5, 2, 4), main = &quot;条形图&quot;)# 恢复默认布局par(mfrow = c(1, 1))\n\n3. ggplot2高级绘图ggplot2是R中最流行的绘图包，提供了更优雅的绘图语法。\n# 安装和加载ggplot2install.packages(&quot;ggplot2&quot;)library(ggplot2)# 创建示例数据df &lt;- data.frame(  x = rep(1:10, 3),  y = c(1:10, (1:10)^0.5, (1:10)^2),  group = rep(c(&quot;线性&quot;, &quot;平方根&quot;, &quot;平方&quot;), each = 10))# 基础ggplot图p &lt;- ggplot(df, aes(x = x, y = y, color = group)) +  geom_point(size = 3) +                    # 添加点  geom_line(size = 1) +                     # 添加线  labs(title = &quot;不同函数的比较&quot;,       x = &quot;X值&quot;,       y = &quot;Y值&quot;,       color = &quot;函数类型&quot;) +  theme_minimal() +                          # 使用简洁主题  theme(plot.title = element_text(hjust = 0.5))  # 标题居中print(p)# 分面图（多个子图）p_facet &lt;- ggplot(df, aes(x = x, y = y)) +  geom_point() +  geom_smooth(method = &quot;loess&quot;) +           # 添加平滑曲线  facet_wrap(~ group, scales = &quot;free_y&quot;) +  # 按group分面  theme_bw()print(p_facet)\n\n基础统计分析R的强大之处在于其统计分析能力。让我们学习一些基础的统计方法。\n1. 描述性统计# 生成示例数据set.seed(123)  # 设置随机种子，保证结果可重现data &lt;- rnorm(100, mean = 50, sd = 10)# 基本统计量mean(data)                  # 均值median(data)                # 中位数sd(data)                    # 标准差var(data)                   # 方差min(data)                   # 最小值max(data)                   # 最大值range(data)                 # 范围（最小值和最大值）quantile(data, c(0.25, 0.75))  # 四分位数# 综合统计摘要summary(data)# 自定义描述统计函数describe_data &lt;- function(x) &#123;  list(    n = length(x),    mean = mean(x, na.rm = TRUE),    median = median(x, na.rm = TRUE),    sd = sd(x, na.rm = TRUE),    min = min(x, na.rm = TRUE),    max = max(x, na.rm = TRUE),    q25 = quantile(x, 0.25, na.rm = TRUE),    q75 = quantile(x, 0.75, na.rm = TRUE)  )&#125;stats &lt;- describe_data(data)print(stats)\n\n2. 假设检验# t检验# 单样本t检验：检验均值是否等于某个值t.test(data, mu = 50)  # 检验均值是否等于50# 双样本t检验：比较两组数据的均值group1 &lt;- rnorm(50, mean = 50, sd = 10)group2 &lt;- rnorm(50, mean = 52, sd = 10)t.test(group1, group2)  # 默认是韦尔奇t检验（方差不等）t.test(group1, group2, var.equal = TRUE)  # 方差相等的t检验# 配对t检验before &lt;- rnorm(30, mean = 100, sd = 15)after &lt;- before + rnorm(30, mean = 5, sd = 5)  # 有改善t.test(before, after, paired = TRUE)# 卡方检验# 创建列联表observed &lt;- matrix(c(20, 30, 25, 25), nrow = 2)chisq.test(observed)# 方差分析（ANOVA）# 创建示例数据treatment &lt;- factor(rep(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), each = 20))response &lt;- c(rnorm(20, mean = 10),               rnorm(20, mean = 12),               rnorm(20, mean = 11))              # 单因素方差分析model &lt;- aov(response ~ treatment)summary(model)# 事后检验（如果ANOVA显著）TukeyHSD(model)\n\n3. 相关性分析# 创建相关数据x &lt;- rnorm(100)y &lt;- 2 * x + rnorm(100, sd = 0.5)  # y与x有较强相关性z &lt;- rnorm(100)  # z与x、y无关data &lt;- data.frame(x = x, y = y, z = z)# 相关系数cor(x, y)                    # 皮尔逊相关系数cor(data)                    # 相关矩阵cor(data, method = &quot;spearman&quot;)  # 斯皮尔曼等级相关# 相关性检验cor.test(x, y)               # 检验相关性是否显著# 可视化相关矩阵install.packages(&quot;corrplot&quot;)library(corrplot)cor_matrix &lt;- cor(data)corrplot(cor_matrix, method = &quot;circle&quot;, type = &quot;upper&quot;)\n\n线性回归线性回归是最基础也是最重要的统计模型之一。\n1. 简单线性回归# 创建示例数据set.seed(123)x &lt;- 1:100y &lt;- 2 * x + 3 + rnorm(100, sd = 10)  # y = 2x + 3 + 噪声data &lt;- data.frame(x = x, y = y)# 建立线性模型model &lt;- lm(y ~ x, data = data)  # y ~ x 表示 y 对 x 回归# 查看模型结果summary(model)                   # 详细的统计结果coef(model)                      # 系数confint(model)                   # 系数的置信区间# 预测new_data &lt;- data.frame(x = c(101, 102, 103))predictions &lt;- predict(model, newdata = new_data)print(predictions)# 带置信区间的预测predict(model, newdata = new_data, interval = &quot;confidence&quot;)predict(model, newdata = new_data, interval = &quot;prediction&quot;)# 可视化plot(data$x, data$y,      main = &quot;线性回归&quot;,     xlab = &quot;X&quot;, ylab = &quot;Y&quot;)abline(model, col = &quot;red&quot;, lwd = 2)  # 添加回归线# 或使用ggplot2library(ggplot2)ggplot(data, aes(x = x, y = y)) +  geom_point() +  geom_smooth(method = &quot;lm&quot;, se = TRUE) +  # se=TRUE显示置信带  labs(title = &quot;线性回归分析&quot;)\n\n2. 多元线性回归# 创建多变量数据n &lt;- 100x1 &lt;- rnorm(n)x2 &lt;- rnorm(n)x3 &lt;- rnorm(n)y &lt;- 2*x1 + 3*x2 - x3 + 5 + rnorm(n, sd = 2)data &lt;- data.frame(y, x1, x2, x3)# 建立多元回归模型model_multi &lt;- lm(y ~ x1 + x2 + x3, data = data)summary(model_multi)# 逐步回归（变量选择）# 向前选择model_null &lt;- lm(y ~ 1, data = data)  # 空模型model_full &lt;- lm(y ~ ., data = data)  # 全模型# 使用AIC准则进行逐步回归step_model &lt;- step(model_null,                    scope = list(lower = model_null, upper = model_full),                   direction = &quot;forward&quot;)\n\n3. 模型诊断# 残差分析residuals &lt;- residuals(model)fitted_values &lt;- fitted(model)# 残差图par(mfrow = c(2, 2))plot(model)  # 自动生成4个诊断图par(mfrow = c(1, 1))# 手动创建诊断图# 1. 残差vs拟合值（检查线性假设和方差齐性）plot(fitted_values, residuals,     main = &quot;残差 vs 拟合值&quot;,     xlab = &quot;拟合值&quot;, ylab = &quot;残差&quot;)abline(h = 0, col = &quot;red&quot;, lty = 2)# 2. Q-Q图（检查正态性假设）qqnorm(residuals)qqline(residuals, col = &quot;red&quot;)# 3. 检查异常值和影响点cooksd &lt;- cooks.distance(model)plot(cooksd, type = &quot;h&quot;,     main = &quot;Cook&#x27;s距离&quot;,     ylab = &quot;Cook&#x27;s距离&quot;)abline(h = 4/length(cooksd), col = &quot;red&quot;, lty = 2)# VIF检查多重共线性（需要car包）install.packages(&quot;car&quot;)library(car)vif(model_multi)  # VIF &gt; 5或10表示可能存在多重共线性\n\n实用技巧和最佳实践1. 代码组织# 项目结构建议# project/# ├── data/          # 原始数据# ├── scripts/       # R脚本# ├── output/        # 结果输出# └── functions/     # 自定义函数# 设置工作目录setwd(&quot;~/my_project&quot;)getwd()  # 查看当前工作目录# 使用相对路径data &lt;- read.csv(&quot;data/my_data.csv&quot;)source(&quot;functions/my_functions.R&quot;)  # 加载自定义函数文件# 清理环境rm(list = ls())  # 清空所有变量gc()             # 垃圾回收，释放内存\n\n2. 错误处理# try-catch结构safe_divide &lt;- function(x, y) &#123;  result &lt;- tryCatch(&#123;    x / y  &#125;, error = function(e) &#123;    print(paste(&quot;错误:&quot;, e$message))    return(NA)  &#125;, warning = function(w) &#123;    print(paste(&quot;警告:&quot;, w$message))    return(x / y)  &#125;)  return(result)&#125;# 测试函数safe_divide(10, 2)   # 正常：5safe_divide(10, 0)   # 产生警告：Infsafe_divide(10, &quot;a&quot;) # 产生错误：NA# 输入验证robust_mean &lt;- function(x) &#123;  if (!is.numeric(x)) &#123;    stop(&quot;输入必须是数值型&quot;)  &#125;  if (length(x) == 0) &#123;    warning(&quot;输入为空向量&quot;)    return(NA)  &#125;  return(mean(x, na.rm = TRUE))&#125;\n\n3. 性能优化# 向量化操作（避免循环）# 慢速方法slow_sum &lt;- function(n) &#123;  total &lt;- 0  for (i in 1:n) &#123;    total &lt;- total + i  &#125;  return(total)&#125;# 快速方法fast_sum &lt;- function(n) &#123;  sum(1:n)&#125;# 比较运行时间system.time(slow_sum(1000000))system.time(fast_sum(1000000))# 预分配内存# 慢速方法slow_grow &lt;- function(n) &#123;  vec &lt;- c()  for (i in 1:n) &#123;    vec &lt;- c(vec, i)  # 每次都重新分配内存  &#125;  return(vec)&#125;# 快速方法fast_grow &lt;- function(n) &#123;  vec &lt;- numeric(n)  # 预分配内存  for (i in 1:n) &#123;    vec[i] &lt;- i  &#125;  return(vec)&#125;# 使用apply函数代替循环# 计算矩阵每行的标准差mat &lt;- matrix(rnorm(10000), nrow = 100)# 使用apply（推荐）row_sds &lt;- apply(mat, 1, sd)# 使用循环（不推荐）row_sds_loop &lt;- numeric(nrow(mat))for (i in 1:nrow(mat)) &#123;  row_sds_loop[i] &lt;- sd(mat[i, ])&#125;\n\n","categories":["学习"],"tags":["知识总结","R语言"]},{"title":"WSL的安装与使用","url":"/2025/07/06/WSL%E7%9A%84%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/","content":"前言：因为某个项目在windows下编译实在是太慢太慢太慢了受不了了，而在Ubuntu下编译非常非常非常快，因此需要安装 WSL 来提高编译速度。\n\n\n据了解 WSL 有两个主要版本：WSL 1 和 WSL 2，它们在架构、性能和功能上有显著差异：\n\n\n\n特性\nWSL 1\nWSL 2\n\n\n\n架构\n转换层（Linux 系统调用 → Windows API）\n轻量级虚拟机（基于 Hyper-V，运行完整 Linux 内核）\n\n\n文件系统性能\nWindows 文件系统（NTFS）访问较慢\n大幅提升（Linux 文件系统 ext4 原生支持）\n\n\n系统调用兼容性\n部分 Linux 系统调用不支持\n几乎 100% 兼容（因使用真实 Linux 内核）\n\n\n启动速度\n更快（无虚拟机）\n稍慢（需启动轻量级 VM）\n\n\n内存占用\n更低\n稍高（需分配固定内存）\n\n\n网络模式\n与 Windows 共享 IP\n独立 IP（类似虚拟机，需端口转发）\n\n\nGPU&#x2F;Docker 支持\n有限\n完整支持（CUDA、Docker 等）\n\n\n而 WSL 2 虽然性能更强、兼容性更好，但在某些硬件相关的场景下会比 WSL 1 更复杂，主要原因包括：\n\n\n网络配置更复杂\n\n\nWSL 2 使用独立的虚拟网络（NAT 模式），而 WSL 1 直接共享 Windows 的网络栈。\n问题示例：\n在 WSL 2 中运行的服务（如 nginx）默认无法通过 localhost 从 Windows 直接访问，需手动配置端口转发或防火墙规则。\n跨设备访问 WSL 2 中的服务（如手机调试）需额外设置。\n\n\n\n\n文件系统访问延迟\n\n\nWindows 访问 Linux 文件：WSL 2 的 Linux 文件存储在虚拟磁盘（ext4）中，Windows 通过 \\\\wsl$ 访问时会有性能损耗。\nLinux 访问 Windows 文件：在 WSL 2 中挂载 Windows 目录（如 /mnt/c）时，IO 性能较差（尤其是大量小文件操作）。\n\n\nUSB&#x2F;外设支持受限\n\n\nWSL 2 默认无法直接访问 USB 设备（如 Arduino、摄像头），需通过第三方工具（如 usbipd-win）或 Windows 驱动桥接。\nWSL 1 因直接调用 Windows 驱动，外设支持更简单。\n\n\nGPU 加速需额外配置\n\n\n虽然 WSL 2 支持 GPU（如 CUDA 开发），但需手动安装：\nWindows 侧：NVIDIA 驱动。\nWSL 2 侧：Linux 版 CUDA Toolkit。\n\n\nWSL 1 无此需求（但 GPU 功能受限）。\n\n\n内存管理问题\n\n\nWSL 2 默认会占用固定内存（如 50% 物理内存），可能因内存不足导致 Windows 卡顿，需手动调整限制（在 .wslconfig 中配置）。\n\n\n因此，我选择安装 WSL 1 ，接下来，我将开始介绍如何在windows电脑上安装 WSL 1 。\n一、安装Windows终端windows11自带windows终端，跳过这一步\n二、启用 WSL 功能打开 PowerShell 管理员模式 输入下面指令\n# 启用 适用于Linux的Windows子系统 功能dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart\n\n完成后重启系统\n或者也可以手动启用：\nWin + S 输入搜索 控制面板 —&gt; 打开 控制面板 —&gt; 点击 程序和功能 —&gt;启动或关闭Windows功能 —&gt; 勾选适用于Linux的Windows子系统 —&gt; 重启系统\n三、安装 Linux 发行版在 Microsoft Store 搜索 Ubuntu ，安装 Ubuntu 24.04.1 LTS\n# cmd查看Windows系统中已安装的WSLwsl -l -v# 列出可用的分发（需要梯子，在 Microsoft Store 下载不需要梯子）wsl.exe --list --online# 进行安装（需要梯子，在 Microsoft Store 下载不需要梯子）wsl.exe --install &lt;发行版名称&gt;# 例如：wsl.exe --install Ubuntu-24.04\n\nUbuntu 安装完成后打开，此时会让你新建用户，按照提示输入用户名密码。\n四、设置为 WSL 1\n在 PowerShell 中运行：\nwsl --set-version &lt;发行版名称&gt; 1# 例如：wsl --set-version Ubuntu-24.04 1\n\n等待转换完成。\n\n\n五、基本使用\n启动 Linux：\n\n在开始菜单中点击安装的发行版名称，或命令行输入 wsl。\n\n\n更新软件包列表\nsudo apt update\n\n升级已安装的软件\nsudo apt upgrade -y \n\nWindows挂载目录\n在WSL（Windows Subsystem for Linux）中，/mnt目录是Windows文件系统在Linux环境中的挂载点，用于实现Windows和Linux之间的文件互通访问。\nWSL会自动将Windows的磁盘驱动器（如C:、D:）挂载到Linux的/mnt目录下，形成对应子目录：\n\nC:盘 → /mnt/c\nD:盘 → /mnt/d\n以此类推。\n例如，Windows的C:\\Users\\YourName\\Documents在WSL中路径为/mnt/c/Users/YourName/Documents。\n\n对性能敏感的项目建议放在WSL原生文件系统内（如~/project），而非/mnt下。\n在Windows中编辑WSL文件：使用VSCode的Remote-WSL扩展或直接访问\\\\wsl$\\。\n在WSL中编辑Windows文件：注意行尾符和权限问题。\n\n下载 neofetch htop\n# 使用sudo权限通过apt包管理器安装neofetch和htop两个软件# neofetch: 用于在终端显示系统信息和logo的轻量级工具# htop: 交互式系统监控工具，比默认的top命令更强大直观sudo apt install neofetch htop\n\n把文件迁移到wsl并递归赋予权限\n# 递归修改所有权（确保用户是所有者）sudo chown -R $USER:$USER .# 递归赋予读写执行权限sudo chmod -R u+rwx .\n\n使用vscode中的WSL插件访问WSL中的文件与工程\n\n退出 Linux：\n\n在 Linux 终端中输入 exit。\n\n\n关闭 WSL\n# 会终止所有未保存的 WSL 会话，类似于强制关机。wsl --shutdown# 如果需要正常退出 Linux 系统，建议先在 WSL 终端内运行 exit 或 sudo shutdown now。\n\n","categories":["学习"],"tags":["资料"]},{"title":"LangChain入门基础教程","url":"/2025/08/10/Langchain/","content":"\n\n\n首先通过一张图来理解Langchain在模型开发中的地位。我们现在使用的各大模型，像DeepSeek、ChatGLM等，都属于LLM（Large Language Model，大语言模型）。而Langchain则是基于LLM的框架，对大语言模型的功能进行了拓展，增加了像RAG（Retrieval-Augmented Generation，检索增强生成）、MCP（Multi-Chain Processing，多链处理）等功能。这些功能通过结合外部知识库、分块处理文本、向量相似性检索等技术，显著降低了模型的幻觉（Hallucination），同时提高了生成内容的准确性与专业性。\n从图中可以看到，Langchain的工作流程包括文档加载、文本分块、嵌入（Embedding）、向量存储、相似性检索等步骤，最终通过Prompt Template生成高质量的答案。这一流程使得模型能够更高效地利用结构化或非结构化数据，从而更好地满足实际应用的需求。\n下面，我们来简单地基于deepseek结合Langchain进行快速的开发测试\n一、各类大语言模型接入 LangChain首先\npip install langchainpip show langchain\n\n在进行 LangChain 开发之前，首先需要准备一个可以进行调用的大模型，这里我们选择使用 DeepSeek 的大模型，并使用 DeepSeek 官方的 API_KEY 进行调用。如果初次使用，需要先在 DeepSeek 的官网 DeepSeek 开放平台 上进行注册并创建一个新的 API_KEY。\n注册好 DeepSeek 的 API_KEY 后，首先在项目同级目录下创建一个 .env 文件，用于存储 DeepSeek 的 API_KEY 。（务必要创建 .env 文件，用于存储 DeepSeek 的 API_KEY ，因为后续  Langchain 会使用到）\nDEEPSEEK_API_KEY=sk-xxx\n\n接下来通过 python-dotenv 库读取 .env 文件中的 API_KEY，使其加载到当前的运行环境中，代码如下:\npip install python-dotenv\n\nimport osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot; )# print(DeepSeek_API_KEY) # 可以通过打印查看\n\n我们在当前的运行环境下不使用 LangChain，直接使用 DeepSeek 的 API 进行网络连通性测试，测试代码如下:\npip install openai\n\n先调用模型进行简单的测试\nfrom openai import OpenAIimport osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot; )#初始化DeepSeek的API客户端client = OpenAI(api_key=DeepSeek_API_KEY, base_url=&quot;https://api.deepseek.com&quot;)#调用DeepSeek的API，生成回答response = client.chat.completions.create(    model=&quot;deepseek-chat&quot;,    messages=[        &#123;&quot;role&quot;: &quot;system&quot;,&quot;content&quot;:&quot;你是乐于助人的助手，请根据用户的问题给出回答&quot;&#125;,        &#123;&quot;role&quot;: &quot;user&quot;,&quot;content&quot;:&quot;你好，请你介绍一下你自己。&quot;&#125;    ])#打印模型最终的响应结果print(response.choices[0].message.content)\n\n可以接收到类似下面的回复：\n你好！我是一个乐于助人的AI助手，随时准备为你提供各种帮助。无论是解答问题、提供建议、协助学习、处理日常事务，还是陪你聊天，我都会尽力满足你的需求。  我的知识涵盖多个领域，包括但不限于科技、历史、文化、健康、编程、生活技巧等。如果你有任何疑问或需要帮助，尽管告诉我！  你可以问我：  - **学习相关**：如何高效学习、解题思路、语言学习建议等  - **生活实用**：菜谱推荐、旅行攻略、时间管理等  - **技术问题**：编程、软件使用、AI相关等  - **创意灵感**：写作、策划、头脑风暴等  - **其他**：闲聊、趣味冷知识、心理疏导等  没有固定的话题限制，我会根据你的需求调整回答方式。希望我能成为你的得力助手！ 😊 你今天想了解些什么呢？\n\n如果可以正常收到 DeepSeek 模型的响应，则说明 DeepSeek 的 API 已经可以正常使用且网络连通性正常。\n接下来我们要考虑的是，对于这样一个 DeepSeek 官方的 API ，如何接入到 LangChain 中呢？其实非常简单，我们只需要使用 LangChain 中的一个 DeepSeek 组件即可像上述代码一样，直接使用相同的 DeepSeek_API_KEY 与大模型进行交互。因此，我们首先需要安装 LangChain 的 DeepSeek 组件，安装命令如下:\npip install langchain-deepseek\n\n这个库并不会被显式地调用，但是在后台运行过程中是会调用这个库的，所以务必要安装这个库\n安装好LangChain集成DeepSeek模型的依赖包后，需要通过一个init_chat_model函数来初始化大模型，代码如下：\nfrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)model = init_chat_model(model=&quot;deepseek-reasoner&quot;, model_provider=&quot;deepseek&quot;)# 其中 model 用来指定要使用的模型名称，而 model_provider 用来指定模型提供者，当写入 deepseek 时，会自动加载 langchain-deepseek 的依赖包，自动加载环境变量 DEEPSEEK_API_KEY ，并使用在 model 中指定的模型名称用来进行交互。question = &quot;你好，请你介绍一下你自己。&quot;result = model.invoke(question)resultprint(result.content)\n\n不仅仅是DeepSeek模型，LangChain还支持其他很多大模型，如OpenAI、Qwen、Gemini等，我们只需要在init_chat_model函数中指定不同的模型名称，就可以调用不同的模型。关于LangChain都支持哪些大模型以及每个模型对应的是哪个第三方依赖包，大家可以在LangChain的官方文档中找到。\n考虑到后续要实现RAG需要Embedding模型，而国内只有Dashscope的Embedding模型的api比较稳定，因此在此介绍一下如何接入Dashscope。Dashscope原名是阿里云的灵积社区，也是国内最大的API集成平台，其中包含了各类开源模型（如Qwen3系列模型）和国内在线模型（如DeepSeek、BaiChuan）模型API服务，现在已合并入阿里云百炼平台。对于国内开发者来说，若要使用Qwen系列模型API（而非本地部署），那么Dashscope平台提供的API服务肯定是最合适的。\n而百炼API获取方式也非常简单，只需注册阿里云账号，然后前往我的API页面进行充值和注册即可：\n然后即可调用海量各类模型了：\n当我们完成了DashScope API注册后，即可使用如下代码进行模型调用（需要提前将DASHSCOPE_API_KEY写到本地.env文件中）：\nimport osfrom openai import OpenAIfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量client = OpenAI(    api_key=os.getenv(&quot;DASHSCOPE_API_KEY&quot;),    base_url=&quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,)completion = client.chat.completions.create(    # 模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models    model=&quot;qwen-plus&quot;,    messages=[        &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;&#125;,        &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你是谁？&quot;&#125;,    ],)print(completion.model_dump_json())\n\n当然，也可以将DashScope中各类模型接入LangChain：\npip install --upgrade dashscope -i https://pypi.tuna.tsinghua.edu.cn/simple\n\nfrom langchain_community.chat_models.tongyi import ChatTongyifrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量model = ChatTongyi()question = &quot;你好，请你介绍一下你自己。&quot;result = model.invoke(question)print(result.content)\n\n【补充】ollama开源大模型接入LangChain\n当然，除了在线大模型的接入，langChain也只是使用Ollama、vLLM等框架启动的本地大模型。这里以ollama为例进行演示。\npip install langchain-ollama\n\n\n注意，这里要确保ollama已经顺利开启，并查看当前模型名称：\nollama list\n\n然后即可使用如下方法接入LangChain：\nfrom langchain_ollama import ChatOllamamodel = ChatOllama(model=&quot;deepseek-r1&quot;)question = &quot;你好，请你介绍一下你自己。&quot;result = model.invoke(question)print(result.content)\n\n二、LangChain 核心功能 Chain 的搭建LangChain之所以被称为LangChain，其核心概念就是Chain。 Chain翻译成中文就是“链”。一个链，指的是可以按照某一种逻辑，按顺序组合成一个流水线的方式。比如我们刚刚实现的问答流程： 用户输入一个问题 –&gt; 发送给大模型 –&gt; 大模型进行推理 –&gt; 将推理结果返回给用户。这个流程就是一个链。\n例如，我们这里可以先尝试着搭建一个简单的链，将模型输出结果“过滤”为一个纯字符串格式：\nfrom langchain_core.output_parsers import StrOutputParserfrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 直接使用模型 + 输出解析器搭建一个链basic_qa_chain = model | StrOutputParser()# 查看输出结果question = &quot;你好，请你介绍一下你自己。&quot;result = basic_qa_chain.invoke(question)print(result)\n\n此时result就不再是包含各种模型调用信息的结果，而是纯粹的模型响应的字符串结果。而这里用到的StrOutputParser()实际上就是用于构成LangChain中一个链条的一个对象，其核心功能是用于处理模型输出结果。同时我们也能发现，只需要使用Model | OutputParser，即可高效搭建一个链。\n一个最基本的Chain结构，是由Model和OutputParser两个组件构成的，其中Model是用来调用大模型的，OutputParser是用来解析大模型的响应结果的。\n类似这种结果解析器还有很多，稍后我们会继续进行介绍。\n接下来我们尝试为当前的执行流程添加一个提示词模板，我们可以借助ChatPromptTemplate非常便捷的将一个提示词模板同样以链的形式加入到当前任务中：\nfrom langchain_core.output_parsers import StrOutputParserfrom langchain.chat_models import init_chat_modelfrom langchain.prompts import ChatPromptTemplatefrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)prompt_template = ChatPromptTemplate([    (&quot;system&quot;, &quot;你是一个乐意助人的助手，请根据用户的问题给出回答&quot;),    (&quot;user&quot;, &quot;这是用户的问题： &#123;topic&#125;， 请用 yes 或 no 来回答&quot;)])# 直接使用模型 + 输出解析器bool_qa_chain = prompt_template | model | StrOutputParser()# 测试question = &quot;请问 1 + 1 是否 大于 2？&quot;# result = bool_qa_chain.invoke(question)# 建议显式传字典result = bool_qa_chain.invoke(&#123;&quot;topic&quot;: question&#125;)print(result)\n\n至此，我们就搭建了一个非常基础的链。在LangChain中，一个基础的链主要由三部分构成，分别是提示词模板、大模型和结果解析器（结构化解析器）：\n用户输入  ↓PromptTemplate → ChatModel → OutputParser（提示词模板）   （大模型）    （结构化解析）  ↓结构化结果\n\n结构化解析器功能最多，一些核心的结构化解析器功能如下：\n\n\n\n解析器名称\n功能描述\n类型\n\n\n\nBooleanOutputParser\n将LLM输出解析为布尔值\n基础类型解析\n\n\nDatetimeOutputParser\n将LLM输出解析为日期时间\n基础类型解析\n\n\nEnumOutputParser\n解析输出为预定义枚举值之一\n基础类型解析\n\n\nRegexParser\n使用正则表达式解析LLM输出\n模式匹配解析\n\n\nRegexDictParser\n使用正则表达式将输出解析为字典\n模式匹配解析\n\n\nStructuredOutputParser\n将LLM输出解析为结构化格式\n结构化解析\n\n\nYamlOutputParser\n使用Pydantic模型解析YAML输出\n结构化解析\n\n\nPandasDataFrameOutputParser\n使用Pandas DataFrame格式解析输出\n数据处理解析\n\n\nCombiningOutputParser\n将多个输出解析器组合为一个\n组合解析器\n\n\nOutputFixingParser\n包装解析器并尝试修复解析错误\n错误处理解析\n\n\nRetryOutputParser\n包装解析器并尝试修复解析错误\n错误处理解析\n\n\nRetryWithErrorOutputParser\n包装解析器并尝试修复解析错误\n错误处理解析\n\n\nResponseSchema\n结构化输出解析器的响应模式\n辅助类\n\n\n一些功能实现如下\n例如借助结构化解析器可以将yes or no转化为True or Fasle：\nfrom langchain.output_parsers import BooleanOutputParserfrom langchain.chat_models import init_chat_modelfrom langchain.prompts import ChatPromptTemplatefrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)prompt_template = ChatPromptTemplate([    (&quot;system&quot;, &quot;你是一个乐意助人的助手，请根据用户的问题给出回答&quot;),    (&quot;user&quot;, &quot;这是用户的问题： &#123;topic&#125;， 请用 yes 或 no 来回答&quot;)])# 直接使用模型 + 输出解析器bool_qa_chain = prompt_template | model | BooleanOutputParser()# 测试question = &quot;请问 1 + 1 是否 大于 2？&quot;result = bool_qa_chain.invoke(question)print(result) # false\n\n而StructuredOutputParser则可以在文档中提取指定的结构化信息：\nfrom langchain.chat_models import init_chat_modelfrom langchain_core.prompts import PromptTemplatefrom langchain.output_parsers import ResponseSchema, StructuredOutputParserfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)schemas = [    ResponseSchema(name=&quot;name&quot;, description=&quot;用户的姓名&quot;),    ResponseSchema(name=&quot;age&quot;, description=&quot;用户的年龄&quot;)]parser = StructuredOutputParser.from_response_schemas(schemas)prompt = PromptTemplate.from_template(    &quot;请根据以下内容提取用户信息，并返回 JSON 格式：\\n&#123;input&#125;\\n\\n&#123;format_instructions&#125;&quot;)chain = (    prompt.partial(format_instructions=parser.get_format_instructions()) | model | parser)result = chain.invoke(&#123;&quot;input&quot;: &quot;用户叫李雷，今年25岁，是一名工程师。&quot;&#125;)print(result) # &#123;&#x27;name&#x27;: &#x27;李雷&#x27;, &#x27;age&#x27;: &#x27;25&#x27;&#125;\n\n这里我们在 PromptTemplate 中，定义了两个占位符变量：\n\n&#123;input&#125; → 将由用户传入的文本替换（如 “用户叫李雷，今年25岁…”）\n\n&#123;format_instructions&#125; → 会通过 partial(...) 提前绑定结构化格式说明\n\n\n而格式化说明使用format_instructions进行标识其实也是一种约定俗称的方法，上述代码也就是相当于在创建Chain的时候，我们就输入了&#123;format_instructions&#125;对应的字符串parser.get_format_instructions()，我们也可以通过如下代码进行打印查看：\nprint(parser.get_format_instructions())\n\n输出为：\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing &quot;```json&quot; and &quot;```&quot;:```json&#123;\t&quot;name&quot;: string  // 用户的姓名\t&quot;age&quot;: string  // 用户的年龄&#125;```\n\n我们也可以进一步创建复合链\nfrom langchain.chat_models import init_chat_modelfrom langchain_core.prompts import PromptTemplatefrom langchain.output_parsers import ResponseSchema, StructuredOutputParserfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 第一步：根据标题生成新闻正文news_gen_prompt = PromptTemplate.from_template(    &quot;请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\\n\\n标题：&#123;title&#125;&quot;)# 第一个子链：生成新闻内容news_chain = news_gen_prompt | model# 第二步：从正文中提取结构化字段schemas = [    ResponseSchema(name=&quot;time&quot;, description=&quot;事件发生的时间&quot;),    ResponseSchema(name=&quot;location&quot;, description=&quot;事件发生的地点&quot;),    ResponseSchema(name=&quot;event&quot;, description=&quot;发生的具体事件&quot;),]parser = StructuredOutputParser.from_response_schemas(schemas)summary_prompt = PromptTemplate.from_template(    &quot;请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\\n\\n&#123;news&#125;\\n\\n&#123;format_instructions&#125;&quot;)# 第二个子链：生成新闻摘要summary_chain = (    summary_prompt.partial(format_instructions=parser.get_format_instructions())    | model    | parser)# 组合成一个复合 Chainfull_chain = news_chain | summary_chain# 调用复合链result = full_chain.invoke(&#123;&quot;title&quot;: &quot;苹果公司在加州发布新款AI芯片&quot;&#125;)print(result)\n\n管道操作符 | 会自动将前一个链的输出作为后一个链的输入，整体流程如下所示：\n用户输入（title）          │          ▼  ┌────────────────────────────┐  │  Chain 1: 生成新闻正文       │  │  Prompt: news_gen_prompt   │  │  Model: DeepSeek           │  └────────────────────────────┘          │          ▼  生成的新闻内容（news）          │          ▼  ┌───────────────────────────────────────┐  │  Chain 2: 提取结构化字段(摘要)           │  │  Prompt: summary_pro                  │  │  Model: DeepSeek                      │  │  OutputParser: StructuredOutputParser │  └───────────────────────────────────────┘          │          ▼  结化输出（如 JSON：时间、地点、事件）\n\n也可以借助LangChain适配器设置自定义可运行的节点\nfrom langchain.chat_models import init_chat_modelfrom langchain_core.prompts import PromptTemplatefrom langchain.output_parsers import ResponseSchema, StructuredOutputParserfrom langchain_core.runnables import RunnableLambdafrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 第一步：根据标题生成新闻正文news_gen_prompt = PromptTemplate.from_template(    &quot;请根据以下新闻标题撰写一段简短的新闻内容（100字以内）：\\n\\n标题：&#123;title&#125;&quot;)# 第一个子链：生成新闻内容news_chain = news_gen_prompt | model# 第二步：从正文中提取结构化字段schemas = [    ResponseSchema(name=&quot;time&quot;, description=&quot;事件发生的时间&quot;),    ResponseSchema(name=&quot;location&quot;, description=&quot;事件发生的地点&quot;),    ResponseSchema(name=&quot;event&quot;, description=&quot;发生的具体事件&quot;),]parser = StructuredOutputParser.from_response_schemas(schemas)summary_prompt = PromptTemplate.from_template(    &quot;请从下面这段新闻内容中提取关键信息，并返回结构化JSON格式：\\n\\n&#123;news&#125;\\n\\n&#123;format_instructions&#125;&quot;)# 第二个子链：生成新闻摘要summary_chain = (    summary_prompt.partial(format_instructions=parser.get_format_instructions())    | model    | parser)# 一个简单的打印函数，调试用def debug_print(x):    print(&quot;中间结果（新闻正文）:&quot;, x)    return xdebug_node = RunnableLambda(debug_print)# 插入 debug 节点full_chain = news_chain | debug_node | summary_chain# 调用复合链result = full_chain.invoke(&#123;&quot;title&quot;: &quot;苹果公司在加州发布新款AI芯片&quot;&#125;)print(result)\n\n通过上述不同的尝试，我们就已经理解了在langChain中，如何使用ChatPromptTemplate、Model、OutputParser来构建一个简单的Chain。其中：\n\nChatPromptTemplate 是用来构建提示模板的，将输入的问题转化为消息列表，可以设置系统指令，也可以添加一些变量；\nModel 是用来调用大模型的，可以指定使用不同的模型；\nOutputParser 是用来解析大模型的响应结果的，可以指定使用不同的解析器。\n\n\n[补充] LCEL关键概念介绍\n什么是 LCEL？——LangChain Expression Language 详解\n在现代大语言模型（LLM）应用的构建中，LangChain 提供了一种全新的表达范式，被称为 LCEL（LangChain Expression Language）。它不仅简化了模型交互的编排过程，还增强了组合的灵活性和可维护性。本文将从概念、设计目的、核心特性和实际价值几个方面，系统性地介绍 LCEL 的本质。\n\n一、LCEL 的定义\nLCEL，全称为 **LangChain Expression Language**，是一种专为 LangChain 框架设计的表达语言。它通过一种链式组合的方式，允许开发者使用清晰、声明式的语法来构建语言模型驱动的应用流程。\n简单来说，LCEL 是一种“函数式管道风格”的组件组合机制，用于连接各种可执行单元（Runnable）。这些单元包括提示模板、语言模型、输出解析器、工具函数等。\n\n二、设计目的\nLCEL 的设计初衷在于：\n\n模块化构建：将模型调用流程拆解为独立、可重用的组件。\n逻辑可视化：通过语法符号（如管道符 |）呈现出明确的数据流路径。\n统一运行接口：所有 LCEL 组件都实现了 .invoke()、.stream()、.batch() 等标准方法，便于在同步、异步或批处理环境下调用。\n脱离框架限制：相比传统的 Chain 类和 Agent 架构，LCEL 更轻量、更具表达力，减少依赖的“黑盒”逻辑。\n\n\n三、核心组成\n\nRunnable 接口\n\nLCEL 的一切基础单元都是 Runnable 对象，它是一种统一的可调用接口，支持如下形式：\n\n.invoke(input)：同步调用\n.stream(input)：流式生成\n.batch(inputs)：批量执行\n\n\n管道运算符 |\n\n这是 LCEL 最具特色的语法符号。多个 Runnable 对象可以通过 | 串联起来，形成清晰的数据处理链。例如：\nprompt | model | parser\n\n表示数据将依次传入提示模板、模型和输出解析器，最终输出结构化结果。\n\nPromptTemplate 与 OutputParser\n\nLCEL 强调组件之间的职责明确，Prompt 只负责模板化输入，Parser 只负责格式化输出，Model 只负责推理。\n\n四、典型优势\n\n\n\n特性\n描述\n\n\n\n\n简洁语法\n使用 `\n` 运算符提升可读性\n\n\n灵活组合\n可任意组合 Prompt、模型、工具、函数等组件\n\n\n\n明确边界\n每个步骤职责分明，方便调试与重用\n\n\n\n可嵌套扩展\n支持函数包装、自定义中间组件和流式拓展\n\n\n\n与 Gradio/FastAPI 集成良好\n可用于构建 API、UI 聊天等多种场景\n\n\n\n\n五、总结\nLCEL 是 LangChain 在 2024 年末引入的一项重要特性，标志着从传统 Agent 架构向“声明式、组合式”开发范式的转变。它不仅让开发者能以更清晰的方式组织 LLM 工作流，也大大提高了系统的可维护性与可测试性。\n\n三、LangChain 记忆存储与搭建多轮对话机器人在langChain中构建一个基本的问答机器人仅需要使用一个Chain便可以快速实现，如下所示：\nfrom langchain_core.output_parsers import StrOutputParserfrom langchain.prompts import ChatPromptTemplatefrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量chatbot_prompt = ChatPromptTemplate.from_messages([    (&quot;system&quot;, &quot;你叫小橘，是一名乐于助人的助手。&quot;),    (&quot;user&quot;, &quot;&#123;input&#125;&quot;)])# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 直接使用模型 + 输出解析器basic_qa_chain = chatbot_prompt | model | StrOutputParser()# 测试question = &quot;你好，请你介绍一下你自己。&quot;result = basic_qa_chain.invoke(question)print(result)\n\n在LangChain中，我们可以通过人工拼接消息队列，来为每次模型调用设置多轮对话记忆。\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessagefrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderfrom langchain.chat_models import init_chat_modelfrom langchain_core.output_parsers import StrOutputParserfrom dotenv import load_dotenvload_dotenv(override=True) # 加载 .env 文件中的环境变量model  = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)parser = StrOutputParser()prompt = ChatPromptTemplate.from_messages([    SystemMessage(content=&quot;你叫小橘，是一名乐于助人的助手。&quot;),    MessagesPlaceholder(variable_name=&quot;messages&quot;),])chain = prompt | model | parsermessages_list = []  # 初始化历史print(&quot;🔹 输入 exit 结束对话&quot;)while True:    user_query = input(&quot;你：&quot;)    if user_query.lower() in &#123;&quot;exit&quot;, &quot;quit&quot;&#125;:        break    # 1) 追加用户消息    messages_list.append(HumanMessage(content=user_query))    # 2) 调用模型    assistant_reply = chain.invoke(&#123;&quot;messages&quot;: messages_list&#125;)    print(&quot;小橘：&quot;, assistant_reply)    # 3) 追加 AI 回复    messages_list.append(AIMessage(content=assistant_reply))    # 4) 仅保留最近 50 条    messages_list = messages_list[-50:]\n\n此外还有一个问题是，大家经常看到的问答机器人其实都是采用流式传输模式。用户输入问题，等待模型直接返回回答，然后用户再输入问题，模型再返回回答，这样循环下去，用户输入问题和模型返回回答之间的时间间隔太长，导致用户感觉机器人反应很慢。所以LangChain提供了一个astream方法，可以实现流式输出，即一旦模型有输出，就立即返回，这样用户就可以看到模型正在思考，而不是等待模型思考完再返回。\n实现的方法也非常简单，只需要在调用模型时将invoke方法替换为astream方法，然后使用async for循环来持续获取模型的输出即可。代码如下：\nfrom langchain_core.output_parsers import StrOutputParserfrom langchain.chat_models import init_chat_modelfrom langchain.prompts import ChatPromptTemplatefrom dotenv import load_dotenvimport asyncioload_dotenv(override=True)  # 加载 .env 文件中的环境变量chatbot_prompt = ChatPromptTemplate.from_messages([    (&quot;system&quot;, &quot;你叫小智，是一名乐于助人的助手。&quot;),    (&quot;user&quot;, &quot;&#123;input&#125;&quot;)])# 使用 DeepSeek 模型model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 直接使用提示模版 + 模型 + 输出解析器qa_chain_with_system = chatbot_prompt | model | StrOutputParser()async def main():    async for chunk in qa_chain_with_system.astream(&#123;&quot;input&quot;: &quot;你好，请你介绍一下你自己&quot;&#125;):        print(chunk, end=&quot;&quot;, flush=True)# 运行异步主函数asyncio.run(main())\n\n同样的，可以进一步为每次模型调用设置多轮对话记忆。\nimport asynciofrom langchain_core.messages import AIMessage, HumanMessage, SystemMessagefrom langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderfrom langchain.chat_models import init_chat_modelfrom langchain_core.output_parsers import StrOutputParserfrom dotenv import load_dotenvload_dotenv(override=True)  # 加载 .env 文件中的环境变量model = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)parser = StrOutputParser()prompt = ChatPromptTemplate.from_messages([    SystemMessage(content=&quot;你叫小橘，是一名乐于助人的助手。&quot;),    MessagesPlaceholder(variable_name=&quot;messages&quot;),])chain = prompt | model | parserasync def main():    messages_list = []  # 初始化历史    print(&quot;🔹 输入 exit 结束对话&quot;)    while True:        user_query = input(&quot;你：&quot;)        if user_query.lower() in &#123;&quot;exit&quot;, &quot;quit&quot;&#125;:            break        # 1) 追加用户消息        messages_list.append(HumanMessage(content=user_query))        # 2) 调用模型（异步流式输出）        print(&quot;小橘：&quot;, end=&quot;&quot;, flush=True)        assistant_reply = &quot;&quot;        async for chunk in chain.astream(&#123;&quot;messages&quot;: messages_list&#125;):            print(chunk, end=&quot;&quot;, flush=True)            assistant_reply += chunk  # 收集回复内容        print() # 换行        # 3) 追加 AI 回复        messages_list.append(AIMessage(content=assistant_reply))        # 4) 仅保留最近 50 条        messages_list = messages_list[-50:]# 运行异步主函数asyncio.run(main())\n\n如上所示展示的问答效果就是我们在构建大模型应用时需要实现的流式输出效果。接下来我们就进一步地，使用gradio来开发一个支持在网页上进行交互的问答机器人。Gradio 是一个用于快速构建机器学习模型交互式演示界面的 Python 库。它允许开发者用几行代码创建 Web 应用，无需前端知识即可让用户通过浏览器输入数据并查看模型预测结果。\n首先需要安装一下gradio的第三方依赖包\npip install gradio\n\n完整实现的代码如下：\n# 导入必要的库import gradio as gr  # 用于构建Web界面的库from langchain.chat_models import init_chat_model  # 初始化聊天模型的函数from langchain_core.output_parsers import StrOutputParser  # 字符串输出解析器from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder  # 聊天提示模板和消息占位符from langchain_core.messages import SystemMessage, HumanMessage, AIMessage  # 系统消息、人类消息和AI消息from dotenv import load_dotenv  # 用于加载环境变量load_dotenv(override=True)  # 加载 .env 文件中的环境变量（用于存储API密钥等敏感信息）# ==================== 第一部分：设置语言模型和对话链 ====================# 1. 初始化聊天模型# 使用&quot;deepseek-chat&quot;模型，模型提供者为&quot;deepseek&quot;model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 2. 创建输出解析器（将模型输出转换为字符串）parser = StrOutputParser()# 3. 创建聊天提示模板# 这里定义了一个系统消息（设置AI助手的角色）和一个消息占位符（用于传入对话历史）chatbot_prompt = ChatPromptTemplate.from_messages(    [        SystemMessage(content=&quot;你叫小橘，是一名乐于助人的助手。&quot;),  # 系统角色设定        MessagesPlaceholder(variable_name=&quot;messages&quot;),  # 手动传入历史对话消息    ])# 4. 创建对话链# 使用LangChain的LCEL（LangChain Expression Language）将提示模板、模型和解析器组合起来# 流程：提示模板 -&gt; 模型 -&gt; 输出解析器qa_chain = chatbot_prompt | model | parser# ==================== 第二部分：创建Gradio界面 ====================# 定义CSS样式（用于美化界面）CSS = &quot;&quot;&quot;.main-container &#123;max-width: 1200px; margin: 0 auto; padding: 20px;&#125;  # 主容器样式.header-text &#123;text-align: center; margin-bottom: 20px;&#125;  # 标题样式&quot;&quot;&quot;# 创建聊天机器人界面的函数def create_chatbot() -&gt; gr.Blocks:    # 创建一个Gradio Blocks界面（比Interface更灵活）    with gr.Blocks(title=&quot;DeepSeek Chat&quot;, css=CSS) as demo:  # 设置标题和CSS        # 主容器（使用上面定义的CSS类）        with gr.Column(elem_classes=[&quot;main-container&quot;]):            # 标题            gr.Markdown(&quot;# 流式对话机器人&quot;, elem_classes=[&quot;header-text&quot;])                        # 聊天机器人组件            chatbot = gr.Chatbot(                height=500,  # 高度500像素                show_copy_button=True,  # 显示复制按钮                avatar_images=(  # 设置头像                    &quot;https://smallgoodgood.top/images/23.jpg&quot;,  # 用户头像                    &quot;https://smallgoodgood.top/images/23.jpg&quot;,  # AI头像                )            )                        # 输入框和按钮            msg = gr.Textbox(placeholder=&quot;请输入您的问题...&quot;, container=False, scale=7)  # 文本输入框            submit = gr.Button(&quot;发送&quot;, scale=1, variant=&quot;primary&quot;)  # 发送按钮（主要样式）            clear = gr.Button(&quot;清空&quot;, scale=1)  # 清空按钮        # ---------------  状态管理：保存 messages_list  ---------------        # Gradio的State组件用于保存对话历史（真正的Message对象列表）        state = gr.State([])        # ---------------  主响应函数（流式处理） ----------------------        async def respond(user_msg: str, chat_hist: list, messages_list: list):            &quot;&quot;&quot;            处理用户输入并生成AI回复（流式）            参数:                user_msg: 用户输入的消息                chat_hist: 聊天历史（用于显示在界面上）                messages_list: 保存的Message对象列表（用于模型处理）            返回:                更新后的msg, chat_hist和messages_list            &quot;&quot;&quot;                        # 1) 检查用户输入是否为空            if not user_msg.strip():                yield &quot;&quot;, chat_hist, messages_list  # 如果为空，直接返回                return            # 2) 将用户消息添加到历史中            # 创建HumanMessage对象（表示用户消息）            messages_list.append(HumanMessage(content=user_msg))            # 更新聊天历史（用于界面显示）            chat_hist = chat_hist + [(user_msg, None)]            yield &quot;&quot;, chat_hist, messages_list  # 先显示用户消息            # 3) 流式调用模型生成回复            partial = &quot;&quot;  # 用于累积模型的流式输出            # 异步流式调用对话链            async for chunk in qa_chain.astream(&#123;&quot;messages&quot;: messages_list&#125;):                partial += chunk  # 累积模型输出                # 更新最后一条AI回复（实现流式效果）                chat_hist[-1] = (user_msg, partial)                yield &quot;&quot;, chat_hist, messages_list  # 实时更新界面            # 4) 将完整回复加入历史，并裁剪到最近50条（防止内存占用过大）            messages_list.append(AIMessage(content=partial))  # 创建AIMessage对象            messages_list = messages_list[-50:]  # 只保留最近50条消息            # 5) 最终返回（Gradio需要把新的state传回）            yield &quot;&quot;, chat_hist, messages_list        # ---------------  清空历史函数 -------------------------------        def clear_history():            &quot;&quot;&quot;清空聊天历史&quot;&quot;&quot;            return [], &quot;&quot;, []  # 返回空列表，分别对应: chatbot, msg输入框, messages_list        # ---------------  事件绑定 ------------------------------        # 绑定输入框的回车事件和发送按钮的点击事件        msg.submit(respond, [msg, chatbot, state], [msg, chatbot, state])        submit.click(respond, [msg, chatbot, state], [msg, chatbot, state])        # 绑定清空按钮的点击事件        clear.click(clear_history, outputs=[chatbot, msg, state])    return demo  # 返回创建的Gradio界面# ==================== 第三部分：启动应用 ====================# 创建聊天机器人界面demo = create_chatbot()# 启动应用# 参数说明:# server_name=&quot;127.0.0.1&quot; - 本地运行# server_port=7860 - 使用7860端口# share=False - 不生成公开链接# debug=True - 调试模式demo.launch(server_name=&quot;127.0.0.1&quot;, server_port=7860, share=False, debug=True)\n\n运行后，在浏览器访问http://127.0.0.1:7860即可进行问答交互。\n当然这只是最简单的问答机器人实现形式，实际上企业应用的问答机器人往往需要更加复杂的逻辑，比如用户权限管理、上下文记忆等\n四、LangChain 接入工具流程在LangChain生态中，既有海量丰富的内置工具，同时也能接入自定义工具，不仅能通过搭建一个个链（Chain）将工具封装在对应的工作流中，也能借助LangChain Agent功能，实时灵活创建不同的Chain来完成复杂工具调用，甚至还可以使用更高级的LangGraph进行工作流编排。\n本小节我们将首先介绍如何在LangChain中接入外部工具，然后从下一小节开始，我们会进一步介绍如何使用LangChain Agent库来搭建更加复杂的工作流。\n这里我们首先介绍最基本的LangChain接入工具流程。在MCP爆火之前，LangChian生态中就已经内置集成了非常多的实用工具，开发者可以快速调用这些工具完成更加复杂工作流的开发。\nLangChain内置工具列表\n我们就以其中代码解释器为例，来介绍如何将内置工具接入LangChain的工作流中。\npip install -qU langchain-community langchain-experimental pandas\n\nTelco数据集是Kaggle分享的一个高分数据集，是Kaggle平台上非常经典的围绕偏态数据集建模的数据集。该数据源自IBM商业社区（IBM Business Analytics Community）上分享的数据集，用于社区成员内部学习使用。\n根据IBM商业社区分享团队描述，该数据集为某电信公司在加利福尼亚为7000余位用户（个人&#x2F;家庭）提供电话和互联网服务的相关记录。由于该数据集并不是竞赛数据集，因此数据集的下载方式相对容易，官网也提供了网页下载选项。我们可以在该数据集的Kaggle主页看到数据集的相关信息以及下载地址。当然，熟练使用Kaggle主页获取数据和挖掘信息（而不是借助第三方渠道），也是算法工程师必备技能之一。\n我们可以先用以下代码查看数据集的一些基本信息：\nimport pandas as pddataset = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)pd.set_option(&#x27;max_colwidth&#x27;,200)print(dataset.head(5))dataset.info()\n\n其中数据集各字段解释如下：\n\n\n\n字段\n解释\n\n\n\ncustomerID\n用户ID\n\n\ngender\n性别\n\n\nSeniorCitizen\n是否是老年人（1代表是）\n\n\nPartner\n是否有配偶（Yes or No）\n\n\nDependents\n是否经济独立（Yes or No）\n\n\ntenure\n用户入网时间\n\n\nPhoneService\n是否开通电话业务（Yes or No）\n\n\nMultipleLines\n是否开通多条电话业务（Yes 、 No or No phoneservice）\n\n\nInternetService\n是否开通互联网服务（No、DSL数字网络或filber potic光线网络）\n\n\nOnlineSecurity\n是否开通网络安全服务（Yes、No or No internetservice）\n\n\nOnlineBackup\n是否开通在线备份服务（Yes、No or No internetservice）\n\n\nDeviceProtection\n是否开通设备保护服务（Yes、No or No internetservice）\n\n\nTechSupport\n是否开通技术支持业务（Yes、No or No internetservice）\n\n\nStreamingTV\n是否开通网络电视（Yes、No or No internetservice）\n\n\nStreamingMovies\n是否开通网络电影（Yes、No or No internetservice）\n\n\nContract\n合同签订方式（按月、按年或者两年）\n\n\nPaperlessBilling\n是否开通电子账单（Yes or No）\n\n\nPaymentMethod\n付款方式（bank transfer、credit card、electronic check、mailed check）\n\n\nMonthlyCharges\n月度费用\n\n\nTotalCharges\n总费用\n\n\nChurn\n是否流失（Yes or No）\n\n\n接下来测试LangChain内置代码解释器工具功能：\n# 导入必要的库import pandas as pd  # 用于数据处理和分析的核心库from langchain_experimental.tools import PythonAstREPLTool  # LangChain的实验性工具，允许安全执行Python代码# 读取CSV文件到Pandas DataFrame# 这是一个电信客户流失数据集(来自Kaggle)df = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)# 创建PythonAstREPLTool工具实例# locals参数将当前作用域的变量(这里只有df)传递到工具的执行环境中# 这样工具内部就可以访问这个DataFrametool = PythonAstREPLTool(locals=&#123;&quot;df&quot;: df&#125;)# 使用LangChain内置代码解释器工具执行Python代码字符串# 这里计算&#x27;SeniorCitizen&#x27;列的平均值# invoke方法会安全地执行传入的代码并返回结果print(tool.invoke(&quot;df[&#x27;SeniorCitizen&#x27;].mean()&quot;))  # 输出老年客户比例的平均值# 直接使用Pandas计算&#x27;MonthlyCharges&#x27;列的平均值# 这是常规的Pandas操作方式，不使用LangChain工具print(df[&#x27;MonthlyCharges&#x27;].mean())  # 输出月费用的平均值\n\nPythonAstREPLTool是一个代码执行工具，特点：\n\n安全地在沙箱中执行Python代码\n可以限制可访问的变量和函数\n常用于AI代理(Agent)中让AI动态执行代码\n\n通过locals参数，我们只暴露df变量给工具\n然后invoke()方法执行代码字符串并返回结果\n接下来创建LangChain工作流并绑定内置工具\nimport pandas as pd  # 用于数据处理和分析的核心库from langchain_experimental.tools import PythonAstREPLTool  # LangChain的实验性工具，允许安全执行Python代码from langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)model  = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)df = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)tool = PythonAstREPLTool(locals=&#123;&quot;df&quot;: df&#125;)llm_with_tools = model.bind_tools([tool])response = llm_with_tools.invoke(    &quot;我有一张表，名为&#x27;df&#x27;，请帮我计算MonthlyCharges字段的均值。&quot;)print(response)\n\n通过观察输出，此时我们发现，LangChain回复的结果就不再是简单的文字内容，而是一条调用外部工具的消息。我们可以使用如下方法将这条消息里面涉及到代码运行的核心参数提取出来：\nimport pandas as pd  # 用于数据处理和分析的核心库from langchain_experimental.tools import PythonAstREPLTool  # LangChain的实验性工具，允许安全执行Python代码from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParserfrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)model  = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)df = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)tool = PythonAstREPLTool(locals=&#123;&quot;df&quot;: df&#125;)parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)llm_with_tools = model.bind_tools([tool]) | parserresponse = llm_with_tools.invoke(    &quot;我有一张表，名为&#x27;df&#x27;，请帮我计算MonthlyCharges字段的均值。&quot;)print(response)\n\n此时输出：\n&#123;&#x27;query&#x27;: &quot;df[&#x27;MonthlyCharges&#x27;].mean()&quot;&#125;\n\n接着通过设置提示词模板，再在当前链中加入一个tool外部函数的环节，即可让大模型输出的参数直接带入到tool中进行运行\nimport pandas as pd  # 用于数据处理和分析的核心库from langchain_core.prompts import ChatPromptTemplatefrom langchain_experimental.tools import PythonAstREPLTool  # LangChain的实验性工具，允许安全执行Python代码from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParserfrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)system = f&quot;&quot;&quot;你可以访问一个名为 `df` 的 pandas 数据框，你可以使用df.head().to_markdown() 查看数据集的基本信息， \\请根据用户提出的问题，编写 Python 代码来回答。只返回代码，不返回其他内容。只允许使用 pandas 和内置库。&quot;&quot;&quot;prompt = ChatPromptTemplate([    (&quot;system&quot;, system),    (&quot;user&quot;, &quot;&#123;question&#125;&quot;)])model  = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)df = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)tool = PythonAstREPLTool(locals=&#123;&quot;df&quot;: df&#125;)llm_with_tools = model.bind_tools([tool])parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)chain = prompt | llm_with_tools | parser | toolprint(chain.invoke(&#123;&quot;question&quot;: &quot;请帮我计算MonthlyCharges字段的均值。&quot;&#125;))\n\n同时，按照此前介绍的，我们还可以在链条中加入一个打印的环节，让模型将编写的Python代码进行打印：\nimport pandas as pd  # 用于数据处理和分析的核心库from langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnableLambdafrom langchain_experimental.tools import PythonAstREPLTool  # LangChain的实验性工具，允许安全执行Python代码from langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParserfrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)system = f&quot;&quot;&quot;你可以访问一个名为 `df` 的 pandas 数据框，你可以使用df.head().to_markdown() 查看数据集的基本信息， \\请根据用户提出的问题，编写 Python 代码来回答。只返回代码，不返回其他内容。只允许使用 pandas 和内置库。&quot;&quot;&quot;prompt = ChatPromptTemplate([    (&quot;system&quot;, system),    (&quot;user&quot;, &quot;&#123;question&#125;&quot;)])model  = init_chat_model(model=&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)df = pd.read_csv(&#x27;WA_Fn-UseC_-Telco-Customer-Churn.csv&#x27;)tool = PythonAstREPLTool(locals=&#123;&quot;df&quot;: df&#125;)llm_with_tools = model.bind_tools([tool])parser = JsonOutputKeyToolsParser(key_name=tool.name, first_tool_only=True)def code_print(res):    print(&quot;即将运行Python代码:&quot;, res[&#x27;query&#x27;])    return resprint_node = RunnableLambda(code_print)chain = prompt | llm_with_tools | parser | print_node | toolprint(chain.invoke(&#123;&quot;question&quot;: &quot;请帮我分析gender、SeniorCitizen和Churn三个字段之间的相关关系。&quot;&#125;))\n\n至此，一个简单的包含官方内置工具的代码解释器工作流就搭建完成了。\n接下来是LangChain接入自定义外部工作流程\n这里我们以实时获取天气数据为例，尝试创建一个外部函数，并将其封装为LangChian的一项基础工作。在langChain中，如果想要把一个普通的函数，变成一个可以被大模型调用的工具，只需要将函数包装成一个Tool对象即可。\n这里我们首先需要获取OpenWeather API Key，并写入.env文件中，方便后续进行天气查询\n浏览器访问openweathermap官方网站\n接着注册并绑定邮箱\n最后进入openweathermap官方网站，点击你的用户名，选择“My API keys”，即可获取OpenWeather API Key\n然后先尝试创建这个外部函数进行测试：\nimport osimport requests,jsonfrom dotenv import load_dotenvload_dotenv(override=True)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)print(&quot;Loaded API Key:&quot;, OPENWEATHER_API_KEY)  # 检查是否非Nonedef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)print(get_weather(&quot;Beijing&quot;))\n\n注意：如果返回401，请不要惊慌，因为API Key会过一会儿生效，时间一般在一小时内\n紧接着将其封装为LangChain能够识别的外部函数，并且如果想让大模型调用某一个外部工具，需要使用bind_tools方法，将工具绑定到模型上。接下来，便可以通过新的llm_with_tools模型通过invoke方法来调用模型。这会产生一个包含tool_calls 的模型响应。代码如下：\nimport osimport requests,jsonfrom langchain.chat_models import init_chat_modelfrom langchain_core.tools import toolfrom dotenv import load_dotenvload_dotenv(override=True)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)print(&quot;Loaded API Key:&quot;, OPENWEATHER_API_KEY)  # 检查是否非None@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)print(get_weather.name)print(get_weather.description)print(get_weather.args)# 定义 天气查询 工具函数tools = [get_weather]# 将工具绑定到模型llm_with_tools = model.bind_tools(tools)response = llm_with_tools.invoke(&quot;你好， 请问北京的天气怎么样？&quot;)print(response)print(response.additional_kwargs)\n\n我们继续调用JsonOutputKeyToolsParser输出解析器来处理模型响应。并加入一个tool外部函数的环节，即可让大模型输出的参数直接带入到tool中进行运行，就能顺利的将用户的需求转化为天气查询，并完成外部工具完成自动运行\nimport osimport requests,jsonfrom langchain.chat_models import init_chat_modelfrom langchain_core.tools import toolfrom langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParserfrom dotenv import load_dotenvload_dotenv(override=True)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)print(&quot;Loaded API Key:&quot;, OPENWEATHER_API_KEY)  # 检查是否非None@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)print(get_weather.name)print(get_weather.description)print(get_weather.args)# 定义 天气查询 工具函数tools = [get_weather]# 将工具绑定到模型llm_with_tools = model.bind_tools(tools)parser = JsonOutputKeyToolsParser(key_name=get_weather.name, first_tool_only=True)llm_chain = llm_with_tools | parserget_weather_chain = llm_with_tools | parser | get_weatherresponse = get_weather_chain.invoke(&quot;你好， 请问北京的天气怎么样？&quot;)print(response)\n\n能够看到，此时Chain就能顺利的将用户的需求转化为天气查询，并完成外部工具的自动运行。但只有这一步还不够，我们还需要将调用工具返回的结果转化为一个模型的问答：\nimport osimport requests,jsonfrom langchain.chat_models import init_chat_modelfrom langchain_core.tools import toolfrom langchain_core.output_parsers.openai_tools import JsonOutputKeyToolsParserfrom langchain.prompts import PromptTemplatefrom langchain_core.output_parsers import StrOutputParserfrom langchain.prompts import PromptTemplatefrom langchain_core.output_parsers import StrOutputParserfrom dotenv import load_dotenvload_dotenv(override=True)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)print(&quot;Loaded API Key:&quot;, OPENWEATHER_API_KEY)  # 检查是否非None@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)print(get_weather.name)print(get_weather.description)print(get_weather.args)# 定义 天气查询 工具函数tools = [get_weather]# 将工具绑定到模型llm_with_tools = model.bind_tools(tools)parser = JsonOutputKeyToolsParser(key_name=get_weather.name, first_tool_only=True)get_weather_chain = llm_with_tools | parser | get_weather# Prompt 模板output_prompt = PromptTemplate.from_template(    &quot;&quot;&quot;你将收到一段 JSON 格式的天气数据，请用简洁自然的方式将其转述给用户。以下是天气 JSON 数据：```json&#123;weather_json&#125;```请将其转换为中文天气描述，例如：“北京当前天气晴，气温为 23°C，湿度 58%，风速 2.1 米/秒。”只返回一句话描述，不要其他说明或解释。&quot;&quot;&quot;)output_chain = output_prompt | model | StrOutputParser()full_chain = get_weather_chain | output_chainresponse = full_chain.invoke(&quot;请问北京今天的天气如何？&quot;)print(response)\n\n最终，我们将这两个Chain进行拼接，即构成完整的外部工具调用流程。\n接着，我们来了解一下LangChain接入自定义外部工作流程\n首先要了解一下 Function calling 基本原理\n我们都知道，能调用外部工具，是大模型进化为智能体Agent的关键，如果不能使用外部工具，大模型就只能是个简单的聊天机器人，甚至连查询天气都做不到。由于底层技术限制啊，大模型本身是无法和外部工具直接通信的，因此Function calling的思路，就是创建一个外部函数（function）作为中介，一边传递大模型的请求，另一边调用外部工具，最终让大模型能够间接的调用外部工具。\n\n例如，当我们要查询当前天气时，让大模型调用外部工具的function calling的过程就如图所示：\n\n而完整的一次Function calling执行流程如下：\n\nDeepSeek function calling 的三种响应模式：\n\n在实际使用中，我们其实可以直接使用create_tool_calling_agent来快速构建工具调用代理。并使用AgentExecutor来执行代理，代码如下：\nimport jsonimport osimport requestsfrom langchain.agents import create_tool_calling_agent, tool, AgentExecutorfrom langchain_core.prompts import ChatPromptTemplatefrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)#定义工具tools = [get_weather]# 构建提示模版prompt = ChatPromptTemplate.from_messages(    [        (&quot;system&quot;, &quot;你是天气助手，请根据用户的问题，给出相应的天气信息&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])# 直接使用`create_tool_calling_agent`创建代理agent = create_tool_calling_agent(model, tools, prompt)# 使用`AgentExecutor`来执行代理agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)response = agent_executor.invoke(&#123;&quot;input&quot;: &quot;请问今天北京的天气怎么样？&quot;&#125;)print(response)print(response[&quot;output&quot;])\n\nLangChain 中Agents模块的整体架构设计。如下所示：\n\n在Agents的内部结构。每个Agent组件一般会由语言模型 + 提示 + 输出解析器构成，它会作为Agents的大脑去处理用户的输入。Agent能够处理的输入主要来源于三个方面：input代表用户的原始输入，Model Response指的是模型对某一个子任务的响应输出，而History则能携带上下文的信息。其输出部分，则链接到实际的工具库，需要调用哪些工具，将由经过Agent模块后拆分的子任务来决定。\n而我们知道，大模型调用外部函数会分为两个过程：识别工具和实际执行。在 Message -&gt; Agent -&gt; Toolkits 这个流程中，负责的是将子任务拆解，然后根据这些子任务在工具库中找到相应的工具，提取工具名称及所需参数，这个过程可以视作一种“静态”的执行流程。而将这些决策转化为实际行动的工作，则会交给AgentExecutor。\n所以综上需要理解的是：在LangChain的Agents实际架构中，Agent的角色是接收输入并决定采取的操作，但它本身并不直接执行这些操作。这一任务是由AgentExecutor来完成的。将Agent（决策大脑）与AgentExecutor（执行操作的Runtime）结合使用，才构成了完整的Agents（智能体），其中AgentExecutor负责调用代理并执行指定的工具，以此来实现整个智能体的功能。\n这也就是为什么create_tool_calling_agent需要通过AgentExecutor才能够实际运行的原因。当然，在这种模式下，**AgentExecutor的内部已经自动处理好了关于我们工具调用的所有逻辑，其中包含串行和并行工具调用的两种常用模式。**\n在大模型中，并行工具调用指的是在大模型调用外部工具时，可以在单次交互过程中可以同时调用多个工具，并行执行以解决用户的问题。如下图所示：\n\n而在create_tool_calling_agent中，已经自动处理了并行工具调用的处理逻辑，并不需要我们在手动处理，比如接下来测试一些复杂的问题：\nimport jsonimport osimport requestsfrom langchain.agents import create_tool_calling_agent, tool, AgentExecutorfrom langchain_core.prompts import ChatPromptTemplatefrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)#定义工具tools = [get_weather]# 构建提示模版prompt = ChatPromptTemplate.from_messages(    [        (&quot;system&quot;, &quot;你是天气助手，请根据用户的问题，给出相应的天气信息&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])# 直接使用`create_tool_calling_agent`创建代理agent = create_tool_calling_agent(model, tools, prompt)# 使用`AgentExecutor`来执行代理agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)response = agent_executor.invoke(&#123;&quot;input&quot;: &quot;请问今天北京和杭州的天气怎么样，哪个城市更热？&quot;&#125;)print(response[&quot;output&quot;])\n\n从这个过程中可以明显的看出，一次性发起了同一个外部函数的两次调用请求，并依次获得了北京和杭州两个城市的天气。这就是一次标准的parallel_function_call。\n\n接下来继续尝试进行多工具串联调用测试：\n\n此时我们再定义一个write_file函数，用于将“文本写入本地”，然后在tools列表中直接添加write_file工具，并修改提示模版，添加write_file工具的使用场景。代码如下所示： \nimport jsonimport osimport requestsfrom langchain.agents import create_tool_calling_agent, tool, AgentExecutorfrom langchain_core.prompts import ChatPromptTemplatefrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)OPENWEATHER_API_KEY = os.getenv(&quot;OPENWEATHER_API_KEY&quot;)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)@tooldef get_weather(loc):    &quot;&quot;&quot;    查询即时天气函数    :param loc: 必要参数，字符串类型，用于表示查询天气的具体城市名称，\\    注意，中国的城市需要用对应城市的英文名称代替，例如如果需要查询北京市天气，则loc参数需要输入&#x27;Beijing&#x27;；    :return：OpenWeather API查询即时天气的结果，具体URL请求地址为：https://api.openweathermap.org/data/2.5/weather\\    返回结果对象类型为解析之后的JSON格式对象，并用字符串形式进行表示，其中包含了全部重要的天气信息    &quot;&quot;&quot;    # Step 1.构建请求    url = &quot;https://api.openweathermap.org/data/2.5/weather&quot;    # Step 2.设置查询参数    params = &#123;        &quot;q&quot;: loc,        &quot;appid&quot;: os.getenv(&quot;OPENWEATHER_API_KEY&quot;),  # 输入API key        &quot;units&quot;: &quot;metric&quot;,  # 使用摄氏度而不是华氏度        &quot;lang&quot;: &quot;zh_cn&quot;  # 输出语言为简体中文    &#125;    # Step 3.发送GET请求    response = requests.get(url, params=params)    # Step 4.解析响应    data = response.json()    return json.dumps(data)@tooldef write_file(content):    &quot;&quot;&quot;    将指定内容写入本地文件。    :param content: 必要参数，字符串类型，用于表示需要写入文档的具体内容。    :return：是否成功写入    &quot;&quot;&quot;    return &quot;已成功写入本地文件。&quot;#定义工具tools = [get_weather, write_file]# 构建提示模版prompt = ChatPromptTemplate.from_messages(    [        (&quot;system&quot;, &quot;你是天气助手，请根据用户的问题，给出相应的天气信息，如果用户需要将查询结果写入文件，请使用write_file工具&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])# 直接使用`create_tool_calling_agent`创建代理agent = create_tool_calling_agent(model, tools, prompt)# 使用`AgentExecutor`来执行代理agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)response = agent_executor.invoke(&#123;&quot;input&quot;: &quot;查一下北京和杭州现在的温度，并将结果写入本地的文件中。&quot;&#125;)print(response[&quot;output&quot;])\n\n通过中间过程信息的打印，我们能够看到在一次交互过程中依次调用的get_weather查询到北京和杭州的天气，然后又将结果写入到本地的文件中。这就是一个非常典型的串行工具调用的流程，如下图所示：\n\n五、LangChain Agent进阶功能介绍借助LangChain Agent+内置工具快速搭建智能体\n既然LangChain Agent能更加灵活调用外部工具，LangChain Agent+LangChain内置工具也能更加快速的完成复杂Agent开发。\nLangChain 第三方工具集成\n下面选择以LangChain 的 Tavily Search 工具为例进行讲解\n可以通过访问此站点创建一个帐户来获取LangChain 的 Tavily Search 工具的 API 密钥，并将其加到.env文件中\nTAVILY_API_KEY=tvly-xxx\n\nlangchain-tavily集成存在于包中\npip install -U langchain-tavily\n\n先编写一个简单的程序验证该工具能正常运行\nimport osfrom langchain_tavily import TavilySearchfrom dotenv import load_dotenvload_dotenv(override=True)# 初始化 Tavily 搜索工具search = TavilySearch(max_results=2)# 执行搜索result = search.invoke(&quot;苹果2025WWDC发布会&quot;)print(result)\n\n再使用LangChain Agent配合LangChain内置的Tavily Search工具快速地完成复杂Agent开发\nimport osfrom langchain_tavily import TavilySearchfrom langchain.agents import AgentExecutor, create_tool_calling_agent, toolfrom langchain_core.prompts import ChatPromptTemplatefrom langchain.chat_models import init_chat_modelfrom dotenv import load_dotenvload_dotenv(override=True)# 初始化 Tavily 搜索工具search = TavilySearch(max_results=2)tools = [search]prompt = ChatPromptTemplate.from_messages(    [        (&quot;system&quot;, &quot;你是一名助人为乐的助手，并且可以调用工具进行网络搜索，获取实时信息。&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)agent = create_tool_calling_agent(model, tools, prompt)agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)result = agent_executor.invoke(&#123;&quot;input&quot;: &quot;请问苹果2025WWDC发布会召开的时间是？&quot;&#125;)print(result[&#x27;output&#x27;])\n\n接着我们来完成多智能体协作实现浏览器自动化\n正如上述我们使用的create_tool_calling_agent方法，它其实在langChain中是一个通用的用来构建工具代理的方法，除此以外，langChain还封装了非常多种不同的Agent实现形式\n下面是推荐的Agent创建函数：\n\n\n\n函数名\n功能描述\n适用场景\n\n\n\ncreate_tool_calling_agent\n创建使用工具的Agent\n通用工具调用\n\n\ncreate_openai_tools_agent\n创建OpenAI工具Agent\nOpenAI模型专用\n\n\ncreate_openai_functions_agent\n创建OpenAI函数Agent\nOpenAI函数调用\n\n\ncreate_react_agent\n创建ReAct推理Agent\n推理+行动模式\n\n\ncreate_structured_chat_agent\n创建结构化聊天Agent\n多输入工具支持\n\n\ncreate_conversational_retrieval_agent\n创建对话检索Agent\n检索增强对话\n\n\ncreate_json_chat_agent\n创建JSON聊天Agent\nJSON格式交互\n\n\ncreate_xml_agent\n创建XML格式Agent\nXML逻辑格式\n\n\ncreate_self_ask_with_search_agent\n创建自问自答搜索Agent\n自主搜索推理\n\n\n其中比较通用场景的就是我们刚刚使用的create_tool_calling_agent，而对于一些符合OpenAI API RESTFUL API的模型，则同样可以使用create_openai_tools_agent，另外像create_react_agent可以用于一些推理任务，create_conversational_retrieval_agent则可以用于一些对话系统，具体还是需要根据实际需求来选择。\n目前来说，在大模型应用开发领域有非常多的需求场景，其中一个比较热门的就是浏览器自动化，通过自动化提取网页内容，然后进行分析，最后生成报告。这样的流程提升效率和收集信息的有效途径。因此接下来，我们就尝试使用尝试使用create_openai_tools_agent来实际开发一个浏览器自动化代理。\n首先，执行浏览器自动化代理需要安装一系列的第三方依赖包，如下所示：\npip install playwright lxml langchain_community beautifulsoup4 reportlab\n\n此外，还需要安装 Playwright 浏览器，需要在当前虚拟环境中执行如下命令：\nplaywright install\n\n这个安装过程它会下载并安装 Playwright 支持的浏览器内核（注意：这里不是用我们本机已有的浏览器），包括Chromium（类似 Chrome）、Firefox、WebKit（类似 Safari），并将这些浏览器下载到本地的 .cache/ms-playwright 目录或项目的 ~/.playwright 目录中，以便 Playwright 使用稳定一致的运行环境。\n这个案例的核心代码首先是需要用代理工具初始化同步 Playwright 浏览器：\nsync_browser = create_sync_playwright_browser()toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser)tools = toolkit.get_tools()\n\n然后再通过create_openai_tools_agent接收初始化的大模型和Playwright工具构建共同构建OpenAI Tools 代理，最后通过AgentExecutor执行代理。\n# 通过 LangChain 创建 OpenAI 工具代理agent = create_openai_tools_agent(model, tools, prompt)# 通过 AgentExecutor 执行代理agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n\n完整的代码因为langChian的模块化封装非常简洁，如下所示：\nfrom langchain_community.agent_toolkits import PlayWrightBrowserToolkitfrom langchain_community.tools.playwright.utils import create_sync_playwright_browserfrom langchain import hubfrom langchain.agents import AgentExecutor, create_openai_tools_agentfrom langchain.chat_models import init_chat_modelimport osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot;)# print(DeepSeek_API_KEY)  # 可以通过打印查看# 初始化 Playwright 浏览器：sync_browser = create_sync_playwright_browser()toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser)tools = toolkit.get_tools()# 通过 LangChain Hub 拉取提示词模版# https://smith.langchain.com/hub# 这是 LangChain 中从 LangChain Hub 加载预定义提示词模板（prompt template）的操作# &quot;hwchase17/openai-tools-agent&quot; 是 LangChain 官方维护的一个标准提示词模板，专为 OpenAI 工具调用型 Agent 设计prompt = hub.pull(&quot;hwchase17/openai-tools-agent&quot;)# 初始化模型model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 通过 LangChain 创建 OpenAI 工具代理agent = create_openai_tools_agent(model, tools, prompt)# 通过 AgentExecutor 执行代理agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)if __name__ == &quot;__main__&quot;:    # 定义任务    command = &#123;        &quot;input&quot;: &quot;访问这个网站 https://blogroll.naosi.org/ 并用中文帮我总结一下这个网站的内容&quot;    &#125;    # 执行任务    response = agent_executor.invoke(command)    print(response[&#x27;output&#x27;])\n\n更进一步地，我们还可以将Playwright Agent封装成工具函数，并结合LangChain的LCEL串行链，实现一个更加复杂的浏览器自动化代理。这里定义的工具如下所示：\n# 1. 创建网站总结工具@tooldef summarize_website(url: str) -&gt; str:    &quot;&quot;&quot;访问指定网站并返回内容总结&quot;&quot;&quot;    try:        # 创建浏览器实例        sync_browser = create_sync_playwright_browser()        toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser)        tools = toolkit.get_tools()        # 初始化模型和Agent        model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)        prompt = hub.pull(&quot;hwchase17/openai-tools-agent&quot;)        agent = create_openai_tools_agent(model, tools, prompt)        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)        # 执行总结任务        command = &#123;            &quot;input&quot;: f&quot;访问这个网站 &#123;url&#125; 并帮我详细总结一下这个网站的内容，包括主要功能、特点和使用方法&quot;        &#125;        result = agent_executor.invoke(command)        return result.get(&quot;output&quot;, &quot;无法获取网站内容总结&quot;)    except Exception as e:        return f&quot;网站访问失败: &#123;str(e)&#125;&quot;# 2. 创建PDF生成工具@tooldef generate_pdf(content: str) -&gt; str:    &quot;&quot;&quot;将文本内容生成为PDF文件&quot;&quot;&quot;    try:        # 生成文件名（带时间戳）        timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)        filename = f&quot;website_summary_&#123;timestamp&#125;.pdf&quot;        # 创建PDF文档        doc = SimpleDocTemplate(filename, pagesize=A4)        styles = getSampleStyleSheet()        # 注册中文字体（如果系统有的话）        try:            # Windows 系统字体路径            font_paths = [                &quot;C:/Windows/Fonts/simhei.ttf&quot;,  # 黑体                &quot;C:/Windows/Fonts/simsun.ttc&quot;,  # 宋体                &quot;C:/Windows/Fonts/msyh.ttc&quot;,  # 微软雅黑            ]            chinese_font_registered = False            for font_path in font_paths:                if os.path.exists(font_path):                    try:                        pdfmetrics.registerFont(TTFont(&#x27;ChineseFont&#x27;, font_path))                        chinese_font_registered = True                        print(f&quot;✅ 成功注册中文字体: &#123;font_path&#125;&quot;)                        break                    except:                        continue            if not chinese_font_registered:                print(&quot;⚠️ 未找到中文字体，使用默认字体&quot;)        except Exception as e:            print(f&quot;⚠️ 字体注册失败: &#123;e&#125;&quot;)        # 自定义样式 - 支持中文        title_style = ParagraphStyle(            &#x27;CustomTitle&#x27;,            parent=styles[&#x27;Heading1&#x27;],            fontSize=18,            alignment=TA_CENTER,            spaceAfter=30,            fontName=&#x27;ChineseFont&#x27; if &#x27;chinese_font_registered&#x27; in locals() and chinese_font_registered else &#x27;Helvetica-Bold&#x27;        )        content_style = ParagraphStyle(            &#x27;CustomContent&#x27;,            parent=styles[&#x27;Normal&#x27;],            fontSize=11,            alignment=TA_JUSTIFY,            leftIndent=20,            rightIndent=20,            spaceAfter=12,            fontName=&#x27;ChineseFont&#x27; if &#x27;chinese_font_registered&#x27; in locals() and chinese_font_registered else &#x27;Helvetica&#x27;        )        # 构建PDF内容        story = []        # 标题        story.append(Paragraph(&quot;网站内容总结报告&quot;, title_style))        story.append(Spacer(1, 20))        # 生成时间        time_text = f&quot;生成时间: &#123;datetime.now().strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;)&#125;&quot;        story.append(Paragraph(time_text, styles[&#x27;Normal&#x27;]))        story.append(Spacer(1, 20))        # 分隔线        story.append(Paragraph(&quot;=&quot; * 50, styles[&#x27;Normal&#x27;]))        story.append(Spacer(1, 15))        # 主要内容 - 改进中文处理        if content:            # 清理和处理内容            content = content.replace(&#x27;\\r\\n&#x27;, &#x27;\\n&#x27;).replace(&#x27;\\r&#x27;, &#x27;\\n&#x27;)            paragraphs = content.split(&#x27;\\n&#x27;)            for para in paragraphs:                if para.strip():                    # 处理特殊字符，确保PDF可以正确显示                    clean_para = para.strip()                    # 转换HTML实体                    clean_para = clean_para.replace(&#x27;&amp;lt;&#x27;, &#x27;&lt;&#x27;).replace(&#x27;&amp;gt;&#x27;, &#x27;&gt;&#x27;).replace(&#x27;&amp;amp;&#x27;, &#x27;&amp;&#x27;)                    try:                        story.append(Paragraph(clean_para, content_style))                        story.append(Spacer(1, 8))                    except Exception as para_error:                        # 如果段落有问题，尝试用默认字体                        try:                            fallback_style = ParagraphStyle(                                &#x27;Fallback&#x27;,                                parent=styles[&#x27;Normal&#x27;],                                fontSize=10,                                leftIndent=20,                                rightIndent=20,                                spaceAfter=10                            )                            story.append(Paragraph(clean_para, fallback_style))                            story.append(Spacer(1, 8))                        except:                            # 如果还是有问题，记录错误但继续                            print(f&quot;⚠️ 段落处理失败: &#123;clean_para[:50]&#125;...&quot;)                            continue        else:            story.append(Paragraph(&quot;暂无内容&quot;, content_style))        # 页脚信息        story.append(Spacer(1, 30))        story.append(Paragraph(&quot;=&quot; * 50, styles[&#x27;Normal&#x27;]))        story.append(Paragraph(&quot;本报告由 Playwright PDF Agent 自动生成&quot;, styles[&#x27;Italic&#x27;]))        # 生成PDF        doc.build(story)        # 获取绝对路径        abs_path = os.path.abspath(filename)        print(f&quot;📄 PDF文件生成完成: &#123;abs_path&#125;&quot;)        return f&quot;PDF文件已成功生成: &#123;abs_path&#125;&quot;    except Exception as e:        error_msg = f&quot;PDF生成失败: &#123;str(e)&#125;&quot;        print(error_msg)        return error_msg\n\n然后我们可以自定义不同的链路，比如简单的串行链由Playwright Agent和 generate_pdf Agent组成，即先爬取网页的内容，然后将网页中的内容写入到本地的PDF文件中。\n# 方法1：简单串行链simple_chain = summarize_website | generate_pdf\n\n除此以外，我们还可以再定一个摘要工具，在使用Playwright工具访问网页后，根据爬取到的网页内容先使用大模型进行摘要总结，再调用generate_pdf工具将总结内容写入到本地的PDF文件中。代码如下所示：\noptimization_prompt = ChatPromptTemplate.from_template(    &quot;&quot;&quot;请优化以下网站总结内容，使其更适合PDF报告格式：    原始总结：    &#123;summary&#125;    请重新组织内容，包括：    1. 清晰的标题和结构    2. 要点总结    3. 详细说明    4. 使用要求等    优化后的内容：&quot;&quot;&quot;)model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 带优化的串行链：网站总结 → LLM优化 → PDF生成optimized_chain = (    summarize_website     | (lambda summary: &#123;&quot;summary&quot;: summary&#125;)    | optimization_prompt     | model     | StrOutputParser()     | generate_pdf)\n\n完整的代码如下所示：\nfrom langchain_community.agent_toolkits import PlayWrightBrowserToolkitfrom langchain_community.tools.playwright.utils import create_sync_playwright_browserfrom langchain import hubfrom langchain.agents import AgentExecutor, create_openai_tools_agentfrom langchain.chat_models import init_chat_modelfrom langchain_core.tools import toolfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.output_parsers import StrOutputParserfrom reportlab.lib.pagesizes import letter, A4from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacerfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStylefrom reportlab.lib.enums import TA_JUSTIFY, TA_CENTERfrom reportlab.pdfbase import pdfmetricsfrom reportlab.pdfbase.ttfonts import TTFontimport osfrom datetime import datetimeimport osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot;)# 1. 创建网站总结工具@tooldef summarize_website(url: str) -&gt; str:    &quot;&quot;&quot;访问指定网站并返回内容总结&quot;&quot;&quot;    try:        # 创建浏览器实例        sync_browser = create_sync_playwright_browser()        toolkit = PlayWrightBrowserToolkit.from_browser(sync_browser=sync_browser)        tools = toolkit.get_tools()        # 初始化模型和Agent        model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)        prompt = hub.pull(&quot;hwchase17/openai-tools-agent&quot;)        agent = create_openai_tools_agent(model, tools, prompt)        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False)        # 执行总结任务        command = &#123;            &quot;input&quot;: f&quot;访问这个网站 &#123;url&#125; 并帮我详细总结一下这个网站的内容，包括主要功能、特点和使用方法&quot;        &#125;        result = agent_executor.invoke(command)        return result.get(&quot;output&quot;, &quot;无法获取网站内容总结&quot;)    except Exception as e:        return f&quot;网站访问失败: &#123;str(e)&#125;&quot;# 2. 创建PDF生成工具@tooldef generate_pdf(content: str) -&gt; str:    &quot;&quot;&quot;将文本内容生成为PDF文件&quot;&quot;&quot;    try:        # 生成文件名（带时间戳）        timestamp = datetime.now().strftime(&quot;%Y%m%d_%H%M%S&quot;)        filename = f&quot;website_summary_&#123;timestamp&#125;.pdf&quot;        # 创建PDF文档        doc = SimpleDocTemplate(filename, pagesize=A4)        styles = getSampleStyleSheet()        # 注册中文字体（如果系统有的话）        try:            # Windows 系统字体路径            font_paths = [                &quot;C:/Windows/Fonts/simhei.ttf&quot;,  # 黑体                &quot;C:/Windows/Fonts/simsun.ttc&quot;,  # 宋体                &quot;C:/Windows/Fonts/msyh.ttc&quot;,  # 微软雅黑            ]            chinese_font_registered = False            for font_path in font_paths:                if os.path.exists(font_path):                    try:                        pdfmetrics.registerFont(TTFont(&#x27;ChineseFont&#x27;, font_path))                        chinese_font_registered = True                        print(f&quot;✅ 成功注册中文字体: &#123;font_path&#125;&quot;)                        break                    except:                        continue            if not chinese_font_registered:                print(&quot;⚠️ 未找到中文字体，使用默认字体&quot;)        except Exception as e:            print(f&quot;⚠️ 字体注册失败: &#123;e&#125;&quot;)        # 自定义样式 - 支持中文        title_style = ParagraphStyle(            &#x27;CustomTitle&#x27;,            parent=styles[&#x27;Heading1&#x27;],            fontSize=18,            alignment=TA_CENTER,            spaceAfter=30,            fontName=&#x27;ChineseFont&#x27; if &#x27;chinese_font_registered&#x27; in locals() and chinese_font_registered else &#x27;Helvetica-Bold&#x27;        )        content_style = ParagraphStyle(            &#x27;CustomContent&#x27;,            parent=styles[&#x27;Normal&#x27;],            fontSize=11,            alignment=TA_JUSTIFY,            leftIndent=20,            rightIndent=20,            spaceAfter=12,            fontName=&#x27;ChineseFont&#x27; if &#x27;chinese_font_registered&#x27; in locals() and chinese_font_registered else &#x27;Helvetica&#x27;        )        # 构建PDF内容        story = []        # 标题        story.append(Paragraph(&quot;网站内容总结报告&quot;, title_style))        story.append(Spacer(1, 20))        # 生成时间        time_text = f&quot;生成时间: &#123;datetime.now().strftime(&#x27;%Y-%m-%d %H:%M:%S&#x27;)&#125;&quot;        story.append(Paragraph(time_text, styles[&#x27;Normal&#x27;]))        story.append(Spacer(1, 20))        # 分隔线        story.append(Paragraph(&quot;=&quot; * 50, styles[&#x27;Normal&#x27;]))        story.append(Spacer(1, 15))        # 主要内容 - 改进中文处理        if content:            # 清理和处理内容            content = content.replace(&#x27;\\r\\n&#x27;, &#x27;\\n&#x27;).replace(&#x27;\\r&#x27;, &#x27;\\n&#x27;)            paragraphs = content.split(&#x27;\\n&#x27;)            for para in paragraphs:                if para.strip():                    # 处理特殊字符，确保PDF可以正确显示                    clean_para = para.strip()                    # 转换HTML实体                    clean_para = clean_para.replace(&#x27;&amp;lt;&#x27;, &#x27;&lt;&#x27;).replace(&#x27;&amp;gt;&#x27;, &#x27;&gt;&#x27;).replace(&#x27;&amp;amp;&#x27;, &#x27;&amp;&#x27;)                    try:                        story.append(Paragraph(clean_para, content_style))                        story.append(Spacer(1, 8))                    except Exception as para_error:                        # 如果段落有问题，尝试用默认字体                        try:                            fallback_style = ParagraphStyle(                                &#x27;Fallback&#x27;,                                parent=styles[&#x27;Normal&#x27;],                                fontSize=10,                                leftIndent=20,                                rightIndent=20,                                spaceAfter=10                            )                            story.append(Paragraph(clean_para, fallback_style))                            story.append(Spacer(1, 8))                        except:                            # 如果还是有问题，记录错误但继续                            print(f&quot;⚠️ 段落处理失败: &#123;clean_para[:50]&#125;...&quot;)                            continue        else:            story.append(Paragraph(&quot;暂无内容&quot;, content_style))        # 页脚信息        story.append(Spacer(1, 30))        story.append(Paragraph(&quot;=&quot; * 50, styles[&#x27;Normal&#x27;]))        story.append(Paragraph(&quot;本报告由 Playwright PDF Agent 自动生成&quot;, styles[&#x27;Italic&#x27;]))        # 生成PDF        doc.build(story)        # 获取绝对路径        abs_path = os.path.abspath(filename)        print(f&quot;📄 PDF文件生成完成: &#123;abs_path&#125;&quot;)        return f&quot;PDF文件已成功生成: &#123;abs_path&#125;&quot;    except Exception as e:        error_msg = f&quot;PDF生成失败: &#123;str(e)&#125;&quot;        print(error_msg)        return error_msg# 3. 创建串行链print(&quot;=== 创建串行链：网站总结 → PDF生成 ===&quot;)# 方法1：简单串行链simple_chain = summarize_website | generate_pdf# 方法2：带LLM优化的串行链optimization_prompt = ChatPromptTemplate.from_template(    &quot;&quot;&quot;请优化以下网站总结内容，使其更适合PDF报告格式：    原始总结：    &#123;summary&#125;        请重新组织内容，包括：    1. 清晰的标题和结构    2. 要点总结    3. 详细说明    4. 使用要求等        优化后的内容：&quot;&quot;&quot;)model = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 带优化的串行链：网站总结 → LLM优化 → PDF生成optimized_chain = (        summarize_website        | (lambda summary: &#123;&quot;summary&quot;: summary&#125;)        | optimization_prompt        | model        | StrOutputParser()        | generate_pdf)# 4. 测试函数def test_simple_chain(url: str):    &quot;&quot;&quot;测试简单串行链&quot;&quot;&quot;    print(f&quot;\\n🔄 开始处理URL: &#123;url&#125;&quot;)    print(&quot;📝 步骤1: 网站总结...&quot;)    print(&quot;📄 步骤2: 生成PDF...&quot;)    result = simple_chain.invoke(url)    print(f&quot;✅ 完成: &#123;result&#125;&quot;)    return resultdef test_optimized_chain(url: str):    &quot;&quot;&quot;测试优化串行链&quot;&quot;&quot;    print(f&quot;\\n🔄 开始处理URL (优化版): &#123;url&#125;&quot;)    print(&quot;📝 步骤1: 网站总结...&quot;)    print(&quot;🎨 步骤2: 内容优化...&quot;)    print(&quot;📄 步骤3: 生成PDF...&quot;)    result = optimized_chain.invoke(url)    print(f&quot;✅ 完成: &#123;result&#125;&quot;)    return result# 5. 创建交互式函数def create_website_pdf_report(url: str, use_optimization: bool = True):    &quot;&quot;&quot;创建网站PDF报告的主函数&quot;&quot;&quot;    print(&quot;=&quot; * 60)    print(&quot;🤖 网站内容PDF生成器&quot;)    print(&quot;=&quot; * 60)    try:        if use_optimization:            result = test_optimized_chain(url)        else:            result = test_simple_chain(url)        print(&quot;\\n&quot; + &quot;=&quot; * 60)        print(&quot;🎉 任务完成！&quot;)        print(&quot;=&quot; * 60)        return result    except Exception as e:        error_msg = f&quot;❌ 处理失败: &#123;str(e)&#125;&quot;        print(error_msg)        return error_msg# 6. 主程序入口if __name__ == &quot;__main__&quot;:    # 测试URL    test_url = &quot;https://blogroll.naosi.org/&quot;    print(&quot;选择处理方式:&quot;)    print(&quot;1. 简单串行链（直接总结 → PDF）&quot;)    print(&quot;2. 优化串行链（总结 → 优化 → PDF）&quot;)    choice = input(&quot;请选择 (1/2): &quot;).strip()    if choice == &quot;1&quot;:        create_website_pdf_report(test_url, use_optimization=False)    elif choice == &quot;2&quot;:        create_website_pdf_report(test_url, use_optimization=True)    else:        print(&quot;使用默认优化模式...&quot;)        create_website_pdf_report(test_url, use_optimization=True)\n\n这里仅做演示参考，实际生成效果不佳，如需使用后续还需要更精细的调整\n六、LangChain 接入 MCP 技术实现流程MCP，全称是Model Context Protocol，模型上下文协议，由Claude母公司Anthropic于去年11月正式提出。\nAnthropic MCP发布通告\nMCP GitHub主页\nMCP的核心作用，是统一了Agent开发过程中，大模型调用外部工具的技术实现流程，从而大幅提高Agent开发效率。在MCP诞生之前，不同的外部工具各有不同的调用方法，要连接这些外部工具开发Agent，就必须“每一把锁单独配一把钥匙”，开发工作非常繁琐。\n\n而MCP的诞生，则统一了这些外部工具的调用流程，使得无论什么样的工具，都可以借助MCP技术按照统一的一个流程快速接入到大模型中，从而大幅加快Agent开发效率。这就好比现在很多设备都可以使用type-c和电脑连接类似。\n\n从技术实现角度来看，我们可以将MCP看成是Function calling的一种封装，通过server-client架构和一整套开发工具，来规范化Function calling开发流程。\n\n首先来介绍一下MCP基础实现流程\nlangchain-mcp-adapters 项目主要为LangChain和LangGraph提供MCP的接入和兼容接口，其工作流程主要如下图所示：\n\n实际上load_mcp_tools() 返回的是标准的 LangChain 工具，所以是完全可以直接在LangChain环境中进行使用的。同时，完全支持stdio、Http SSE和Streamable HTTP三种不同的通讯协议。\n一个极简的天气查询MCP调用流程如下：\n\n接下来，我们先尝试手动实现一遍MCP实践流程，然后再考虑将已经部署好的server代入其中，作为tools进行调用。\n首先借助uv创建MCP运行环境\n方法 1：使用 pip 安装（适用于已安装 pip 的系统）\npip install uv\n\n方法 2：使用 curl 直接安装\n如果你的系统没有 pip，可以直接运行：\ncurl -LsSf https://astral.sh/uv/install.sh | sh\n\n这会自动下载 uv 并安装到 /usr/local/bin。\n接着创建 MCP 客户端项目\n# 创建项目目录uv init mcp-client# 进入项目目录cd mcp-client\n\n接着创建MCP客户端虚拟环境\n# 创建虚拟环境uv venv# 激活虚拟环境# Linux/macOS环境source .venv/bin/activate# Windows环境.\\.venv\\Scripts\\Activate.ps1# .\\.venv\\Scripts\\activate.bat\n\n然后即可通过add方法在虚拟环境中安装相关的库。\n# 安装 MCP SDKuv add mcp openai python-dotenv httpx\n\n接着编写用于天气查询的server服务器代码：\n这里我们需要在服务器上创建一个weather_server.py，并写入如下代码：\nimport jsonimport httpxfrom typing import Anyfrom mcp.server.fastmcp import FastMCP# 初始化 MCP 服务器mcp = FastMCP(&quot;WeatherServer&quot;)# OpenWeather API 配置OPENWEATHER_API_BASE = &quot;https://api.openweathermap.org/data/2.5/weather&quot;API_KEY = &quot;YOUR_API_KEY&quot;  # 请替换为你自己的 OpenWeather API KeyUSER_AGENT = &quot;weather-app/1.0&quot;async def fetch_weather(city: str) -&gt; dict[str, Any] | None:    &quot;&quot;&quot;    从 OpenWeather API 获取天气信息。    :param city: 城市名称（需使用英文，如 Beijing）    :return: 天气数据字典；若出错返回包含 error 信息的字典    &quot;&quot;&quot;    params = &#123;        &quot;q&quot;: city,        &quot;appid&quot;: API_KEY,        &quot;units&quot;: &quot;metric&quot;,        &quot;lang&quot;: &quot;zh_cn&quot;    &#125;    headers = &#123;&quot;User-Agent&quot;: USER_AGENT&#125;    async with httpx.AsyncClient() as client:        try:            response = await client.get(OPENWEATHER_API_BASE, params=params, headers=headers, timeout=30.0)            response.raise_for_status()            return response.json()  # 返回字典类型        except httpx.HTTPStatusError as e:            return &#123;&quot;error&quot;: f&quot;HTTP 错误: &#123;e.response.status_code&#125;&quot;&#125;        except Exception as e:            return &#123;&quot;error&quot;: f&quot;请求失败: &#123;str(e)&#125;&quot;&#125;def format_weather(data: dict[str, Any] | str) -&gt; str:    &quot;&quot;&quot;    将天气数据格式化为易读文本。    :param data: 天气数据（可以是字典或 JSON 字符串）    :return: 格式化后的天气信息字符串    &quot;&quot;&quot;    # 如果传入的是字符串，则先转换为字典    if isinstance(data, str):        try:            data = json.loads(data)        except Exception as e:            return f&quot;无法解析天气数据: &#123;e&#125;&quot;    # 如果数据中包含错误信息，直接返回错误提示    if &quot;error&quot; in data:        return f&quot;⚠️ &#123;data[&#x27;error&#x27;]&#125;&quot;    # 提取数据时做容错处理    city = data.get(&quot;name&quot;, &quot;未知&quot;)    country = data.get(&quot;sys&quot;, &#123;&#125;).get(&quot;country&quot;, &quot;未知&quot;)    temp = data.get(&quot;main&quot;, &#123;&#125;).get(&quot;temp&quot;, &quot;N/A&quot;)    humidity = data.get(&quot;main&quot;, &#123;&#125;).get(&quot;humidity&quot;, &quot;N/A&quot;)    wind_speed = data.get(&quot;wind&quot;, &#123;&#125;).get(&quot;speed&quot;, &quot;N/A&quot;)    # weather 可能为空列表，因此用 [0] 前先提供默认字典    weather_list = data.get(&quot;weather&quot;, [&#123;&#125;])    description = weather_list[0].get(&quot;description&quot;, &quot;未知&quot;)    return (        f&quot;🌍 &#123;city&#125;, &#123;country&#125;\\n&quot;        f&quot;🌡 温度: &#123;temp&#125;°C\\n&quot;        f&quot;💧 湿度: &#123;humidity&#125;%\\n&quot;        f&quot;🌬 风速: &#123;wind_speed&#125; m/s\\n&quot;        f&quot;🌤 天气: &#123;description&#125;\\n&quot;    )@mcp.tool()async def query_weather(city: str) -&gt; str:    &quot;&quot;&quot;    输入指定城市的英文名称，返回今日天气查询结果。    :param city: 城市名称（需使用英文）    :return: 格式化后的天气信息    &quot;&quot;&quot;    data = await fetch_weather(city)    return format_weather(data)if __name__ == &quot;__main__&quot;:    # 以标准 I/O 方式运行 MCP 服务器    mcp.run(transport=&#x27;stdio&#x27;)\n\n为了更好的测试多MCP工具调用流程，这里我们继续创建一个write_server.py服务器：\nimport jsonimport httpxfrom typing import Anyfrom mcp.server.fastmcp import FastMCP# 初始化 MCP 服务器mcp = FastMCP(&quot;WriteServer&quot;)USER_AGENT = &quot;write-app/1.0&quot;@mcp.tool()async def write_file(content: str) -&gt; str:    &quot;&quot;&quot;    将指定内容写入本地文件。    :param content: 必要参数，字符串类型，用于表示需要写入文档的具体内容。    :return：是否成功写入    &quot;&quot;&quot;    return &quot;已成功写入本地文件。&quot;if __name__ == &quot;__main__&quot;:    # 以标准 I/O 方式运行 MCP 服务器    mcp.run(transport=&#x27;stdio&#x27;)\n\n然后创建一个可以和server进行通信的客户端\n需要注意的是，该客户端需要包含大模型调用的基础信息。我们需要编写一个client.py脚本，这个脚本内容非常复杂，这里提供的是通用的mcp客户端脚本，还未接入Langchain，代码如下：\nimport asyncioimport jsonimport loggingimport osimport shutilfrom contextlib import AsyncExitStackfrom typing import Any, Dict, List, Optionalimport httpxfrom dotenv import load_dotenvfrom openai import OpenAI  # OpenAI Python SDKfrom mcp import ClientSession, StdioServerParametersfrom mcp.client.stdio import stdio_client# Configure logginglogging.basicConfig(    level=logging.INFO, format=&quot;%(asctime)s - %(levelname)s - %(message)s&quot;)# =============================# 配置加载类（支持环境变量及配置文件）# =============================class Configuration:    &quot;&quot;&quot;管理 MCP 客户端的环境变量和配置文件&quot;&quot;&quot;    def __init__(self) -&gt; None:        load_dotenv()        # 从环境变量中加载 API key, base_url 和 model        self.api_key = os.getenv(&quot;LLM_API_KEY&quot;)        self.base_url = os.getenv(&quot;BASE_URL&quot;)        self.model = os.getenv(&quot;MODEL&quot;)        if not self.api_key:            raise ValueError(&quot;❌ 未找到 LLM_API_KEY，请在 .env 文件中配置&quot;)    @staticmethod    def load_config(file_path: str) -&gt; Dict[str, Any]:        &quot;&quot;&quot;        从 JSON 文件加载服务器配置                Args:            file_path: JSON 配置文件路径                Returns:            包含服务器配置的字典        &quot;&quot;&quot;        with open(file_path, &quot;r&quot;) as f:            return json.load(f)# =============================# MCP 服务器客户端类# =============================class Server:    &quot;&quot;&quot;管理单个 MCP 服务器连接和工具调用&quot;&quot;&quot;    def __init__(self, name: str, config: Dict[str, Any]) -&gt; None:        self.name: str = name        self.config: Dict[str, Any] = config        self.session: Optional[ClientSession] = None        self.exit_stack: AsyncExitStack = AsyncExitStack()        self._cleanup_lock = asyncio.Lock()    async def initialize(self) -&gt; None:        &quot;&quot;&quot;初始化与 MCP 服务器的连接&quot;&quot;&quot;        # command 字段直接从配置获取        command = self.config[&quot;command&quot;]        if command is None:            raise ValueError(&quot;command 不能为空&quot;)        server_params = StdioServerParameters(            command=command,            args=self.config[&quot;args&quot;],            env=&#123;**os.environ, **self.config[&quot;env&quot;]&#125; if self.config.get(&quot;env&quot;) else None,        )        try:            stdio_transport = await self.exit_stack.enter_async_context(                stdio_client(server_params)            )            read_stream, write_stream = stdio_transport            session = await self.exit_stack.enter_async_context(                ClientSession(read_stream, write_stream)            )            await session.initialize()            self.session = session        except Exception as e:            logging.error(f&quot;Error initializing server &#123;self.name&#125;: &#123;e&#125;&quot;)            await self.cleanup()            raise    async def list_tools(self) -&gt; List[Any]:        &quot;&quot;&quot;获取服务器可用的工具列表        Returns:            工具列表        &quot;&quot;&quot;        if not self.session:            raise RuntimeError(f&quot;Server &#123;self.name&#125; not initialized&quot;)        tools_response = await self.session.list_tools()        tools = []        for item in tools_response:            if isinstance(item, tuple) and item[0] == &quot;tools&quot;:                for tool in item[1]:                    tools.append(Tool(tool.name, tool.description, tool.inputSchema))        return tools    async def execute_tool(        self, tool_name: str, arguments: Dict[str, Any], retries: int = 2, delay: float = 1.0    ) -&gt; Any:        &quot;&quot;&quot;执行指定工具，并支持重试机制        Args:            tool_name: 工具名称            arguments: 工具参数            retries: 重试次数            delay: 重试间隔秒数        Returns:            工具调用结果        &quot;&quot;&quot;        if not self.session:            raise RuntimeError(f&quot;Server &#123;self.name&#125; not initialized&quot;)        attempt = 0        while attempt &lt; retries:            try:                logging.info(f&quot;Executing &#123;tool_name&#125; on server &#123;self.name&#125;...&quot;)                result = await self.session.call_tool(tool_name, arguments)                return result            except Exception as e:                attempt += 1                logging.warning(                    f&quot;Error executing tool: &#123;e&#125;. Attempt &#123;attempt&#125; of &#123;retries&#125;.&quot;                )                if attempt &lt; retries:                    logging.info(f&quot;Retrying in &#123;delay&#125; seconds...&quot;)                    await asyncio.sleep(delay)                else:                    logging.error(&quot;Max retries reached. Failing.&quot;)                    raise    async def cleanup(self) -&gt; None:        &quot;&quot;&quot;清理服务器资源&quot;&quot;&quot;        async with self._cleanup_lock:            try:                await self.exit_stack.aclose()                self.session = None            except Exception as e:                logging.error(f&quot;Error during cleanup of server &#123;self.name&#125;: &#123;e&#125;&quot;)# =============================# 工具封装类# =============================class Tool:    &quot;&quot;&quot;封装 MCP 返回的工具信息&quot;&quot;&quot;    def __init__(self, name: str, description: str, input_schema: Dict[str, Any]) -&gt; None:        self.name: str = name        self.description: str = description        self.input_schema: Dict[str, Any] = input_schema    def format_for_llm(self) -&gt; str:        &quot;&quot;&quot;生成用于 LLM 提示的工具描述&quot;&quot;&quot;        args_desc = []        if &quot;properties&quot; in self.input_schema:            for param_name, param_info in self.input_schema[&quot;properties&quot;].items():                arg_desc = f&quot;- &#123;param_name&#125;: &#123;param_info.get(&#x27;description&#x27;, &#x27;No description&#x27;)&#125;&quot;                if param_name in self.input_schema.get(&quot;required&quot;, []):                    arg_desc += &quot; (required)&quot;                args_desc.append(arg_desc)        return f&quot;&quot;&quot;Tool: &#123;self.name&#125;Description: &#123;self.description&#125;Arguments:&#123;chr(10).join(args_desc)&#125;&quot;&quot;&quot;# =============================# LLM 客户端封装类（使用 OpenAI SDK）# =============================class LLMClient:    &quot;&quot;&quot;使用 OpenAI SDK 与大模型交互&quot;&quot;&quot;    def __init__(self, api_key: str, base_url: Optional[str], model: str) -&gt; None:        self.client = OpenAI(api_key=api_key, base_url=base_url)        self.model = model    def get_response(self, messages: List[Dict[str, Any]], tools: Optional[List[Dict[str, Any]]] = None) -&gt; Any:        &quot;&quot;&quot;        发送消息给大模型 API，支持传入工具参数（function calling 格式）        &quot;&quot;&quot;        payload = &#123;            &quot;model&quot;: self.model,            &quot;messages&quot;: messages,            &quot;tools&quot;: tools,        &#125;        try:            response = self.client.chat.completions.create(**payload)            return response        except Exception as e:            logging.error(f&quot;Error during LLM call: &#123;e&#125;&quot;)            raise# =============================# 多服务器 MCP 客户端类（集成配置文件、工具格式转换与 OpenAI SDK 调用）# =============================class MultiServerMCPClient:    def __init__(self) -&gt; None:        &quot;&quot;&quot;        管理多个 MCP 服务器，并使用 OpenAI Function Calling 风格的接口调用大模型        &quot;&quot;&quot;        self.exit_stack = AsyncExitStack()        config = Configuration()        self.openai_api_key = config.api_key        self.base_url = config.base_url        self.model = config.model        self.client = LLMClient(self.openai_api_key, self.base_url, self.model)        # (server_name -&gt; Server 对象)        self.servers: Dict[str, Server] = &#123;&#125;        # 各个 server 的工具列表        self.tools_by_server: Dict[str, List[Any]] = &#123;&#125;        self.all_tools: List[Dict[str, Any]] = []    async def connect_to_servers(self, servers_config: Dict[str, Any]) -&gt; None:        &quot;&quot;&quot;        根据配置文件同时启动多个服务器并获取工具        servers_config 的格式为：        &#123;          &quot;mcpServers&quot;: &#123;              &quot;sqlite&quot;: &#123; &quot;command&quot;: &quot;uvx&quot;, &quot;args&quot;: [ ... ] &#125;,              &quot;puppeteer&quot;: &#123; &quot;command&quot;: &quot;npx&quot;, &quot;args&quot;: [ ... ] &#125;,              ...          &#125;        &#125;        &quot;&quot;&quot;        mcp_servers = servers_config.get(&quot;mcpServers&quot;, &#123;&#125;)        for server_name, srv_config in mcp_servers.items():            server = Server(server_name, srv_config)            await server.initialize()            self.servers[server_name] = server            tools = await server.list_tools()            self.tools_by_server[server_name] = tools            for tool in tools:                # 统一重命名：serverName_toolName                function_name = f&quot;&#123;server_name&#125;_&#123;tool.name&#125;&quot;                self.all_tools.append(&#123;                    &quot;type&quot;: &quot;function&quot;,                    &quot;function&quot;: &#123;                        &quot;name&quot;: function_name,                        &quot;description&quot;: tool.description,                        &quot;input_schema&quot;: tool.input_schema                    &#125;                &#125;)        # 转换为 OpenAI Function Calling 所需格式        self.all_tools = await self.transform_json(self.all_tools)        logging.info(&quot;\\n✅ 已连接到下列服务器:&quot;)        for name in self.servers:            srv_cfg = mcp_servers[name]            logging.info(f&quot;  - &#123;name&#125;: command=&#123;srv_cfg[&#x27;command&#x27;]&#125;, args=&#123;srv_cfg[&#x27;args&#x27;]&#125;&quot;)        logging.info(&quot;\\n汇总的工具:&quot;)        for t in self.all_tools:            logging.info(f&quot;  - &#123;t[&#x27;function&#x27;][&#x27;name&#x27;]&#125;&quot;)    async def transform_json(self, json_data: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:        &quot;&quot;&quot;        将工具的 input_schema 转换为 OpenAI 所需的 parameters 格式，并删除多余字段        &quot;&quot;&quot;        result = []        for item in json_data:            if not isinstance(item, dict) or &quot;type&quot; not in item or &quot;function&quot; not in item:                continue            old_func = item[&quot;function&quot;]            if not isinstance(old_func, dict) or &quot;name&quot; not in old_func or &quot;description&quot; not in old_func:                continue            new_func = &#123;                &quot;name&quot;: old_func[&quot;name&quot;],                &quot;description&quot;: old_func[&quot;description&quot;],                &quot;parameters&quot;: &#123;&#125;            &#125;            if &quot;input_schema&quot; in old_func and isinstance(old_func[&quot;input_schema&quot;], dict):                old_schema = old_func[&quot;input_schema&quot;]                new_func[&quot;parameters&quot;][&quot;type&quot;] = old_schema.get(&quot;type&quot;, &quot;object&quot;)                new_func[&quot;parameters&quot;][&quot;properties&quot;] = old_schema.get(&quot;properties&quot;, &#123;&#125;)                new_func[&quot;parameters&quot;][&quot;required&quot;] = old_schema.get(&quot;required&quot;, [])            new_item = &#123;                &quot;type&quot;: item[&quot;type&quot;],                &quot;function&quot;: new_func            &#125;            result.append(new_item)        return result    async def chat_base(self, messages: List[Dict[str, Any]]) -&gt; Any:        &quot;&quot;&quot;        使用 OpenAI 接口进行对话，并支持多次工具调用（Function Calling）。        如果返回 finish_reason 为 &quot;tool_calls&quot;，则进行工具调用后再发起请求。        &quot;&quot;&quot;        response = self.client.get_response(messages, tools=self.all_tools)        # 如果模型返回工具调用        if response.choices[0].finish_reason == &quot;tool_calls&quot;:            while True:                messages = await self.create_function_response_messages(messages, response)                response = self.client.get_response(messages, tools=self.all_tools)                if response.choices[0].finish_reason != &quot;tool_calls&quot;:                    break        return response    async def create_function_response_messages(self, messages: List[Dict[str, Any]], response: Any) -&gt; List[Dict[str, Any]]:        &quot;&quot;&quot;        将模型返回的工具调用解析执行，并将结果追加到消息队列中        &quot;&quot;&quot;        function_call_messages = response.choices[0].message.tool_calls        messages.append(response.choices[0].message.model_dump())        for function_call_message in function_call_messages:            tool_name = function_call_message.function.name            tool_args = json.loads(function_call_message.function.arguments)            # 调用 MCP 工具            function_response = await self._call_mcp_tool(tool_name, tool_args)            # 🔍 打印返回值及其类型            # print(f&quot;[DEBUG] tool_name: &#123;tool_name&#125;&quot;)            # print(f&quot;[DEBUG] tool_args: &#123;tool_args&#125;&quot;)            # print(f&quot;[DEBUG] function_response: &#123;function_response&#125;&quot;)            # print(f&quot;[DEBUG] type(function_response): &#123;type(function_response)&#125;&quot;)            messages.append(&#123;                &quot;role&quot;: &quot;tool&quot;,                &quot;content&quot;: function_response,                &quot;tool_call_id&quot;: function_call_message.id,            &#125;)        return messages    async def process_query(self, user_query: str) -&gt; str:        &quot;&quot;&quot;        OpenAI Function Calling 流程：         1. 发送用户消息 + 工具信息         2. 若模型返回 finish_reason 为 &quot;tool_calls&quot;，则解析并调用 MCP 工具         3. 将工具调用结果返回给模型，获得最终回答        &quot;&quot;&quot;        messages = [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: user_query&#125;]        response = self.client.get_response(messages, tools=self.all_tools)        content = response.choices[0]        logging.info(content)        if content.finish_reason == &quot;tool_calls&quot;:            tool_call = content.message.tool_calls[0]            tool_name = tool_call.function.name            tool_args = json.loads(tool_call.function.arguments)            logging.info(f&quot;\\n[ 调用工具: &#123;tool_name&#125;, 参数: &#123;tool_args&#125; ]\\n&quot;)            result = await self._call_mcp_tool(tool_name, tool_args)            messages.append(content.message.model_dump())            messages.append(&#123;                &quot;role&quot;: &quot;tool&quot;,                &quot;content&quot;: result,                &quot;tool_call_id&quot;: tool_call.id,            &#125;)            response = self.client.get_response(messages, tools=self.all_tools)            return response.choices[0].message.content        return content.message.content    async def _call_mcp_tool(self, tool_full_name: str, tool_args: Dict[str, Any]) -&gt; str:        &quot;&quot;&quot;        根据 &quot;serverName_toolName&quot; 格式调用相应 MCP 工具        &quot;&quot;&quot;        parts = tool_full_name.split(&quot;_&quot;, 1)        if len(parts) != 2:            return f&quot;无效的工具名称: &#123;tool_full_name&#125;&quot;        server_name, tool_name = parts        server = self.servers.get(server_name)        if not server:            return f&quot;找不到服务器: &#123;server_name&#125;&quot;        resp = await server.execute_tool(tool_name, tool_args)                # 🛠️ 修复点：提取 TextContent 中的文本（或转成字符串）        content = resp.content        if isinstance(content, list):            # 提取所有 TextContent 对象中的 text 字段            texts = [c.text for c in content if hasattr(c, &quot;text&quot;)]            return &quot;\\n&quot;.join(texts)        elif isinstance(content, dict) or isinstance(content, list):            # 如果是 dict 或 list，但不是 TextContent 类型            return json.dumps(content, ensure_ascii=False)        elif content is None:            return &quot;工具执行无输出&quot;        else:            return str(content)    async def chat_loop(self) -&gt; None:        &quot;&quot;&quot;多服务器 MCP + OpenAI Function Calling 客户端主循环&quot;&quot;&quot;        logging.info(&quot;\\n🤖 多服务器 MCP + Function Calling 客户端已启动！输入 &#x27;quit&#x27; 退出。&quot;)        messages: List[Dict[str, Any]] = []        while True:            query = input(&quot;\\n你: &quot;).strip()            if query.lower() == &quot;quit&quot;:                break            try:                messages.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: query&#125;)                messages = messages[-20:]  # 保持最新 20 条上下文                response = await self.chat_base(messages)                messages.append(response.choices[0].message.model_dump())                result = response.choices[0].message.content                # logging.info(f&quot;\\nAI: &#123;result&#125;&quot;)                print(f&quot;\\nAI: &#123;result&#125;&quot;)            except Exception as e:                print(f&quot;\\n⚠️  调用过程出错: &#123;e&#125;&quot;)    async def cleanup(self) -&gt; None:        &quot;&quot;&quot;关闭所有资源&quot;&quot;&quot;        await self.exit_stack.aclose()# =============================# 主函数# =============================async def main() -&gt; None:    # 从配置文件加载服务器配置    config = Configuration()    servers_config = config.load_config(&quot;servers_config.json&quot;)    client = MultiServerMCPClient()    try:        await client.connect_to_servers(servers_config)        await client.chat_loop()    finally:        try:            await asyncio.sleep(0.1)            await client.cleanup()        except RuntimeError as e:            # 如果是因为退出 cancel scope 导致的异常，可以选择忽略            if &quot;Attempted to exit cancel scope&quot; in str(e):                logging.info(&quot;退出时检测到 cancel scope 异常，已忽略。&quot;)            else:                raiseif __name__ == &quot;__main__&quot;:    asyncio.run(main())\n\n接下来继续创建一个.env文件，来保存大模型调用的API-KEY\n并写入如下内容：\nBASE_URL=https://api.deepseek.comMODEL=deepseek-chatOPENAI_API_KEY=YOUR_DEEPSEEK_API_KEY\n\n接下来继续创建servers_config.json文件，用于保存MCP工具基本信息：\n&#123;  &quot;mcpServers&quot;: &#123;    &quot;weather&quot;: &#123;      &quot;command&quot;: &quot;python&quot;,      &quot;args&quot;: [&quot;weather_server.py&quot;],      &quot;transport&quot;: &quot;stdio&quot;    &#125;,    &quot;write&quot;: &#123;      &quot;command&quot;: &quot;python&quot;,      &quot;args&quot;: [&quot;write_server.py&quot;],      &quot;transport&quot;: &quot;stdio&quot;    &#125;  &#125;&#125;\n\n最后在命令行中执行如下命令，注意在此之前要先启动两个mcp服务器脚本，即可开启对话：\nuv run client.py\n\n至此，即完成了一次简单的MCP执行流程。\n上面是使用Function calling直接调用MCP的工具\n接下来来介绍**MCP+LangChain的基础调用流程**，代码量也会大幅减少\nLangChain调用MCP是可以将MCP的工具直接转换为LangChain的工具，然后通过预定义的MCP_Client实现与外部MCP的读写操作，换而言之就是我们需要改写原先的client，将原先的Function calling调用逻辑修改为LangChain调用逻辑：\n&quot;&quot;&quot;多服务器 MCP + LangChain Agent 示例---------------------------------1. 读取 .env 中的 LLM_API_KEY / BASE_URL / MODEL2. 读取 servers_config.json 中的 MCP 服务器信息3. 启动 MCP 服务器（支持多个）4. 将所有工具注入 LangChain Agent，由大模型自动选择并调用&quot;&quot;&quot;import asyncioimport jsonimport loggingimport osfrom typing import Any, Dict, Listfrom dotenv import load_dotenvfrom langchain import hubfrom langchain.agents import AgentExecutor, create_openai_tools_agentfrom langchain.chat_models import init_chat_modelfrom langchain_mcp_adapters.client import MultiServerMCPClientfrom langchain_mcp_adapters.tools import load_mcp_tools# ────────────────────────────# 环境配置# ────────────────────────────class Configuration:    &quot;&quot;&quot;读取 .env 与 servers_config.json&quot;&quot;&quot;    def __init__(self) -&gt; None:        load_dotenv()        self.api_key: str = os.getenv(&quot;LLM_API_KEY&quot;) or &quot;&quot;        self.base_url: str | None = os.getenv(&quot;BASE_URL&quot;)  # DeepSeek 用 https://api.deepseek.com        self.model: str = os.getenv(&quot;MODEL&quot;) or &quot;deepseek-chat&quot;        if not self.api_key:            raise ValueError(&quot;❌ 未找到 LLM_API_KEY，请在 .env 中配置&quot;)    @staticmethod    def load_servers(file_path: str = &quot;servers_config.json&quot;) -&gt; Dict[str, Any]:        with open(file_path, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:            return json.load(f).get(&quot;mcpServers&quot;, &#123;&#125;)# ────────────────────────────# 主逻辑# ────────────────────────────async def run_chat_loop() -&gt; None:    &quot;&quot;&quot;启动 MCP-Agent 聊天循环&quot;&quot;&quot;    cfg = Configuration()    os.environ[&quot;DEEPSEEK_API_KEY&quot;] = os.getenv(&quot;LLM_API_KEY&quot;, &quot;&quot;)    if cfg.base_url:        os.environ[&quot;DEEPSEEK_API_BASE&quot;] = cfg.base_url    servers_cfg = Configuration.load_servers()    # 把 key 注入环境，LangChain-OpenAI / DeepSeek 会自动读取    os.environ[&quot;OPENAI_API_KEY&quot;] = cfg.api_key    if cfg.base_url:  # 对 DeepSeek 之类的自定义域名很有用        os.environ[&quot;OPENAI_BASE_URL&quot;] = cfg.base_url    # 1️⃣ 连接多台 MCP 服务器    mcp_client = MultiServerMCPClient(servers_cfg)    tools = await mcp_client.get_tools()         # LangChain Tool 对象列表    logging.info(f&quot;✅ 已加载 &#123;len(tools)&#125; 个 MCP 工具： &#123;[t.name for t in tools]&#125;&quot;)    # 2️⃣ 初始化大模型（DeepSeek / OpenAI / 任意兼容 OpenAI 协议的模型）    llm = init_chat_model(        model=cfg.model,        model_provider=&quot;deepseek&quot; if &quot;deepseek&quot; in cfg.model else &quot;openai&quot;,    )    # 3️⃣ 构造 LangChain Agent（用通用 prompt）    prompt = hub.pull(&quot;hwchase17/openai-tools-agent&quot;)    agent = create_openai_tools_agent(llm, tools, prompt)    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)    # 4️⃣ CLI 聊天    print(&quot;\\n🤖 MCP Agent 已启动，输入 &#x27;quit&#x27; 退出&quot;)    while True:        user_input = input(&quot;\\n你: &quot;).strip()        if user_input.lower() == &quot;quit&quot;:            break        try:            result = await agent_executor.ainvoke(&#123;&quot;input&quot;: user_input&#125;)            print(f&quot;\\nAI: &#123;result[&#x27;output&#x27;]&#125;&quot;)        except Exception as exc:            print(f&quot;\\n⚠️  出错: &#123;exc&#125;&quot;)    # 5️⃣ 清理    await mcp_client.cleanup()    print(&quot;🧹 资源已清理，Bye!&quot;)# ────────────────────────────# 入口# ────────────────────────────if __name__ == &quot;__main__&quot;:    logging.basicConfig(level=logging.INFO, format=&quot;%(asctime)s - %(levelname)s - %(message)s&quot;)    asyncio.run(run_chat_loop())\n\nLangChain接入MCP的核心原理为： weather_server.py → 启动为子进程 → stdio 通信 → MCP 协议 → 转换为 LangChain 工具 → LangChain Agent 执行读写，核心转换过程为：\n\n@mcp.tool() → 标准 LangChain Tool\n\nstdio_client() → 自动处理 read/write 流，其中read 表示从 MCP 服务器读取响应的流，write 表示向 MCP 服务器发送请求的流，对于 stdio weather_server.py，它们就是子进程的 stdout 和 stdin\n\nload_mcp_tools() → 一键转换所有工具\n\n\n七、LangChain RAG知识库检索系统开发首先介绍LangChain 实现本地知识库问答\n供Agents在处理复杂任务的某个阶段使用，这其实是一种更为复杂的应用架构——Agent + RAG。\n假设现在我们有一个偌大的知识库，当想从该知识库中去检索最相关的内容时，最简单的方法是：接收到一个查询（Query），就直接在知识库中进行搜索。这种做法其实是可行的，但存在两个关键的问题：\n\n假设提问的Query的答案出现在一篇文章中，去知识库中找到一篇与用户输入相关的文章是很容易的，但是我们将检索到的这整篇文章直接放入Prompt中并不是最优的选择，因为其中一定会包含非常多无关的信息，而无效信息越多，对大模型后续的推理影响越大。\n\n任何一个大模型都存在最大输入的Token限制，一个流程中可能涉及多次检索，每次检索都会产生相应的上下文，无法容纳如此多的信息。\n\n\n\n解决上述两个问题的方式是：把存放着原始数据的知识库（Knowledge）中的每一个raw data，切分成一个一个的小块，这些小块可以是一个段落，也可以是数据库中某个索引对应的值。这个切分过程被称为“分块”（chunking），如下述流程所示：\n\n以第一个原始数据为例（raw data 1），通过一些特定的方法进行切分，一个完整的内容会被分割成 chunk1 ~ chunk4。采取相同的方法，继续对raw data 2、raw data 3直至raw data n进行切分。完成这一过程后，我们最终得到的是一个充满分块数据（chunks）的新的知识库（repository），其中每一项都是一个单独的chunk。例如，如果原始文档共有10个，那么经过切分，可能会产生出100个chunks。\n完成这一转化后，当再次接收到一个查询（Query）时，就会在更新后的知识库（repository）中进行搜索，这时检索的范围就不再是某个完整的文档，而是其中的某一个部分，返回的是一个或多个特定的chunk，这样返回的信息量就会更小且更精确。随后，这些被检索到的chunk会被加入到Prompt中，作为上下文信息与用户原始的Query共同输入到大模型进行处理，以生成最终的回答。\n在上述将原始数据（raw data）转化为chunk的过程中，就会包含构建RAG的第一部分开发工作：这包括如果做数据清洗，如去除停用词、标点符号等。此外，还涉及如何选择合适的split方法来进行数据切分的一系列技术。\n接下来面临的问题是，尽管所有数据已经被切割成一个个chunk，其存储形式还是以字符串形式存在，如果想从repository中匹配到与输入的query相关的chunks，比较两句话是否相似，看一句话中相同字有几个，这显然是行不通的。我们需要获取的是句子所蕴含的深层含义，而非仅仅是表面的字面相似度。因此，大家也能想到，在NLP中去计算文本相似度的有效的方法就是Embedding，即将这些chunks转换成向量（vector）形式。所以流程会丰富如下：\n\n如上所示，解决搜索效率和计算相似度优化算法的答案就是：向量数据库。同时也产生了构建RAG的第三部分工作：我们要去了解和学习如何选择、使用向量数据库。\n最终整体流程就如上图所示，一个基础的RAG架构会只要包含以下几方面的开发工作：\n\n如何将原始数据转化成chunks；\n如何将chunks转化成Vector；\n如何算向量相似度的算法；\n如何利用向量数据库提升搜索效率；\n如何把找到的chunks与原始query拼接在一起，产生最终的Prompt；\n\n而上述流程，其实更像是一个自由拼接的结果，比如不同的文档类型可以选择不同的文档解析器，也可以选择不同的Vector数据库，甚至可以自由选择Embedding模型和Vector数据库的组合。其自由程度非常高，如下图所示：\n\n由于这一部分比较复杂，因此在这仅给出示例代码，后续再做补充（后面的内容有需要可以看，也可以等后续给出更详细的教程）下面是通过 Streamlit 前端界面，结合 LangChain 框架 与 DashScope 向量嵌入服务，实现了一个轻量化的 RAG（Retrieval-Augmented Generation） 智能问答系统，支持上传多个 PDF 文档，系统将自动完成文本提取、分块、向量化，并构建基于 FAISS 的检索数据库。用户随后可以在页面中输入任意问题，系统会调用大语言模型（如 DeepSeek-Chat）对 PDF 内容进行语义理解和回答生成。\n其完整代码如下所示：\n! pip install streamlit PyPDF2 dashscope faiss-cpu\n\nimport streamlit as stfrom PyPDF2 import PdfReaderfrom langchain.text_splitter import RecursiveCharacterTextSplitterfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_community.vectorstores import FAISSfrom langchain.tools.retriever import create_retriever_toolfrom langchain.agents import AgentExecutor, create_tool_calling_agentfrom langchain_community.embeddings import DashScopeEmbeddingsfrom langchain.chat_models import init_chat_modelimport osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot;)dashscope_api_key = os.getenv(&quot;dashscope_api_key&quot;)os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;embeddings = DashScopeEmbeddings(    model=&quot;text-embedding-v1&quot;, dashscope_api_key=dashscope_api_key)def pdf_read(pdf_doc):    text = &quot;&quot;    for pdf in pdf_doc:        pdf_reader = PdfReader(pdf)        for page in pdf_reader.pages:            text += page.extract_text()    return textdef get_chunks(text):    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)    chunks = text_splitter.split_text(text)    return chunksdef vector_store(text_chunks):    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)    vector_store.save_local(&quot;faiss_db&quot;)def get_conversational_chain(tools, ques):    llm = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)    prompt = ChatPromptTemplate.from_messages([        (            &quot;system&quot;,            &quot;&quot;&quot;你是AI助手，请根据提供的上下文回答问题，确保提供所有细节，如果答案不在上下文中，请说&quot;答案不在上下文中&quot;，不要提供错误的答案&quot;&quot;&quot;,        ),        (&quot;placeholder&quot;, &quot;&#123;chat_history&#125;&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])    tool = [tools]    agent = create_tool_calling_agent(llm, tool, prompt)    agent_executor = AgentExecutor(agent=agent, tools=tool, verbose=True)    response = agent_executor.invoke(&#123;&quot;input&quot;: ques&#125;)    print(response)    st.write(&quot;🤖 回答: &quot;, response[&#x27;output&#x27;])def check_database_exists():    &quot;&quot;&quot;检查FAISS数据库是否存在&quot;&quot;&quot;    return os.path.exists(&quot;faiss_db&quot;) and os.path.exists(&quot;faiss_db/index.faiss&quot;)def user_input(user_question):    # 检查数据库是否存在    if not check_database_exists():        st.error(&quot;❌ 请先上传PDF文件并点击&#x27;Submit &amp; Process&#x27;按钮来处理文档！&quot;)        st.info(&quot;💡 步骤：1️⃣ 上传PDF → 2️⃣ 点击处理 → 3️⃣ 开始提问&quot;)        return    try:        # 加载FAISS数据库        new_db = FAISS.load_local(&quot;faiss_db&quot;, embeddings, allow_dangerous_deserialization=True)        retriever = new_db.as_retriever()        retrieval_chain = create_retriever_tool(retriever, &quot;pdf_extractor&quot;,                                                &quot;This tool is to give answer to queries from the pdf&quot;)        get_conversational_chain(retrieval_chain, user_question)    except Exception as e:        st.error(f&quot;❌ 加载数据库时出错: &#123;str(e)&#125;&quot;)        st.info(&quot;请重新处理PDF文件&quot;)def main():    st.set_page_config(&quot;🤖 LangChain B站公开课 By九天Hector&quot;)    st.header(&quot;🤖 LangChain B站公开课 By九天Hector&quot;)    # 显示数据库状态    col1, col2 = st.columns([3, 1])    with col1:        if check_database_exists():            pass        else:            st.warning(&quot;⚠️ 请先上传并处理PDF文件&quot;)with col2:    if st.button(&quot;🗑️ 清除数据库&quot;):        try:            import shutil            if os.path.exists(&quot;faiss_db&quot;):                shutil.rmtree(&quot;faiss_db&quot;)            st.success(&quot;数据库已清除&quot;)            st.rerun()        except Exception as e:            st.error(f&quot;清除失败: &#123;e&#125;&quot;)# 用户问题输入user_question = st.text_input(&quot;💬 请输入问题&quot;,                              placeholder=&quot;例如：这个文档的主要内容是什么？&quot;,                              disabled=not check_database_exists())if user_question:    if check_database_exists():        with st.spinner(&quot;🤔 AI正在分析文档...&quot;):            user_input(user_question)    else:        st.error(&quot;❌ 请先上传并处理PDF文件！&quot;)# 侧边栏with st.sidebar:    st.title(&quot;📁 文档管理&quot;)    # 显示当前状态    if check_database_exists():        st.success(&quot;✅ 数据库状态：已就绪&quot;)    else:        st.info(&quot;📝 状态：等待上传PDF&quot;)    st.markdown(&quot;---&quot;)    # 文件上传    pdf_doc = st.file_uploader(        &quot;📎 上传PDF文件&quot;,        accept_multiple_files=True,        type=[&#x27;pdf&#x27;],        help=&quot;支持上传多个PDF文件&quot;    )    if pdf_doc:        st.info(f&quot;📄 已选择 &#123;len(pdf_doc)&#125; 个文件&quot;)        for i, pdf in enumerate(pdf_doc, 1):            st.write(f&quot;&#123;i&#125;. &#123;pdf.name&#125;&quot;)    # 处理按钮    process_button = st.button(        &quot;🚀 提交并处理&quot;,        disabled=not pdf_doc,        use_container_width=True    )    if process_button:        if pdf_doc:            with st.spinner(&quot;📊 正在处理PDF文件...&quot;):                try:                    # 读取PDF内容                    raw_text = pdf_read(pdf_doc)                    if not raw_text.strip():                        st.error(&quot;❌ 无法从PDF中提取文本，请检查文件是否有效&quot;)                        return                    # 分割文本                    text_chunks = get_chunks(raw_text)                    st.info(f&quot;📝 文本已分割为 &#123;len(text_chunks)&#125; 个片段&quot;)                    # 创建向量数据库                    vector_store(text_chunks)                    st.success(&quot;✅ PDF处理完成！现在可以开始提问了&quot;)                    st.balloons()                    st.rerun()                except Exception as e:                    st.error(f&quot;❌ 处理PDF时出错: &#123;str(e)&#125;&quot;)        else:            st.warning(&quot;⚠️ 请先选择PDF文件&quot;)    # 使用说明    with st.expander(&quot;💡 使用说明&quot;):        st.markdown(&quot;&quot;&quot;                **步骤：**                1. 📎 上传一个或多个PDF文件                2. 🚀 点击&quot;Submit &amp; Process&quot;处理文档                3. 💬 在主页面输入您的问题                4. 🤖 AI将基于PDF内容回答问题                **提示：**                - 支持多个PDF文件同时上传                - 处理大文件可能需要一些时间                - 可以随时清除数据库重新开始                &quot;&quot;&quot;)if __name__ == &quot;__main__&quot;:    main()\n\n基于此，我们能够实现：\n\nLangChain 的多模块能力（向量搜索 + Agent工具）\nStreamlit 前端交互\nFAISS 向量数据库\nDashScope Embedding + DeepSeek 模型接入\n并完成了完整的 RAG（检索增强生成）流程\n\n以下是各部分功能实现代码讲解：\n🔧 1. 导入库 &amp; 环境初始化\nimport streamlit as stfrom PyPDF2 import PdfReaderfrom langchain.text_splitter import RecursiveCharacterTextSplitter...load_dotenv(override=True)\n\n\nStreamlit 用于构建网页界面。\n\nPyPDF2 用来读取 PDF 文本。\n\nload_dotenv() 加载 .env 中的 API Key，例如：\nDEEPSEEK_API_KEY=sk-xxxDASHSCOPE_API_KEY=xxx\n\n\n🔐 2. 加载 API 密钥与设置环境变量\nDeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot;)dashscope_api_key = os.getenv(&quot;dashscope_api_key&quot;)os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;]=&quot;TRUE&quot;\n\n\n从环境变量中读取 DashScope 和 DeepSeek API。\n设置 KMP_DUPLICATE_LIB_OK 避免某些 MKL 多线程报错。\n\n\n🧠 3. 初始化向量 Embedding 模型\nembeddings = DashScopeEmbeddings(    model=&quot;text-embedding-v1&quot;, dashscope_api_key=dashscope_api_key)\n\n\n用阿里云 DashScope 提供的 text-embedding-v1 将文本转为向量表示，用于相似度搜索。\n\n\n📄 4. 处理 PDF 文本与向量化逻辑\ndef pdf_read(pdf_doc):    ...def get_chunks(text):    ...def vector_store(text_chunks):    ...\n\n\npdf_read：逐页读取 PDF 内容并拼接。\nget_chunks：将长文本切片为多个段落（chunk），每段 1000 字，重叠 200 字。\nvector_store：用 FAISS 建立向量索引，并保存到本地 faiss_db/。\n\n\n🔁 5. Agent对话链 + 工具调用（核心 RAG）\ndef get_conversational_chain(tools, ques):    llm = init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)    ...    agent_executor = AgentExecutor(...)    response = agent_executor.invoke(&#123;&quot;input&quot;: ques&#125;)    ...\n\n\n初始化 DeepSeek 模型为 Agent。\n\n使用 LangChain 的 create_tool_calling_agent 构造 Agent，输入：\n\nprompt（你设定的系统角色）\n工具（retriever 工具）\n\n\nAgentExecutor.invoke：LangChain 自动判断是否调用工具，完成“读取上下文 → 查询 → 回答”流程。\n\n\n\n🔍 6. 用户提问逻辑（调用 FAISS）\ndef user_input(user_question):    ...    new_db = FAISS.load_local(&quot;faiss_db&quot;, embeddings, ...)    retriever = new_db.as_retriever()    retrieval_chain = create_retriever_tool(retriever, &quot;pdf_extractor&quot;, ...)    get_conversational_chain(retrieval_chain, user_question)\n\n\n加载本地 FAISS 向量库；\n将其转为 LangChain 的检索工具；\n交由 Agent 调用完成回答。\n\n\n🧠 7. 检查数据库是否存在\ndef check_database_exists():    return os.path.exists(&quot;faiss_db&quot;) and os.path.exists(&quot;faiss_db/index.faiss&quot;)\n\n简单检查本地是否已有向量化数据。\n\n🌐 8. 主界面逻辑（Streamlit）\ndef main():    st.set_page_config(...)    ...\n\n\n页面标题与界面配置。\n\nst.columns 分栏：左边显示提示，右边放置“清空数据库”按钮。\n\n主输入框：st.text_input(&quot;请输入问题&quot;)\n\n只有当数据库存在时才能提问。\n\n\n侧边栏：\n\nPDF 上传器；\n提交按钮（处理上传的 PDF → 分片 → 向量化 → 存储）。\n\n\n\n\n🎯 9. 提交 PDF 后执行的逻辑\nif process_button:    raw_text = pdf_read(pdf_doc)    ...    text_chunks = get_chunks(raw_text)    vector_store(text_chunks)\n\n\n当点击“提交并处理”后：\n\n读取上传的 PDF；\n切片文本；\n向量化入库；\n弹出气球提示，并 st.rerun() 刷新页面状态。\n\n\n\n\n📎 项目结构总结\n\n\n\n模块\n说明\n\n\n\n🧾 PDF解析\n读取用户上传的 PDF\n\n\n✂️ 文本切片\n按段落分割内容\n\n\n📊 向量化\nDashScope Embedding + FAISS 建库\n\n\n🔁 查询接口\n用户输入 → 召回相关 chunk\n\n\n🤖 DeepSeek Agent\n调用检索工具并给出回答\n\n\n💻 UI层\nStreamlit 实现全部交互\n\n\n其中LangChain RAG核心功能相关代码如下：\nStep 1：PDF 文件上传与文本提取\n使用 st.file_uploader() 组件支持多文件上传，并通过 PyPDF2.PdfReader 对每页内容进行提取，组合为整体文本。\ndef pdf_read(pdf_doc):    text = &quot;&quot;    for pdf in pdf_doc:        pdf_reader = PdfReader(pdf)        for page in pdf_reader.pages:            text += page.extract_text()    return text\n\nStep 2：文本分块与向量数据库构建\n使用 RecursiveCharacterTextSplitter 将长文档切割为固定长度（1000字）+ 重叠（200字）的小块，将文本块通过 DashScopeEmbeddings 嵌入为向量，使用 FAISS 本地存储向量数据库。\nchunks = text_splitter.split_text(text)vector_store = FAISS.from_texts(chunks, embedding=embeddings)vector_store.save_local(&quot;faiss_db&quot;)\n\nStep 3：用户提问与语义检索\n通过 Streamlit 获取用户输入问题，如果向量数据库存在，则加载 FAISS 检索器，使用 create_retriever_tool() 构建 LangChain 工具，交由 AgentExecutor 执行，自动调用检索器并生成答案。\nretrieval_chain = create_retriever_tool(retriever, ...)agent = create_tool_calling_agent(llm, [retrieval_chain], prompt)response = agent_executor.invoke(&#123;&quot;input&quot;: ques&#125;)\n\n下面再基于LangChain搭建AI数据分析智能体Data Agent\n接下来，我们进一步丰富智能问答系统的功能，接下来的案例中，我们构建一个基于 Streamlit + LangChain + DashScope + DeepSeek 的智能化数据分析助手，融合两个典型的企业级大模型应用场景：\n\nPDF 智能问答：支持上传多个 PDF 文档，自动完成内容提取、文本切块、语义向量化，并构建 FAISS 本地检索库，结合大模型进行问答；\n\nCSV 数据智能分析：通过自然语言指令分析结构化数据，包括统计查询、代码生成与图表绘制；\n\n\n完整代码如下所示：\npip install langchain_experimental matplotlib tabulate\n\nimport streamlit as stimport pandas as pdimport osfrom PyPDF2 import PdfReaderfrom langchain.text_splitter import RecursiveCharacterTextSplitterfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_community.vectorstores import FAISSfrom langchain.tools.retriever import create_retriever_toolfrom langchain.agents import AgentExecutor, create_tool_calling_agentfrom langchain_community.embeddings import DashScopeEmbeddingsfrom langchain.chat_models import init_chat_modelfrom langchain_experimental.tools import PythonAstREPLToolimport matplotlibmatplotlib.use(&#x27;Agg&#x27;)import osfrom dotenv import load_dotenvload_dotenv(override=True)DeepSeek_API_KEY = os.getenv(&quot;DEEPSEEK_API_KEY&quot;)dashscope_api_key = os.getenv(&quot;dashscope_api_key&quot;)# 设置环境变量os.environ[&quot;KMP_DUPLICATE_LIB_OK&quot;] = &quot;TRUE&quot;# 页面配置st.set_page_config(    page_title=&quot;By九天Hector&quot;,    page_icon=&quot;🤖&quot;,    layout=&quot;wide&quot;,    initial_sidebar_state=&quot;expanded&quot;)# 自定义CSS样式st.markdown(&quot;&quot;&quot;    &lt;style&gt;        /* 主题色彩 */        :root &#123;            --primary-color: #1f77b4;            --secondary-color: #ff7f0e;            --success-color: #2ca02c;            --warning-color: #ff9800;            --error-color: #d62728;            --background-color: #f8f9fa;        &#125;        /* 隐藏默认的Streamlit样式 */        #MainMenu &#123;visibility: hidden;&#125;        footer &#123;visibility: hidden;&#125;        header &#123;visibility: hidden;&#125;        /* 标题样式 */        .main-header &#123;            background: linear-gradient(90deg, #1f77b4, #ff7f0e);            -webkit-background-clip: text;            -webkit-text-fill-color: transparent;            font-size: 3rem;            font-weight: bold;            text-align: center;            margin-bottom: 2rem;        &#125;        /* 卡片样式 */        .info-card &#123;            background: white;            padding: 1.5rem;            border-radius: 10px;            box-shadow: 0 2px 10px rgba(0,0,0,0.1);            margin: 1rem 0;            border-left: 4px solid var(--primary-color);        &#125;        .success-card &#123;            background: linear-gradient(135deg, #e8f5e8, #f0f8f0);            border-left: 4px solid var(--success-color);        &#125;        .warning-card &#123;            background: linear-gradient(135deg, #fff8e1, #fffbf0);            border-left: 4px solid var(--warning-color);        &#125;        /* 按钮样式 */        .stButton &gt; button &#123;            background: linear-gradient(45deg, #1f77b4, #2196F3);            color: white;            border: none;            border-radius: 8px;            padding: 0.5rem 1rem;            font-weight: 600;            transition: all 0.3s ease;            box-shadow: 0 2px 8px rgba(31, 119, 180, 0.3);        &#125;        .stButton &gt; button:hover &#123;            transform: translateY(-2px);            box-shadow: 0 4px 12px rgba(31, 119, 180, 0.4);        &#125;        /* Tab样式 */        .stTabs [data-baseweb=&quot;tab-list&quot;] &#123;            gap: 8px;            background-color: #f8f9fa;            border-radius: 10px;            padding: 0.5rem;        &#125;        .stTabs [data-baseweb=&quot;tab&quot;] &#123;            height: 60px;            background-color: white;            border-radius: 8px;            padding: 0 24px;            font-weight: 600;            border: 2px solid transparent;            transition: all 0.3s ease;        &#125;        .stTabs [aria-selected=&quot;true&quot;] &#123;            background: linear-gradient(45deg, #1f77b4, #2196F3);            color: white !important;            border: 2px solid #1f77b4;        &#125;        /* 侧边栏样式 */        .css-1d391kg &#123;            background: linear-gradient(180deg, #f8f9fa, #ffffff);        &#125;        /* 文件上传区域 */        .uploadedFile &#123;            background: #f8f9fa;            border: 2px dashed #1f77b4;            border-radius: 10px;            padding: 1rem;            text-align: center;            margin: 1rem 0;        &#125;        /* 状态指示器 */        .status-indicator &#123;            display: inline-flex;            align-items: center;            gap: 0.5rem;            padding: 0.5rem 1rem;            border-radius: 20px;            font-weight: 600;            font-size: 0.9rem;        &#125;        .status-ready &#123;            background: #e8f5e8;            color: #2ca02c;            border: 1px solid #2ca02c;        &#125;        .status-waiting &#123;            background: #fff8e1;            color: #ff9800;            border: 1px solid #ff9800;        &#125;    &lt;/style&gt;    &quot;&quot;&quot;, unsafe_allow_html=True)# 初始化embeddings@st.cache_resourcedef init_embeddings():    return DashScopeEmbeddings(        model=&quot;text-embedding-v1&quot;,        dashscope_api_key=dashscope_api_key    )# 初始化LLM@st.cache_resourcedef init_llm():    return init_chat_model(&quot;deepseek-chat&quot;, model_provider=&quot;deepseek&quot;)# 初始化会话状态def init_session_state():    if &#x27;pdf_messages&#x27; not in st.session_state:        st.session_state.pdf_messages = []    if &#x27;csv_messages&#x27; not in st.session_state:        st.session_state.csv_messages = []    if &#x27;df&#x27; not in st.session_state:        st.session_state.df = None# PDF处理函数def pdf_read(pdf_doc):    text = &quot;&quot;    for pdf in pdf_doc:        pdf_reader = PdfReader(pdf)        for page in pdf_reader.pages:            text += page.extract_text()    return textdef get_chunks(text):    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)    chunks = text_splitter.split_text(text)    return chunksdef vector_store(text_chunks):    embeddings = init_embeddings()    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)    vector_store.save_local(&quot;faiss_db&quot;)def check_database_exists():    return os.path.exists(&quot;faiss_db&quot;) and os.path.exists(&quot;faiss_db/index.faiss&quot;)def get_pdf_response(user_question):    if not check_database_exists():        return &quot;❌ 请先上传PDF文件并点击&#x27;Submit &amp; Process&#x27;按钮来处理文档！&quot;    try:        embeddings = init_embeddings()        llm = init_llm()        new_db = FAISS.load_local(&quot;faiss_db&quot;, embeddings, allow_dangerous_deserialization=True)        retriever = new_db.as_retriever()        prompt = ChatPromptTemplate.from_messages([            (&quot;system&quot;,             &quot;&quot;&quot;你是AI助手，请根据提供的上下文回答问题，确保提供所有细节，如果答案不在上下文中，请说&quot;答案不在上下文中&quot;，不要提供错误的答案&quot;&quot;&quot;),            (&quot;placeholder&quot;, &quot;&#123;chat_history&#125;&quot;),            (&quot;human&quot;, &quot;&#123;input&#125;&quot;),            (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),        ])        retrieval_chain = create_retriever_tool(retriever, &quot;pdf_extractor&quot;,                                                &quot;This tool is to give answer to queries from the pdf&quot;)        agent = create_tool_calling_agent(llm, [retrieval_chain], prompt)        agent_executor = AgentExecutor(agent=agent, tools=[retrieval_chain], verbose=True)        response = agent_executor.invoke(&#123;&quot;input&quot;: user_question&#125;)        return response[&#x27;output&#x27;]    except Exception as e:        return f&quot;❌ 处理问题时出错: &#123;str(e)&#125;&quot;# CSV处理函数def get_csv_response(query: str) -&gt; str:    if st.session_state.df is None:        return &quot;请先上传CSV文件&quot;    llm = init_llm()    locals_dict = &#123;&#x27;df&#x27;: st.session_state.df&#125;    tools = [PythonAstREPLTool(locals=locals_dict)]    system = f&quot;&quot;&quot;Given a pandas dataframe `df` answer user&#x27;s query.        Here&#x27;s the output of `df.head().to_markdown()` for your reference, you have access to full dataframe as `df`:\n    &#123;st.session_state.df.head().to_markdown()&#125;\n    Give final answer as soon as you have enough data, otherwise generate code using `df` and call required tool.If user asks you to make a graph, save it as `plot.png`, and output GRAPH:&lt;graph title&gt;.Example:\n    plt.hist(df[&#39;Age&#39;])\n    plt.xlabel(&#39;Age&#39;)\n    plt.ylabel(&#39;Count&#39;)\n    plt.title(&#39;Age Histogram&#39;)\n    plt.savefig(&#39;plot.png&#39;)\n    GRAPH:Age histogram        Query:&quot;&quot;&quot;        prompt = ChatPromptTemplate.from_messages([        (&quot;system&quot;, system),        (&quot;placeholder&quot;, &quot;&#123;chat_history&#125;&quot;),        (&quot;human&quot;, &quot;&#123;input&#125;&quot;),        (&quot;placeholder&quot;, &quot;&#123;agent_scratchpad&#125;&quot;),    ])        agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)        return agent_executor.invoke(&#123;&quot;input&quot;: query&#125;)[&#x27;output&#x27;]def main():    init_session_state()    # 主标题    st.markdown(&#x27;&lt;h1 class=&quot;main-header&quot;&gt;🤖 LangChain B站公开课 By九天Hector&lt;/h1&gt;&#x27;, unsafe_allow_html=True)    st.markdown(        &#x27;&lt;div style=&quot;text-align: center; margin-bottom: 2rem; color: #666;&quot;&gt;集PDF问答与数据分析于一体的智能助手&lt;/div&gt;&#x27;,        unsafe_allow_html=True)        # 创建两个主要功能的标签页    tab1, tab2 = st.tabs([&quot;📄 PDF智能问答&quot;, &quot;📊 CSV数据分析&quot;])        # PDF问答模块    with tab1:        col1, col2 = st.columns([2, 1])            with col1:            st.markdown(&quot;### 💬 与PDF文档对话&quot;)                # 显示数据库状态            if check_database_exists():                st.markdown(                    &#x27;&lt;div class=&quot;info-card success-card&quot;&gt;&lt;span class=&quot;status-indicator status-ready&quot;&gt;✅ PDF数据库已准备就绪&lt;/span&gt;&lt;/div&gt;&#x27;,                    unsafe_allow_html=True)            else:                st.markdown(                    &#x27;&lt;div class=&quot;info-card warning-card&quot;&gt;&lt;span class=&quot;status-indicator status-waiting&quot;&gt;⚠️ 请先上传并处理PDF文件&lt;/span&gt;&lt;/div&gt;&#x27;,                    unsafe_allow_html=True)                # 聊天界面            for message in st.session_state.pdf_messages:                with st.chat_message(message[&quot;role&quot;]):                    st.markdown(message[&quot;content&quot;])                # 用户输入            if pdf_query := st.chat_input(&quot;💭 向PDF提问...&quot;, disabled=not check_database_exists()):                st.session_state.pdf_messages.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: pdf_query&#125;)                with st.chat_message(&quot;user&quot;):                    st.markdown(pdf_query)                    with st.chat_message(&quot;assistant&quot;):                    with st.spinner(&quot;🤔 AI正在分析文档...&quot;):                        response = get_pdf_response(pdf_query)                    st.markdown(response)                    st.session_state.pdf_messages.append(&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response&#125;)            with col2:            st.markdown(&quot;### 📁 文档管理&quot;)                # 文件上传            pdf_docs = st.file_uploader(                &quot;📎 上传PDF文件&quot;,                accept_multiple_files=True,                type=[&#x27;pdf&#x27;],                help=&quot;支持上传多个PDF文件&quot;            )                if pdf_docs:                st.success(f&quot;📄 已选择 &#123;len(pdf_docs)&#125; 个文件&quot;)                for i, pdf in enumerate(pdf_docs, 1):                    st.write(f&quot;• &#123;pdf.name&#125;&quot;)                # 处理按钮            if st.button(&quot;🚀 上传并处理PDF文档&quot;, disabled=not pdf_docs, use_container_width=True):                with st.spinner(&quot;📊 正在处理PDF文件...&quot;):                    try:                        raw_text = pdf_read(pdf_docs)                        if not raw_text.strip():                            st.error(&quot;❌ 无法从PDF中提取文本&quot;)                            return                            text_chunks = get_chunks(raw_text)                        st.info(f&quot;📝 文本已分割为 &#123;len(text_chunks)&#125; 个片段&quot;)                            vector_store(text_chunks)                        st.success(&quot;✅ PDF处理完成！&quot;)                        st.balloons()                        st.rerun()                        except Exception as e:                        st.error(f&quot;❌ 处理PDF时出错: &#123;str(e)&#125;&quot;)                # 清除数据库            if st.button(&quot;🗑️ 清除PDF数据库&quot;, use_container_width=True):                try:                    import shutil                    if os.path.exists(&quot;faiss_db&quot;):                        shutil.rmtree(&quot;faiss_db&quot;)                    st.session_state.pdf_messages = []                    st.success(&quot;数据库已清除&quot;)                    st.rerun()                except Exception as e:                    st.error(f&quot;清除失败: &#123;e&#125;&quot;)        # CSV数据分析模块    with tab2:        col1, col2 = st.columns([2, 1])            with col1:            st.markdown(&quot;### 📈 数据分析对话&quot;)                # 显示数据状态            if st.session_state.df is not None:                st.markdown(                    &#x27;&lt;div class=&quot;info-card success-card&quot;&gt;&lt;span class=&quot;status-indicator status-ready&quot;&gt;✅ 数据已加载完成&lt;/span&gt;&lt;/div&gt;&#x27;,                    unsafe_allow_html=True)            else:                st.markdown(                    &#x27;&lt;div class=&quot;info-card warning-card&quot;&gt;&lt;span class=&quot;status-indicator status-waiting&quot;&gt;⚠️ 请先上传CSV文件&lt;/span&gt;&lt;/div&gt;&#x27;,                    unsafe_allow_html=True)                # 聊天界面            for message in st.session_state.csv_messages:                with st.chat_message(message[&quot;role&quot;]):                    if message[&quot;type&quot;] == &quot;dataframe&quot;:                        st.dataframe(message[&quot;content&quot;])                    elif message[&quot;type&quot;] == &quot;image&quot;:                        st.write(message[&quot;content&quot;])                        if os.path.exists(&#x27;plot.png&#x27;):                            st.image(&#x27;plot.png&#x27;)                    else:                        st.markdown(message[&quot;content&quot;])                # 用户输入            if csv_query := st.chat_input(&quot;📊 分析数据...&quot;, disabled=st.session_state.df is None):                st.session_state.csv_messages.append(&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: csv_query, &quot;type&quot;: &quot;text&quot;&#125;)                with st.chat_message(&quot;user&quot;):                    st.markdown(csv_query)                    with st.chat_message(&quot;assistant&quot;):                    with st.spinner(&quot;🔄 正在分析数据...&quot;):                        response = get_csv_response(csv_query)                        if isinstance(response, pd.DataFrame):                        st.dataframe(response)                        st.session_state.csv_messages.append(                            &#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response, &quot;type&quot;: &quot;dataframe&quot;&#125;)                    elif &quot;GRAPH&quot; in str(response):                        text = str(response)[str(response).find(&quot;GRAPH&quot;) + 6:]                        st.write(text)                        if os.path.exists(&#x27;plot.png&#x27;):                            st.image(&#x27;plot.png&#x27;)                        st.session_state.csv_messages.append(&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: text, &quot;type&quot;: &quot;image&quot;&#125;)                    else:                        st.markdown(response)                        st.session_state.csv_messages.append(&#123;&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: response, &quot;type&quot;: &quot;text&quot;&#125;)            with col2:            st.markdown(&quot;### 📊 数据管理&quot;)                # CSV文件上传            csv_file = st.file_uploader(&quot;📈 上传CSV文件&quot;, type=&#x27;csv&#x27;)            if csv_file:                st.session_state.df = pd.read_csv(csv_file)                st.success(f&quot;✅ 数据加载成功!&quot;)                    # 显示数据预览                with st.expander(&quot;👀 数据预览&quot;, expanded=True):                    st.dataframe(st.session_state.df.head())                    st.write(f&quot;📏 数据维度: &#123;st.session_state.df.shape[0]&#125; 行 × &#123;st.session_state.df.shape[1]&#125; 列&quot;)                # 数据信息            if st.session_state.df is not None:                if st.button(&quot;📋 显示数据信息&quot;, use_container_width=True):                    with st.expander(&quot;📊 数据统计信息&quot;, expanded=True):                        st.write(&quot;**基本信息:**&quot;)                        st.text(f&quot;行数: &#123;st.session_state.df.shape[0]&#125;&quot;)                        st.text(f&quot;列数: &#123;st.session_state.df.shape[1]&#125;&quot;)                        st.write(&quot;**列名:**&quot;)                        st.write(list(st.session_state.df.columns))                        st.write(&quot;**数据类型:**&quot;)                        # 修复：将dtypes转换为字符串格式显示                        dtype_info = pd.DataFrame(&#123;                            &#x27;列名&#x27;: st.session_state.df.columns,                            &#x27;数据类型&#x27;: [str(dtype) for dtype in st.session_state.df.dtypes]                        &#125;)                        st.dataframe(dtype_info, use_container_width=True)                # 清除数据            if st.button(&quot;🗑️ 清除CSV数据&quot;, use_container_width=True):                st.session_state.df = None                st.session_state.csv_messages = []                if os.path.exists(&#x27;plot.png&#x27;):                    os.remove(&#x27;plot.png&#x27;)                st.success(&quot;数据已清除&quot;)                st.rerun()        # 底部信息    st.markdown(&quot;---&quot;)    col1, col2, col3 = st.columns(3)    with col1:        st.markdown(&quot;**🔧 技术栈:**&quot;)        st.markdown(&quot;• LangChain • Streamlit • FAISS • DeepSeek&quot;)    with col2:        st.markdown(&quot;**✨ 功能特色:**&quot;)        st.markdown(&quot;• PDF智能问答 • 数据可视化分析&quot;)    with col3:        st.markdown(&quot;**💡 使用提示:**&quot;)        st.markdown(&quot;• 支持多文件上传 • 实时对话交互&quot;)if __name__ == &quot;__main__&quot;:    main() \n\n✅ 总结（核心功能架构）\n\n\n\n模块\n技术组件\n说明\n\n\n\nPDF 问答\nFAISS + Retriever Tool\n构成 RAG 检索增强流程\n\n\nCSV 分析\nPythonAstREPLTool + Pandas\n实现代码生成 + 可视化\n\n\nLLM\nDeepSeek Chat\n统一 Agent 调用\n\n\n向量库\nDashScope Embedding + FAISS\n支持中文语义匹配\n\n\nUI\nStreamlit + 自定义 CSS\n提供多 Tab 页面与交互式聊天\n\n\n状态管理\nst.session_state\n管理历史、数据、图片等上下文\n\n\n这里不再重复赘述PDF智能问答的流程，重点说明CSV数据智能分析的流程。\nStep 1. CSV 文件上传与 DataFrame 显示\n用户上传 .csv 文件后由 pandas.read_csv() 加载为 DataFrame，实时预览数据行列、列名、类型等信息。\nst.session_state.df = pd.read_csv(csv_file)st.dataframe(st.session_state.df.head())\n\nStep 2. 构建代码执行工具 Agent\n构建系统提示，注入 DataFrame 的 .head() 输出增强语境理解，使用 PythonAstREPLTool 工具允许模型执行基于 df 的代码分析，通过 create_tool_calling_agent 构建分析 Agent，可执行筛选、分组、聚合等 pandas 操作，图表绘制（保存为 plot.png，关键词识别后渲染）。\ntools = [PythonAstREPLTool(locals=&#123;&quot;df&quot;: st.session_state.df&#125;)]\n\nStep 3. 图表识别与自动展示\n若模型返回内容中包含 “GRAPH:”，则自动读取 plot.png 并展示；支持 plt.hist()、plt.bar() 等可视化命令；会话记录中分类保存文本、图像与表格类型内容。\n","categories":["学习"],"tags":["教程","知识总结","LangChain"]},{"title":"对内容进行了一些完善","url":"/2024/10/05/add-something-new/","content":"\n\n\n因为闲着所以试一些有意思的小玩意儿,不知道有没有人看得到哈哈哈哈哈哈 \n首先就是使用了隐藏文本\n以后可以说一些悄悄话了（）\n新增了跳转链接尝试与 Rhodes Island™ 取得弱神经连接：\n\n        \n        Rhodes Island™'与  Rhodes  Island™  取得弱神经连接'\n\n想添加自己的链接可以联系我\n新增了音乐播放器放一首我听得最多的\n&nbsp;\n\n思绪绵绵呀\n新增了一只噬元兽没错，就是左下角这一只（不知道你们有没有看到，毕竟隐身了）\n在添加的过程中看到有个博客有罗小黑的桌宠，本来打算也添加一个的，但是忘记收藏，导致现在找不到那个博客了。后来我也在B站上找到了lpk文件，尝试了一上午加半个下午，仍然不知道怎么添加，只能作罢。。（如果有谁看到那个用了罗小黑的博客或者知道怎么在web上使用lpk文件，请联系我，不胜感激）\n新增了本站运行时间在右下角哟\n特意把时间设置成北京时间，可以当作时钟（我多贴心），但是久了之后时间会变慢记得刷新一下网页哟\n\n新增了点击特效就用《起风了》的歌词吧 不要问我为什么，多听几遍就知道了\n希望你们喜欢\n点下去的时候是烟花，松开的时候是歌词，有个时间差更容易看见歌词（可以等烟花散了再松开）\n\n新增了彩色滚动字体  \n    \n  \n    var binft = function (r) {\n      function t() {\n        return b[Math.floor(Math.random() * b.length)]\n      }  \n      function e() {\n        return String.fromCharCode(94 * Math.random() + 33)\n      }\n      function n(r) {\n        for (var n = document.createDocumentFragment(), i = 0; r > i; i++) {\n          var l = document.createElement(\"span\");\n          l.textContent = e(), l.style.color = t(), n.appendChild(l)\n        }\n        return n\n      }\n      function i() {\n        var t = o[c.skillI];\n        c.step ? c.step-- : (c.step = g, c.prefixP < l.length ? (c.prefixP >= 0 && (c.text += l[c.prefixP]), c.prefixP++) : \"forward\" === c.direction ? c.skillP < t.length ? (c.text += t[c.skillP], c.skillP++) : c.delay ? c.delay-- : (c.direction = \"backward\", c.delay = a) : c.skillP > 0 ? (c.text = c.text.slice(0, -1), c.skillP--) : (c.skillI = (c.skillI + 1) % o.length, c.direction = \"forward\")), r.textContent = c.text, r.appendChild(n(c.prefixP < l.length ? Math.min(s, s + c.prefixP) : Math.min(s, t.length - c.skillP))), setTimeout(i, d)\n      }\n      var l = \"\",\n      o = [\"这一路上走走停停\",\"顺着少年漂流的痕迹\",\"迈出车站的前一刻\",\"竟有些犹豫\",\"不禁笑这近乡情怯\",\"仍无法避免\",\"而长野的天\",\"依旧那么暖\",\"风吹起了从前\",\"从前初识这世间\",\"万般流连\",\"看着天边似在眼前\",\"也甘愿赴汤蹈火去走它一遍\",\"如今走过这世间\",\"万般流连\",\"翻过岁月不同侧脸\",\"措不及防闯入你的笑颜\",\"我曾难自拔于世界之大\",\"也沉溺于其中梦话\",\"不得真假 不做挣扎 不惧笑话\",\"我曾将青春翻涌成她\",\"也曾指尖弹出盛夏\",\"心之所动 且就随缘去吧\",\"逆着光行走 任风吹雨打\",\"短短的路走走停停\",\"也有了几分的距离\",\"不知抚摸的是故事\",\"还是段心情\",\"也许期待的不过是\",\"与时间为敌\",\"再次见到你\",\"微凉晨光里\",\"笑得很甜蜜\",\"从前初识这世间\",\"万般流连\",\"看着天边似在眼前\",\"也甘愿赴汤蹈火去走它一遍\",\"如今走过这世间\",\"万般流连\",\"翻过岁月不同侧脸\",\"措不及防闯入你的笑颜\",\"我曾难自拔于世界之大\",\"也沉溺于其中梦话\",\"不做真假 不做挣扎 不惧笑话\",\"我曾将青春翻涌成她\",\"也曾指尖弹出盛夏\",\"心之所动 且就随缘去吧\",\"晚风吹起你鬓间的白发\",\"抚平回忆留下的疤\",\"你的眼中 明暗交杂 一笑生花\",\"暮色遮住你蹒跚的步伐\",\"走进床头藏起的画\",\"画中的你 低着头说话\",\"我仍感叹于世界之大\",\"也沉醉于儿时情话\",\"不剩真假 不做挣扎 无谓笑话\",\"我终将青春还给了她\",\"连同指尖弹出的盛夏\",\"心之所动 就随风去了\",\"以爱之名 你还愿意吗\"].map(function (r) {\n      return r + \"\"\n      }),\n      a = 15,//文字保留时间\n      g = 1,//文字出现速度 越大越慢\n      s = 4,//乱码长度\n      d = 50,//单个乱码展示时间\n      b = [\"rgb(110,64,170)\", \"rgb(150,61,179)\", \"rgb(191,60,175)\", \"rgb(228,65,157)\", \"rgb(254,75,131)\", \"rgb(255,94,99)\", \"rgb(255,120,71)\", \"rgb(251,150,51)\", \"rgb(226,183,47)\", \"rgb(198,214,60)\", \"rgb(175,240,91)\", \"rgb(127,246,88)\", \"rgb(82,246,103)\", \"rgb(48,239,130)\", \"rgb(29,223,163)\", \"rgb(26,199,194)\", \"rgb(35,171,216)\", \"rgb(54,140,225)\", \"rgb(76,110,219)\", \"rgb(96,84,200)\"],\n      c = {\n        text: \"\",\n        prefixP: -s,\n        skillI: 0,\n        skillP: 0,\n        direction: \"forward\",\n        delay: a,\n        step: g\n      };\n      i()\n      };\n      binft(document.getElementById('binft'));\n   \n\n\n\n\n刷新一下就能显示了，目前还是一个bug\n\n改进了折叠文本\n        \n            \n            \n            明日方舟语录\n\n        \n        是棋子，那就吃掉；是堡垒，那就攻陷；是王权，那就推翻。&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;——《明日方舟》觉得很霸气所以选这一句\n\n        \n\n\n\n\n杂记\n昨天成功捕捉噬元兽，带着她去看了尾巴的伤口并顺带做了绝育\n\n \n\n\n\n伤的挺严重的，已经感染了，幸好及时送到医院\n\n \n\n\n最后再附上几张 令 的图作为结束吧\n\n\n\n\n\n令 还是挺帅的\n\n","categories":["记录生活"],"tags":["功能拓展"]},{"title":"算法题的错题整理及反思","url":"/2024/10/27/algorithm/","content":"这是关于算法题的整理及思考\n\n\n题目来源不一定，主要来源应该是CF、洛谷等\n也会包含一些关于比赛的反思等\n水平较低哈哈哈哈哈哈哈哈哈，还在尝试中\n\nCodeforces Round 982 (Div. 2) B标签：\n\n\n暴力枚举（brute force）\n贪心（greedy）\n\n\n题目：\n\n\nProblem-B-Codeforces\nStalin Sort-洛谷\n\n\n题目大意\n\n给出一个数组，问是否可以通过对其任意子数组进行多次斯大林排序，使得最终的数组是非增的。\n*子数组指的是任意一段连续子数组，斯大林排序指将严格降序的元素剔除，具体定义见题目\n\n思路分析：\n\n通过斯大林排序的定义可知\n\n任何一段数组进行斯大林排序后第一个元素都不会改变\n\n如果处理完的数组元素大于等于两个，则按非降序排列\n\n\n进一步分析\n\n对于使用斯大林排序的任意子数组，如果存在大于第一个元素的其他元素则会被保留，而小于第一个元素的一定会被剔除因此要使最后是非降序的，就必须要把子数组中大于第一个元素的其他元素都剔除掉\n那么要使剔除后的数组是可以通过对其任意子数组进行多次斯大林排序，使得最终的数组是非增的就要使剔除后的数组的首元素最大\n接下来只需要从头遍历整个数组，找到有最多元素的满足首元素最大的数组（不一定连续）即可\n即对数组中的每个元素寻找有多少个（k）在他之后的不大于他的元素，并记录下最大值（f）\n将元素总个数减去（最大值+1）就是其他要剔除的元素的个数\n\n\n\n        \n            \n            \n            可能的疑问\n\n        \n        \n问题一：对每个元素只考虑后面的其他元素，为什么不用考虑前面的其他元素就把他们全部剔除\n答：\n\n如果前面的元素大于等于该元素，则前面元素遍历时的值k1就会大于该值k2，那么f就会等于k1，不影响\n如果前面的元素小于该元素，则必须剔除，否则剔除后的数组的首元素就不是最大的，那么就不满足要求\n\n\n\n        \n\n思路误区：\n\n比赛时想的是减序列通过斯大林排序一定会消失，所以先对整个数组进行一次斯大林排序，得到非减序列，再把第一次出现的最大值前的元素全部剔除掉，那么剩下的就是非增序列了，问题在于在第一次通过斯大林排序时删掉的元素仍在剔除元素后的数组之中，此时数组还可能存在递增序列，不满足题意很烦的是样例给的随便过，比赛时一直没找到问题所在\n\n代码：\n#include &lt;bits/stdc++.h&gt;using namespace std;int main() {    int t;    cin &gt;&gt; t; // 读取测试用例数量      while (t--)    {        int n;        cin &gt;&gt; n;        int* a = new int[n + 1];        for (int i = 0; i &lt; n; i++)        {            cin &gt;&gt; a[i];        }        int f = 0;        for (int i = 0; i &lt; n - 1; i++)        {            int k = 0;            for (int j = i + 1; j &lt; n; j++)            {                if (a[j] &lt;= a[i])                    k++;            }            f = max(f, k);        }        cout &lt;&lt; n - (f + 1) &lt;&lt; endl;        delete[] a;    }    return 0;}\n\nEducational Codeforces Round 115 (Rated for Div. 2) C标签：\n\n\n暴力\n\n\n题目：\n\n\nProblem - C - Codeforces\n\n\n题目大意\n\n从数组中删掉两个数使得数学平均值不变，问一共有多少组\n\n思路分析：\n\nFirst of all, instead of the mathematic mean, let’s consider the sum of elements. If the mathematic mean is , then the sum of elements of the array is . Let’s denote the sum of elements in the original array as . Note  is always an integer.\nIf we remove two elements from the array, the resulting sum of elements should become . So, the sum of the elements we remove should be exactly .\nIf  is not an integer, the answer is  (to check that, you can simply compare  with ). Otherwise, we have to find the number of pairs  such that  and . This is a well-known problem.\nTo solve it, you can calculate the number of occurrences of each element and store it in some associative data structure (for example, map in C++). Let  be the number of occurrences of element . Then, you should iterate on the element  you want to remove and check how many elements match it, that is, how many elements give exactly  if you add  to them. The number of these elements is just . Let’s sum up all these values for every element in the array.\nUnfortunately, this sum is not the answer yet. We need to take care of two things:\n\nif for some index , , then  matches itself, so you have to subtract the number of such elements from the answer;\nevery pair of elements is counted twice: the first time when we consider the first element of the pair, and the second time — when we consider the second element of the pair. So, don’t forget to divide the answer by .\n\n\n代码：\n#include &lt;bits/stdc++.h&gt;using namespace std;int main() {  int t;  scanf(\"%d\", &amp;t);  while (t--) {    int n;    scanf(\"%d\", &amp;n);    vector&lt;int&gt; a(n);    map&lt;int, int&gt; cnt;    for (auto &amp;x : a) {      scanf(\"%d\", &amp;x);      cnt[x] += 1;    }    long long sum = accumulate(a.begin(), a.end(), 0LL);    if ((2 * sum) % n != 0) {      puts(\"0\");      continue;    }    long long need = (2 * sum) / n;    long long ans = 0;    for (int i = 0; i &lt; n; ++i) {      int a1 = a[i];      int a2 = need - a1;      if (cnt.count(a2)) ans += cnt[a2];      if (a1 == a2) ans -= 1;    }    printf(\"%lld\\n\", ans / 2);  }}\n\nP9236 [蓝桥杯 2023 省 A] 异或和之和标签：\n\n\n前缀和\n位运算\n\n\n题目：\n\nP9236 蓝桥杯 2023 省 A 异或和之和\n\n题目大意\n\n给定一个数组 ，分别求其每个子段的异或和，并求出它们的和。或者说，对于每组满足 1≤L≤R≤n 的 L,R，求出数组中第 L 至第 R 个元素的异或和。然后输出每组 L,R 得到的结果加起来的值。\n\n思路分析：\n\n首先考虑使用暴力求解，穷举L、R的所有组合，此时时间复杂度为  ，对每种情况从L到R求异或和，则此时时间复杂度为  ，能过30%的数据。\n继续优化，使用前缀异或和，因为每个数和自己的异或和都是0，每个数和零的异或和都是它本身，因此求L到R的异或和就是求 1到L-1的异或和 和 1到R的异或和 的异或和，这样在输入每个数时就能一边输入一边求出前缀异或和并存在数组中。求L到R的异或和只需要将前缀和  与前缀和 求异或和即可。时间复杂度是  ，能够60%的数据。\n继续优化，可以发现前缀和  与前缀和 的异或和的第  （从0开始）位为1时才对结果有贡献  ，而所有L和R的组合恰好是把所有前缀和两两求异或和再求和，因此，我们可以统计出所有前缀和的第  位的1的个数  和0的个数  ，只有第  位是1和0搭配时异或和的第  （从0开始）位才为1，则根据乘法原理一共在第  位的贡献是  ，又因为，因此结果为：，时间复杂度为 ，可以通过该题。具体实现可以对于每一个  前缀和，我们将其按位拆分，并将结果加入计数数组  中。其中 i 表示第 i 个二进制位，j 表示这一位上为 j（只能为 0 或 1）， 表示在所有数中，第 i 个二进制位上为 j 的有 个。\n\n代码：\n#include &lt;bits/stdc++.h&gt;#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;cstring&gt;#include&lt;algorithm&gt; #include&lt;queue&gt;#include&lt;stack&gt;#include&lt;vector&gt;#include&lt;cmath&gt;using namespace std;int main(){\tint n;\tlong long sum=0;\tlong long flag=0;\tlong long A;\tlong long w[25][3]={0}; \tcin&gt;&gt;n;\tlong long *mem=new long long [n+1];\tmem[0]=0;\tfor(int i=1;i&lt;=n;i++)\t{\t\tcin&gt;&gt;A;\t\tmem[i]=mem[i-1]^A;\t}\tfor(int i=0;i&lt;=n;i++)\t{\t\tfor(int j=0;j&lt;=20;j++)\t\t{\t\t\tw[j][mem[i]&gt;&gt;j&amp;1]++;\t\t}\t}\tfor(int i=0;i&lt;=20;i++)\t\tsum+=w[i][0]*w[i][1]*pow(2,i);\tcout&lt;&lt;sum&lt;&lt;endl;\treturn 0;} \n\nP8773 [蓝桥杯 2022 省 A] 选数异或标签：\n\n\n线段树\nST表\n\n\n题目：\n\n蓝桥杯 2022 省 A] 选数异或\n\n题目大意\n\n给定一个长度为  的数列  和一个非负整数 , 给定  次查询, 每次询问能否从某个区间  中选择两个数使得他们的异或等于  。\n\n思路分析：\n\n因为提前给出了，而要^=，则可以根据得出=^，因此可以在输入时就对其进行预处理。我们可以用map记录某个元素最后出现的位置，然后对每一个输入的 我们可以找到其之前的与其异或后为的最后一个元素的位置，记作=^，且可知&lt;并且若不存在则，那么要使区间  中有两个数使得他们的异或等于  ，只需使得该区间内有一个元素的在该区间内即可，即只需要的最大值大于等于即可。我们可以设为  中的最大值，那么只需&gt;=，就能保证在区间  中有至少有两个数使得他们的异或等于 。同时在具体实现上我们可以用在输入数据时就进行预处理。\n\n代码：\n#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;cstring&gt;#include&lt;algorithm&gt; #include&lt;queue&gt;#include&lt;stack&gt;#include&lt;vector&gt;#include&lt;cmath&gt;#include&lt;map&gt;using namespace std;int main(){\tint n,m,x;\tcin&gt;&gt;n&gt;&gt;m&gt;&gt;x;\tmap&lt;int,int&gt; a;\tint A;\tint *f=new int[n+1];\tfor(int i=0;i&lt;=n;i++)\t{\t\tf[i]=0; \t}\tfor(int i=1;i&lt;=n;i++)\t{\t\tcin&gt;&gt;A;\t\tf[i]=max(f[i-1],a[A^x]);\t\ta[A]=i;\t}\tfor(int j=0;j&lt;m;j++)\t{\t\tint l,r;\t\tcin&gt;&gt;l&gt;&gt;r;\t\tif(f[r]&gt;=l)\t\t\tcout&lt;&lt;\"yes\"&lt;&lt;endl;\t\telse\t\t\tcout&lt;&lt;\"no\"&lt;&lt;endl;\t}\treturn 0;} \n\n附记突然发现我都是三分钟热度，隔一段时间就换不同的事做，兜兜转转的，一会做算法，一会做嵌入式，一会做前端，循环往复，结果每件事都做得一般哈哈哈哈哈（看来我是分时操作系统），性格好像也是，有时候很社牛，有时候又很社恐，还是太在意他人的看法吗哈哈哈哈，反正也没什么人会看，就在这底下蛮写这一段话吧，算是对这一段时间的总结，接下来要维持这种样子吗？还是做一些改变？还没想好，但是现在这样也挺舒服的，隔一段时间做一件事不会腻，也算是保持新鲜感的一种方法吧。就先写到这吧（2025.4.9）\n\n打算从下个学期开始重点学习算法（又在立flag了），下个学期应该是没什么事了吧，算法的学习荒废好久了，唉……不过ai现在发展这么迅速，学算法感觉是前途渺茫，还在探索ing…好累，不是身体累，是精神被消耗了，有一种说不上来的无力感，就像席德总期盼着老席德会回来一样，接下来用水浇花（2025.9.22）\n","categories":["学习"],"tags":["算法","错题整理"]},{"title":"新增基于本博客内容回答的ai模块","url":"/2025/06/22/ai/","content":"现在可以通过左边栏的AI模块进入，访问本博客专属的AI喵~\n\n\n目前还有些许问题等待解决\n\n增加公式的在线渲染\n增加AI对本博客的内容总结以及导航\n增加AI的联网功能\n增加访客自定义的角色\n增加图像等文件的上传\n增加流式输出\n增加更强的保护措施\n\n本AI所有聊天记录都是访客的本地保存，刷新后即清空消失，不会上传或存储到任何其他地方，我看不到任何访客的聊天记录，特此声明，可以放心使用。\n","categories":["学习"],"tags":["功能拓展"]},{"title":"复制黏贴时内容异常出错原因分析","url":"/2024/11/20/copy_wrong/","content":"最近我在进行复制黏贴时出现了多次的错误\n\n\n一次是复制一个网址，黏贴看上去也没问题，但是就是跳转不到对应的网页，直到我将他在记事本中黏贴时才发现其变成了一堆乱码\n还有一次是我在网页上拷贝代码，将代码黏贴后看上去也没有任何问题，但就是运行时报错，每一行都报无法识别命令的错\n因此在此记录该问题，并简要分析复制黏贴出错原因\n推荐大家复制黏贴不行时试试自己输入，后续找到克服问题的方法会在此提出，或者尝试下列措施\n\n首先先分析一下为什么复制黏贴会出错\n复制粘贴内容出现不一致或变成乱码的原因可能与以下因素有关：\n1. 字符编码问题\n不同的软件或系统使用的字符编码方式可能不一致（例如 UTF-8、GB2312 等）。当粘贴的内容被另一个程序读取时，如果解码方式不一致，就会导致乱码。\n解决方法：确保复制和粘贴的两端使用相同的字符编码。如果是文档，保存为 UTF-8 通常兼容性较好。\n\n2. 格式问题\n复制的内容可能包含不可见的格式化信息（如字体、颜色、样式等），但目标软件不支持这些格式，可能导致显示异常或部分信息丢失。\n解决方法：尝试使用“纯文本”粘贴（通常是通过 Ctrl+Shift+V 或选择“仅粘贴文本”选项）。\n\n3. 源数据限制\n某些软件（如网页）可能会在复制时附加隐藏代码或广告内容，导致粘贴后出现意外结果。（真可恶）\n解决方法：先粘贴到一个纯文本编辑器（如记事本）中清除多余信息，然后再复制到目标位置。\n\n4. 语言和区域设置冲突\n如果系统的语言或区域设置与粘贴内容不匹配，可能会导致显示不正确。例如，中文文本在未启用中文支持的环境中可能会变成乱码。\n解决方法：检查系统的语言和区域设置，确保支持复制内容的语言。\n\n5. 特殊字符或符号\n某些特殊字符或符号可能在不同的软件或系统中显示效果不同，甚至可能直接变成乱码。\n解决方法：尽量避免使用过多特殊字符，或者确认目标软件是否支持这些字符。\n\n6. 跨平台兼容性问题\nWindows、macOS 和 Linux 之间在处理换行符、制表符等特殊格式时可能存在差异，导致粘贴内容变形。\n解决方法：在跨平台操作时，使用通用工具或格式化工具（如转换成纯文本）处理内容。\n\n7. 剪贴板问题\n剪贴板有时会因为数据量过大或软件冲突而无法正确复制和粘贴。\n解决方法：清空剪贴板后重新操作，或者使用专门的剪贴板管理工具（如 ClipClip）。\n\n8. 目标程序的限制\n某些程序在粘贴时会主动过滤内容或重构格式，导致粘贴结果不同。\n解决方法：尝试不同的粘贴方式，或者检查程序的粘贴选项设置。\n\n","categories":["学习"],"tags":["计算机问题"]},{"title":"杂谈","url":"/2024/02/09/my-first-blog/","content":"这是我的第一个博客嘿嘿嘿\n\n\n这是我的第一个 Blog\n但是我不知道写什么哈哈哈哈哈\n\n\n目前还在测试中\n\n\n如果你感觉无聊你可以看看B站 \n\n关于后续后续我将会发布有关于IT技术、生活等方面的内容，不过我觉得应该不会有什么人看的，所以水一水(雾)。\n关于为什么写博客有两个理由，一个是为了装*，另一个还是为了装*哈哈哈哈哈哈哈哈哈。\n\n好了，正经一点\n\n其实是因为看见大神学长写博客所以突发奇想，想给自己做一个博客(好像还是不是什么正经理由嘿嘿嘿)\n\n时间有点来不及了，还有挺多事要做的，所以先写到这儿吧，现在要发布了(希望能发布成功)\n附一张我最爱的小猪的照片：\n \n再附一张铃兰和罗小黑的动图：\n\n","categories":["记录生活"],"tags":["杂谈"]},{"title":"git介绍","url":"/2025/07/11/git/","content":"前言：最近在做关于C的项目工程，涉及到多人协作以及版本控制，每天都有大量的代码修改，也经常性地回退上几个版本，此时git就非常好用。最近有一个学弟他在修改代码后程序就跑不通了，把修改的地方删掉后仍有非常非常多的报错，因为没有git，他也没办法进行版本回退，只好重新新建一个新的工程，所以我觉得有必要介绍一下git，也作为我自己的一次git的复习，说不定还有什么我漏掉的但是很有用的工具呢。\n\n\n嗯，本来想自己写，发现一个不错的视频就先贴在下面了，后续有其他的视频中没提到的我再补充吧\nGit教程\n😎\n","categories":["学习"],"tags":["资料"]},{"title":"感谢大家","url":"/2024/10/02/thx/","content":"\n感谢我身边的大家，本博客的搭建离不开大家的建议和帮助。\n\n\n特此鸣谢\n","categories":["记录生活"],"tags":["杂谈"]},{"title":"Vscode插件开发教程","url":"/2025/07/17/vscode%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E6%95%99%E7%A8%8B/","content":"本教程记录一次简单的Vscode插件开发过程\n\n\n清理使用管理员权限打开命令行窗口，运行如下命令：\nnpm uninstall -g yo generator-codenpm cache clean --force\n\n使用管理员权限配置环境\n安装Node.js：确保你已安装最新版本的Node.js，使用以下命令验证：\nnode -vnpm -v\n\n如果未安装可按以下步骤使用官方安装包来安装node.js：\n\n卸载旧版本\nnpm uninstall -g npm  # 先卸载npm\n\n访问 Node.js 官网（建议选择 LTS 版本，如 20.x）。下载 .msi 安装包（如 node-v20.x.x-x64.msi）。\n\n双击安装包，全程默认选项（会自动覆盖旧版本并更新环境变量）。\n\n勾选 **Automatically install the necessary tools**（包括 npm 和 Python 等依赖）。\n\n打开新的终端（CMD&#x2F;PowerShell），运行：\nnode -v  # 应显示新版本号（如 v20.x.x）npm -v   # 应显示对应的npm版本\n\n\n安装Yeoman和VS Code扩展生成器：\nnpm install -g yo generator-code\n\n\nyo：Yeoman，一个项目脚手架工具\ngenerator-code：专门用于生成VSCode插件项目的生成器\n\n\n\n创建新插件项目\n运行生成器\nyo code\n\n按照提示选择：\nD:\\my-vscode&gt;yo code     _-----_     ╭──────────────────────────╮    |       |    │   Welcome to the Visual  │    |--(o)--|    │   Studio Code Extension  │   `---------´   │        generator!        │    ( _´U`_ )    ╰──────────────────────────╯    /___A___\\   /     |  ~  |   __&#x27;.___.&#x27;__ ´   `  |° ´ Y `? What type of extension do you want to create? New Extension (JavaScript)? What&#x27;s the name of your extension? rainbow-comments? What&#x27;s the identifier of your extension? rainbow-comments? What&#x27;s the description of your extension? rainbow-comments? Enable JavaScript type checking in &#x27;jsconfig.json&#x27;? No? Initialize a git repository? Yes? Which package manager to use? npm\n\n编写插件代码打开extension.js文件，替换为以下代码：\nconst vscode = require(&#x27;vscode&#x27;);// 定义多种颜色方案const colorSchemes = &#123;    rainbow: [ // 彩虹色        &#x27;#FF0000&#x27;, &#x27;#FF7F00&#x27;, &#x27;#FFFF00&#x27;,         &#x27;#00FF00&#x27;, &#x27;#5ec5f5ff&#x27;, &#x27;#0000FF&#x27;, &#x27;#9400D3&#x27;    ],    pastel: [ // 糖果色        &#x27;#FFD1DC&#x27;, &#x27;#FFECB8&#x27;, &#x27;#E2F0CB&#x27;,        &#x27;#B5EAD7&#x27;, &#x27;#C7CEEA&#x27;, &#x27;#D8B5FF&#x27;    ],    monochrome: [ // 灰色系        &#x27;#6f6f6fff&#x27;    ],    warm: [ // 暖色调        &#x27;#FF6B6B&#x27;, &#x27;#FFA07A&#x27;, &#x27;#FFD166&#x27;,        &#x27;#F7C1BB&#x27;, &#x27;#ff0080ff&#x27;    ],    cool: [ // 冷色调        &#x27;#c6f4fbff&#x27;, &#x27;#a39feaff&#x27;, &#x27;#7BC9FF&#x27;,        &#x27;#9494ffff&#x27;, &#x27;#b1d8fbff&#x27;    ]&#125;;// 清除所有装饰器function clearAllDecorations(editor, decorationTypes) &#123;    decorationTypes.forEach(type =&gt; &#123;        editor.setDecorations(type, []);    &#125;);&#125;/** * 应用颜色方案到注释 * @param &#123;vscode.TextEditor&#125; editor  * @param &#123;string[]&#125; colors  */function applyColorScheme(editor, colors) &#123;    const document = editor.document;    const text = document.getText();    const commentRegex = /(\\/\\/[^\\n]*|\\/\\*[\\s\\S]*?\\*\\/)/g;    let match;    let colorIndex = 0;    const decorations = [];    while ((match = commentRegex.exec(text))) &#123;        const startPos = document.positionAt(match.index);        const endPos = document.positionAt(match.index + match[0].length);                decorations.push(&#123;            range: new vscode.Range(startPos, endPos),            renderOptions: &#123;                color: colors[colorIndex % colors.length],                fontWeight: &#x27;bold&#x27;,                fontStyle: &#x27;italic&#x27;            &#125;        &#125;);        colorIndex++;    &#125;    // 创建装饰器类型并应用    const decorationTypes = colors.map(color =&gt; &#123;        return vscode.window.createTextEditorDecorationType(&#123;            color: color,            fontWeight: &#x27;bold&#x27;,            fontStyle: &#x27;italic&#x27;        &#125;);    &#125;);    // 应用装饰器    colors.forEach((color, index) =&gt; &#123;        const colorDecorations = decorations.filter((d, i) =&gt; i % colors.length === index);        editor.setDecorations(decorationTypes[index], colorDecorations);    &#125;);    return decorationTypes;&#125;function activate(context) &#123;    let activeDecorationTypes = []; // 保存当前活动的装饰器    // 注册多个命令    const commands = [        &#123; name: &#x27;rainbow&#x27;, title: &#x27;注释颜色: 彩虹色&#x27; &#125;,        &#123; name: &#x27;pastel&#x27;, title: &#x27;注释颜色: 糖果色&#x27; &#125;,        &#123; name: &#x27;monochrome&#x27;, title: &#x27;注释颜色: 灰色&#x27; &#125;,        &#123; name: &#x27;warm&#x27;, title: &#x27;注释颜色: 暖色&#x27; &#125;,        &#123; name: &#x27;cool&#x27;, title: &#x27;注释颜色: 冷色&#x27; &#125;,        &#123; name: &#x27;clear&#x27;, title: &#x27;恢复默认注释颜色&#x27; &#125;    ];    commands.forEach(cmd =&gt; &#123;        let disposable = vscode.commands.registerCommand(            `rainbow-comments.$&#123;cmd.name&#125;`,            function () &#123;                const editor = vscode.window.activeTextEditor;                if (!editor) &#123;                    vscode.window.showWarningMessage(&#x27;没有打开的编辑器！&#x27;);                    return;                &#125;                // 清除之前的装饰器                clearAllDecorations(editor, activeDecorationTypes);                activeDecorationTypes = [];                if (cmd.name !== &#x27;clear&#x27;) &#123;                    // 应用新颜色方案                    activeDecorationTypes = applyColorScheme(                        editor,                         colorSchemes[cmd.name]                    );                    vscode.window.showInformationMessage(                        `已应用 $&#123;cmd.title&#125; 方案!`                    );                &#125; else &#123;                    vscode.window.showInformationMessage(&#x27;已清除所有注释颜色&#x27;);                &#125;            &#125;        );        context.subscriptions.push(disposable);    &#125;);&#125;function deactivate() &#123;    // 清理资源&#125;module.exports = &#123;    activate,    deactivate&#125;;\n\n修改package.json在package.json中添加以下内容：\n&quot;contributes&quot;: &#123;    &quot;commands&quot;: [        &#123;            &quot;command&quot;: &quot;rainbow-comments.rainbow&quot;,            &quot;title&quot;: &quot;注释颜色: 彩虹色&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.pastel&quot;,            &quot;title&quot;: &quot;注释颜色: 糖果色&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.monochrome&quot;,            &quot;title&quot;: &quot;注释颜色: 灰色&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.warm&quot;,            &quot;title&quot;: &quot;注释颜色: 暖色&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.cool&quot;,            &quot;title&quot;: &quot;注释颜色: 冷色&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.clear&quot;,            &quot;title&quot;: &quot;恢复默认注释颜色&quot;        &#125;    ],    &quot;menus&quot;: &#123;      &quot;editor/context&quot;: [        &#123;            &quot;command&quot;: &quot;rainbow-comments.rainbow&quot;,            &quot;group&quot;: &quot;rainbow@1&quot;,              &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.pastel&quot;,            &quot;group&quot;: &quot;rainbow@2&quot;,            &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.monochrome&quot;,            &quot;group&quot;: &quot;rainbow@3&quot;,            &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.warm&quot;,            &quot;group&quot;: &quot;rainbow@4&quot;,            &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.cool&quot;,            &quot;group&quot;: &quot;rainbow@5&quot;,            &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;,        &#123;            &quot;command&quot;: &quot;rainbow-comments.clear&quot;,            &quot;group&quot;: &quot;rainbow@6&quot;,            &quot;when&quot;: &quot;editorTextFocus&quot;        &#125;      ]    &#125;  &#125;\n\n运行和测试插件\n按F5启动调试\n在新打开的VSCode窗口中打开一个代码文件\n按Ctrl+Shift+P打开命令面板输入并选择命令\n或者直接右键选择需要执行的命令\n观察你的注释颜色变化\n\n发布插件如果你想分享你的插件：\n\n安装vsce：npm install -g vsce\n创建发布账号：https://aka.ms/vscode-create-publisher\n登录：vsce login &lt;publisher-name&gt; \n打包：vsce package\n发布：vsce publish\n\n或者你也可以：\n\n安装vsce：npm install -g vsce\n创建发布账号：https://aka.ms/vscode-create-publisher\n打包：vsce package\n发布：将生成的.vsix文件拖到上述网页上传 Azure DevOps 扩展中即可\n\n注意：.vsix 文件的发布者信息必须与目标发布者相匹配，即项目中的 package.json 文件中的”publisher”: “xxx”必须与登录的发布者ID完全一致\n示例已将上述插件上传到了 vscode 中的插件应用市场，可以搜索 Zenith-zh 安装后在目标文件中右键启用后查看效果🥰\n","categories":["学习"],"tags":["教程"]},{"title":"Win11蓝牙消失解决方案","url":"/2025/07/15/win11%E8%93%9D%E7%89%99%E6%B6%88%E5%A4%B1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"今天正用着蓝牙，突然鼠标就动不了了，尝试去关蓝牙，发现蓝牙图标在点击后卡死了，打开设置里发现蓝牙也消失了！\n\n\n打开设备管理器打算卸载重装蓝牙，发现连设备管理器里都没有蓝牙，仿佛这台电脑本来就没有蓝牙一般（看来要换成星闪了？）。\n接着又使用 services.msc 重启蓝牙支持服务，发现还是不行！\n作罢，只好重启，但是在重启后连那个卡死的蓝牙图标都没有了，仿佛蓝牙硬件就没存在过。\n但是这肯定是不可能的，所以要不然就是蓝牙硬件坏了，要不然就是驱动问题，推测可能是静电影响了蓝牙硬件的正常工作，在网络上寻找解决方案，发现一种神奇的“释放静电”解决方法：\n\n把所有线都拔了，长按关机键，重新启动。\n\n在尝试后蓝牙也是成功回归，就仿佛它没有离开过一般\n哎，Windows真是个神奇的系统~\n电脑有点大病的时候，可能它只需要关机睡一觉~\n💤\n","categories":["学习"],"tags":["资料"]},{"title":"C++ STL常用内容总结","url":"/2024/10/29/stl/","content":"说明这是关于C++ STL常用内容总结\n强调使用方法，并不强调原理\n本篇博客是我用于个人学习总结用的\n\n\n大部分内容来源于网络和书本，因为是个人整理复习用所以就先不加了，如果后期看的人多我会加上的\n因为还有挺多课的，而且还有比赛和组里的任务，所以可能会不定期不定量更新\n内容可能有不全的，或错误的，欢迎批评指正\n目录主要包含下面几个STL函数\n\n\nvector 动态数组\nstack 栈\nqueue 队列\ndeque 双端队列\npriority_queue 优先队列\nmap 映射\nset 集合\npair 二元组\nstring 字符串\nbitset\narray 数组\ntuple 元组\n……\n\n\n这是目前的安排，计划在11.03前赶完，因为11.03要比赛，11.10还要考离散，中间还要把几次练习赛的题补了。（好忙）\n补：比赛也算是拿了银奖了\n被高中生爆杀\n\n目前（11.02）已将上述STL函数整理完成，算是按时提前完成了吧\n后续会增加一些常用的STL函数，例如sort等\n暂定在12.20前完成后续的补充\n话不多说，接下来进入正题吧\nSTL函数总结vector 动态数组介绍vector为可变长数组（动态数组），定义的vector数组可以随时添加数值和删除元素。\n\n注意：在局部区域中（比如局部函数里面）开vector数组，是在 堆空间 里面开的。\n在局部区域开 数组 是在 栈空间 开的，而栈空间比较小，如果开了非常长的数组就会发生爆栈。\n故局部区域 不可以 开大长度数组，但是可以开大长度vector。\n\n\n头文件：\n#include &lt;vector&gt;\n\n一维初始化：\nvector&lt;int&gt; a; //定义了一个名为a的一维数组,数组存储int类型数据vector&lt;double&gt; b;//定义了一个名为b的一维数组，数组存储double类型数据vector&lt;node&gt; c;//定义了一个名为c的一维数组，数组存储结构体类型数据，node是结构体类型\n\n指定长度和初始值的初始化\nvector&lt;int&gt; v(n);// 定义一个长度为n的数组，初始值默认为0，下标范围 [0, n - 1]vector&lt;int&gt; v(n, 1);//定义一个长度为n的数组，下标范围 [0, n - 1], v[0] 到 v[n - 1]所有的元素初始值均为1//注意：指定数组长度之后（指定长度后的数组就相当于正常的数组了）\n\n初始化中有多个元素\nvector&lt;int&gt; a&#123;1, 2, 3, 4, 5&#125;;//数组a中有五个元素，数组长度就为5\n\n拷贝初始化\nvector&lt;int&gt; a(n + 1, 0);vector&lt;int&gt; b(a); // 两个数组中的类型必须相同,a和b都是长度为n+1，初始值都为0的数组vector&lt;int&gt; c = a; // 也是拷贝初始化,c和a是完全一样的数组\n\n二维初始化\n//定义第一维固定长度为5，第二维可变化的二维数组vector&lt;int&gt; v[5];//定义可变长二维数组//注意：行不可变（只有5行）, 而列可变,可以在指定行添加元素//第一维固定长度为5，第二维长度可以改变\n\n\nvector&lt;int&gt; v[5]可以这样理解：长度为5的v数组，数组中存储的是vector&lt;int&gt; 数据类型，而该类型就是数组形式，故v为二维数组。其中每个数组元素均为空，因为没有指定长度，所以第二维可变长。可以进行下述操作：\nv[1].push_back(2);//第二行尾部增加一个元素 2v[2].push_back(3);//第三行尾部增加一个元素 3\n\n\n行列均可变\n//初始化二维均可变长数组vector&lt;vector&lt;int&gt;&gt; v;//定义一个行和列均可变的二维数组\n\n\n应用：可以在v数组里面装多个数组\nvector&lt;int&gt; t1&#123;1, 2, 3, 4&#125;;vector&lt;int&gt; t2&#123;2, 3, 4, 5&#125;;v.push_back(t1);v.push_back(t2);v.push_back(&#123;3, 4, 5, 6&#125;) // &#123;3, 4, 5, 6&#125;可以作为vector的初始化,相当于一个无名vector\n\n\n行列长度均固定\n\nn + 1行  m + 1列  初始值为0\nvector&lt;vector&lt;int&gt;&gt; a(n + 1, vector&lt;int&gt;(m + 1, 0));//定义一个长度为 n+1 的数组，下标范围 [0, n - 1], a[0] 到 a[n - 1]所有的元素初始值均为vector&lt;int&gt;(m + 1, 0)\n\n\nc++17及以上支持的形式（定义模板类的对象时，可以不指定模板参数，但必须要在构造函数中能推导出模板参数）\nvector a&#123;1, 2, 3, 4, 5&#125;; // 声明一个int类型动态数组，初识元素自己指定vector a(n + 1, vector(m + 1, 0));\n\n方法函数个人认为vector和数组的差距首先是存储位置不一样，vector是在堆空间，数组是在栈空间，其次就是vector中有许多方法函数，这些方法函数可以极大的方便我们编程，解题，不仅仅vector是这样的，其他STL函数也是。但是因为我才刚刚入门，这只是我的一种感觉，具体怎么等我多学一些，学深一些再来补充。先占个坑。\n知道了如何定义初始化可变数组，下面就需要知道如何添加，删除，修改数据。\nc指定为数组名称，含义中会注明算法复杂度。\n\n\n\n代码\n含义\n\n\n\nc.front()\n返回第一个数据O ( 1 )\n\n\nc.back()\n返回数组中的最后一个数据 O ( 1 )\n\n\nc.pop_back()\n删除最后一个数据O ( 1 )\n\n\nc.push_back(element)\n在尾部加一个数据O ( 1 )\n\n\nc.size()\n返回实际数据个数（unsigned类型）O ( 1 )\n\n\nc.clear()\n清除元素个数O ( N )，N为元素个数\n\n\nc.resize(n, v)\n改变数组大小为n,n个空间数值赋为v，如果没有默认赋值为0\n\n\nc.insert(it, x)\n向任意迭代器it（通俗来说就是地址）插入一个元素x ，O ( N )\n\n\nc.erase(first,last)\n删除[first,last)的所有元素，O ( N )\n\n\nc.begin()\n返回首元素的迭代器（通俗来说就是地址）O ( 1 )\n\n\nc.end()\n返回最后一个元素后一个位置的迭代器（地址）O ( 1 )\n\n\nc.empty()\n判断是否为空，为空返回真，反之返回假 O ( 1 )\n\n\n\n注意：\n\nend()返回的是最后一个元素的后一个位置的地址，不是最后一个元素的地址，所有STL容器均是如此\n\n使用 vi.resize(n, v) 函数时，若 vi 之前指定过大小为 pre\n\npre &gt; n ：即数组大小变小了，数组会保存前 n 个元素，前 n 个元素值为原来的值，不都变为 v\npre &lt; n ：即数组大小变大了，数组会在后面插入 n - pre 个值为 v 的元素\n\n也就是说，这个初始值 v 只对新插入的元素生效。\n#include&lt;bits/stdc++.h&gt;using namespace std;void out(vector&lt;int&gt; &amp;a) &#123; for (auto &amp;x: a) cout &lt;&lt; x &lt;&lt; &quot; &quot;; cout &lt;&lt; &quot;\\n&quot;; &#125;int main() &#123;\tvector&lt;int&gt; a(5, 1);\tout(a); // 1 1 1 1 1\ta.resize(10, 2);\tout(a); // 1 1 1 1 1 2 2 2 2 2\ta.resize(3, 3);\tout(a); // 1 1 1\treturn 0;&#125;\n\n\n排序\n使用sort排序要： sort(c.begin(), c.end());\n\nsort()为STL函数，请参考本文最后面STL函数系列。\n\n对所有元素进行排序，如果要对指定区间进行排序，可以对sort()里面的参数进行加减改动。\nvector&lt;int&gt; a(n + 1);sort(a.begin() + 1, a.end()); // 对[1, n]区间进行从小到大排序\n\n访问共三种方法：\n\n下标法 ： 和普通数组一样\n\n注意：一维数组的下标是从 0 到 v.size()-1 ，访问之外的数会出现越界错误\n\n迭代器法 ： 类似指针一样的访问 ，首先需要声明迭代器变量，和声明指针变量一样，可以根据代码进行理解（附有注释）。\nvector&lt;int&gt; vi; //定义一个vi数组vector&lt;int&gt;::iterator it = vi.begin();//声明一个迭代器指向vi的初始位置\n\n使用auto ：非常简便，但是会访问数组的所有元素（特别注意0位置元素也会访问到）\n\n\n下标访问直接和普通数组一样进行访问即可。\n//添加元素for(int i = 0; i &lt; 5; i++)\tvi.push_back(i);\t//下标访问 for(int i = 0; i &lt; 5; i++)\tcout &lt;&lt; vi[i] &lt;&lt; &quot; &quot;;cout &lt;&lt; &quot;\\n&quot;;\n\n迭代器访问类似指针，迭代器就是充当指针的作用。\nvector&lt;int&gt; vi&#123;1, 2, 3, 4, 5&#125;;//迭代器访问vector&lt;int&gt;::iterator it;   // 相当于声明了一个迭代器类型的变量it// 通俗来说就是声明了一个指针变量\n\n\n方法一\nvector&lt;int&gt;::iterator it = vi.begin(); for(int i = 0; i &lt; 5; i++)\tcout &lt;&lt; *(it + i) &lt;&lt; &quot; &quot;;cout &lt;&lt; &quot;\\n&quot;;\n\n方法二\nvector&lt;int&gt;::iterator it;for(it = vi.begin(); it != vi.end();it ++)\tcout &lt;&lt; *it &lt;&lt; &quot; &quot;;//vi.end()指向尾元素地址的下一个地址// 或者auto it = vi.begin();while (it != vi.end()) &#123;    cout &lt;&lt; *it &lt;&lt; &quot;\\n&quot;;    it++;&#125;\n\n智能指针只能遍历完数组，如果要指定的内容进行遍历，需要另选方法。\nauto 能够自动识别并获取类型。\n// 1. 输入vector&lt;int&gt; a(n);for (auto &amp;x: a) &#123;    cin &gt;&gt; x; // 可以进行输入，注意加引用&#125;// for (auto &amp;x: a)：这是一个范围for循环，用于遍历向量a中的每个元素。auto关键字自动推导变量x的类型，这里x的类型将是int&amp;（整数的引用），因为我们在循环中使用了引用&amp;。使用引用的好处是可以直接修改向量中的元素值。// 2. 输出vector&lt;int&gt; v;v.push_back(12);v.push_back(241);for(auto val : v) &#123;\tcout &lt;&lt; val &lt;&lt; &quot; &quot;; // 12 241&#125;\n\n\nvector注意：\n\nvi[i] 和 *(vi.begin() + i) 等价，与指针类似。\nvector和string的STL容器支持*(it + i)的元素访问，其它容器可能也可以支持这种方式访问，但用的不多，可自行尝试。\n\n\nstack 栈介绍栈为数据结构的一种，是STL中实现的一个先进后出，后进先出的容器。\n\n头文件\n//头文件需要添加#include&lt;stack&gt;\n\n声明\n//声明stack&lt;int&gt; s;stack&lt;string&gt; s;stack&lt;node&gt; s;//node是结构体类型\n\n方法函数\n\n\n代码\n含义\n\n\n\ns.push(ele)\n元素ele入栈，增加元素 O ( 1 )\n\n\ns.pop()\n移除栈顶元素 O ( 1 )\n\n\ns.top()\n取得栈顶元素（但不删除）O ( 1 )\n\n\ns.empty()\n检测栈内是否为空，空为真 O ( 1 )\n\n\ns.size()\n返回栈内元素的个数 O ( 1 )\n\n\n栈遍历栈遍历栈只能对栈顶元素进行操作，如果想要进行遍历，只能将栈中元素一个个取出来存在数组中\nstack&lt;int&gt; st;for (int i = 0; i &lt; 10; ++i) st.push(i);while (!st.empty()) &#123;    int tp = st.top(); // 栈顶元素    st.pop();&#125;\n\n数组模拟栈进行遍历通过一个数组对栈进行模拟，一个存放下标的变量top模拟指向栈顶的指针。\n\n一般来说单调栈和单调队列写法均可使用额外变量 tt 或 hh 来进行模拟\n\n特点： 比STL的stack速度更快，遍历元素方便\nint s[100]; // 栈 从左至右为栈底到栈顶int tt = -1; // tt 代表栈顶指针,初始栈内无元素，tt为-1for(int i = 0; i &lt;= 5; ++i) &#123;\t//入栈 \ts[++tt] = i;&#125;// 出栈int top_element = s[tt--]; //入栈操作示意//  0  1  2  3  4  5  //                tt//出栈后示意//  0  1  2  3  4 //              tt\n\nqueue 队列介绍队列是一种先进先出的数据结构。\n\n头文件\n//头文件#include&lt;queue&gt;\n\n定义初始化\n//定义初始化queue&lt;int&gt; q;\n\n方法函数\n\n\n代码\n含义\n\n\n\nq.front()\n返回队首元素 O ( 1 )\n\n\nq.back()\n返回队尾元素 O ( 1 )\n\n\nq.push(element)\n尾部添加一个元素element 进队O ( 1 )\n\n\nq.pop()\n删除第一个元素 出队 O ( 1 )\n\n\nq.size()\n返回队列中元素个数，返回值类型unsigned int O ( 1 )\n\n\nq.empty()\n判断是否为空，队列为空，返回true O ( 1 )\n\n\n队列模拟使用q[]数组模拟队列\nhh表示队首元素的下标，初始值为0\ntt表示队尾元素的下标，初始值为-1，表示刚开始队列为空\n\n一般来说单调栈和单调队列写法均可使用额外变量 tt 或 hh 来进行模拟\n\n#include&lt;bits/stdc++.h&gt;using namespace std;const int N = 1e5 + 5;int q[N];int main() &#123;\tint hh = 0,tt = -1;//\t入队 \tq[++tt] = 1;\tq[++tt] = 2; //\t将所有元素出队 \twhile(hh &lt;= tt) &#123;\t\tint t = q[hh++];\t\tprintf(&quot;%d &quot;,t);\t&#125;\treturn 0; &#125; \n\ndeque  双端队列介绍首尾都可插入和删除的队列为双端队列。\n\n头文件\n//添加头文件#include&lt;deque&gt;\n\n初始化定义\n//初始化定义deque&lt;int&gt; dq;\n\n方法函数\n注意双端队列的常数比较大。\n\n\n\n\n代码\n含义\n\n\n\npush_back(x)&#x2F;push_front(x)\n把x插入队尾后 &#x2F; 队首 O ( 1 )\n\n\nback()&#x2F;front()\n返回队尾 &#x2F; 队首元素 O ( 1 )\n\n\npop_back() &#x2F; pop_front()\n删除队尾 &#x2F; 队首元素 O ( 1 )\n\n\nerase(iterator it)\n删除双端队列中的某一个元素\n\n\nerase(iterator first,iterator last)\n删除双端队列中[first,last)中的元素\n\n\nempty()\n判断deque是否空 O ( 1 )\n\n\nsize()\n返回deque的元素数量 O ( 1 )\n\n\nclear()\n清空deque\n\n\n注意点deque可以进行排序\n\n双端队列排序一般不用，感觉毫无用处，使用其他STL依然可以实现相同功能\n\n//从小到大sort(q.begin(), q.end())//从大到小排序sort(q.begin(), q.end(), greater&lt;int&gt;());//deque里面的类型需要是int型sort(q.begin(), q.end(), greater());//高版本C++才可以用\n\npriority_queue 优先队列介绍优先队列是在正常队列的基础上加了优先级，保证每次的队首元素都是优先级最大的。\n可以实现每次从优先队列中取出的元素都是队列中优先级最大的一个。\n它的底层是通过堆来实现的。\n\n头文件\n//头文件#include&lt;queue&gt;\n\n初始化\n//初始化定义priority_queue&lt;int&gt; q;\n\n函数方法\n\n\n代码\n含义\n\n\n\nq.top()\n访问队首元素 O ( 1 )\n\n\nq.push()\n入队 O ( l o g N )\n\n\nq.pop()\n堆顶（队首）元素出队 O ( l o g N )\n\n\nq.size()\n队列元素个数 O ( 1 )\n\n\nq.empty()\n是否为空 O ( 1 )\n\n\n注意没有clear()！不提供该方法\n优先队列只能通过top()访问队首元素（优先级最高的元素）\n设置优先级基本数据类型的优先级priority_queue&lt;int&gt; pq; // 默认大根堆, 即每次取出的元素是队列中的最大值priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q; // 小根堆, 每次取出的元素是队列中的最小值\n\n参数解释：\n\n第一个参数：就是优先队列中存储的数据类型\n\n第二个参数：\nvector&lt;int&gt; 是用来承载底层数据结构堆的容器，若优先队列中存放的是double型数据，就要填vector&lt;double&gt;总之存的是什么类型的数据，就相应的填写对应类型。同时也要改动第三个参数里面的对应类型。\n\n第三个参数：\nless&lt;int&gt; 表示数字大的优先级大，堆顶为最大的数字greater&lt;int&gt;表示数字小的优先级大，堆顶为最小的数字int代表的是数据类型，也要填优先队列中存储的数据类型\n\n\n\n\n基础写法（非常常用）：\npriority_queue&lt;int&gt; q1; // 默认大根堆, 即每次取出的元素是队列中的最大值priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt; &gt; q2; // 大根堆, 每次取出的元素是队列中的最大值，同第一行priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt; &gt; q3; // 小根堆, 每次取出的元素是队列中的最小值\n\n自定义排序（不常见，主要是写着麻烦）：\n下面的代码比较长，基础类型优先级写着太麻烦，用基础写法即可。\nstruct cmp1 &#123;\tbool operator()(int x, int y) &#123;\t\treturn x &gt; y;\t&#125;&#125;;struct cmp2 &#123;\tbool operator()(const int x, const int y) &#123;\t\treturn x &lt; y;\t&#125;&#125;;priority_queue&lt;int, vector&lt;int&gt;, cmp1&gt; q1; // 小根堆priority_queue&lt;int, vector&lt;int&gt;, cmp2&gt; q2; // 大根堆\n\n高级数据类型(结构体)优先级\n即优先队列中存储结构体类型，必须要设置优先级，即结构体的比较运算（因为优先队列的堆中要比较大小，才能将对应最大或者最小元素移到堆顶）。\n\n优先级设置可以定义在结构体内进行小于号重载，也可以定义在结构体外。\n//要排序的结构体（存储在优先队列里面的）struct Point &#123;\tint x, y;&#125;;\n\n\n版本一：自定义全局比较规则\n//定义的比较结构体//注意：cmp是个结构体 struct cmp &#123;//自定义堆的排序规则 \tbool operator()(const Point&amp; a,const Point&amp; b) &#123;\t\treturn a.x &lt; b.x;\t&#125;&#125;;//初始化定义， priority_queue&lt;Point, vector&lt;Point&gt;, cmp&gt; q; // x大的在堆顶\n\n版本二：直接在结构体里面写\n\n因为是在结构体内部自定义的规则，一旦需要比较结构体，自动调用结构体内部重载运算符规则。\n\n结构体内部有两种方式：\n\n方式一 ：\nstruct node &#123;\tint x, y;\tfriend bool operator &lt; (Point a, Point b) &#123;//为两个结构体参数，结构体调用一定要写上friend\t\treturn a.x &lt; b.x;//按x从小到大排，x大的在堆顶\t&#125;&#125;;\n\n方式二 ：（推荐此种）\nstruct node &#123;    int x, y;    bool operator &lt; (const Point &amp;a) const &#123;//直接传入一个参数，不必要写friend        return x &lt; a.x;//按x升序排列，x大的在堆顶    &#125;&#125;;\n\n优先队列的定义\npriority_queue&lt;Point&gt; q;\n\n注意： 优先队列自定义排序规则和sort()函数定义cmp函数很相似，但是最后返回的情况是相反的。即相同的符号，最后定义的排列顺序是完全相反的。所以只需要记住sort的排序规则和优先队列的排序规则是相反的就可以了。\n\n当理解了堆的原理就会发现，堆调整时比较顺序是孩子和父亲节点进行比较，如果是 &gt; ，那么孩子节点要大于父亲节点，堆顶自然是最小值。\n\n\n\n\n\n存储特殊类型的优先级存储pair类型\n排序规则：默认先对pair的first进行降序排序，然后再对second降序排序对first先排序，大的排在前面，如果first元素相同，再对second元素排序，保持大的在前面。\n#include&lt;bits/stdc++.h&gt;using namespace std;int main() &#123;    priority_queue&lt;pair&lt;int, int&gt; &gt;q;\tq.push(&#123;7, 8&#125;);\tq.push(&#123;7, 9&#125;);\tq.push(make_pair(8, 7));    while(!q.empty()) &#123;        cout &lt;&lt; q.top().first &lt;&lt; &quot; &quot; &lt;&lt; q.top().second &lt;&lt; &quot;\\n&quot;;        q.pop();    &#125;    return 0;&#125;\n\n\n结果：8 77 97 8\n\n\n\nmap 映射介绍映射类似于函数的对应关系，每个x对应一个y，而map是每个键对应一个值。会python的朋友学习后就会知道这和python的字典非常类似。\n\n比如说：学习 对应 看书，学习 是键，看书 是值。学习-&gt;看书玩耍 对应 打游戏，玩耍 是键，打游戏 是值。玩耍-&gt;打游戏\n\n\n头文件\n//头文件#include&lt;map&gt;\n\n初始化\n//初始化定义map&lt;string, string&gt; mp;map&lt;string, int&gt; mp;map&lt;int, node&gt; mp;//node是结构体类型\n\n\nmap特性：map会按照键的顺序从小到大自动排序，键的类型必须可以比较大小\n\n\n\n函数方法\n\n\n代码\n含义\n\n\n\nmp.find(key)\n返回键为key的映射的迭代器 $O(logN) $ 注意：用find函数来定位数据出现位置，它返回一个迭代器。当数据存在时，返回数据所在位置的迭代器，数据不存在时，返回mp.end ( )\n\n\nmp.erase(it)\n删除迭代器对应的键和值 O ( l o g N )\n\n\nmp.erase(key)\n根据映射的键删除键和值 O ( l o g N )\n\n\nmp.erase(first,last)\n删除左闭右开区间迭代器对应的键和值 O ( l a s t − f i r s t )\n\n\nmp.size()\n返回映射的对数 O (1)\n\n\nmp.clear()\n清空map中的所有元素 O ( N )\n\n\nmp.insert()\n插入元素，插入时要构造键值对\n\n\nmp.empty()\n如果map为空，返回true，否则返回false\n\n\nmp.begin()\n返回指向map第一个元素的迭代器（地址）\n\n\nmp.end()\n返回指向map尾部的迭代器（最后一个元素的下一个地址）\n\n\nmp.rbegin()\n返回指向map最后一个元素的迭代器（地址）\n\n\nmp.rend()\n返回指向map第一个元素前面(上一个）的逆向迭代器（地址）\n\n\nmp.count(key)\n查看元素是否存在，因为map中键是唯一的，所以存在返回1，不存在返回0\n\n\nmp.lower_bound()\n返回一个迭代器，指向键值&gt;&#x3D; key的第一个元素\n\n\nmp.upper_bound()\n返回一个迭代器，指向键值&gt; key的第一个元素\n\n\n注意下面说明部分函数方法的注意点\n\n注意：查找元素是否存在时，可以使用①mp.find() ② mp.count() ③ mp[key]但是第三种情况，如果不存在对应的key时，会自动创建一个键值对（产生一个额外的键值对空间）所以为了不增加额外的空间负担，最好使用前两种方法\n\n迭代器进行正反向遍历\nmp.begin()和mp.end()用法：\n用于正向遍历map\nmap&lt;int,int&gt; mp;mp[1] = 2;mp[2] = 3;mp[3] = 4;auto it = mp.begin();while(it != mp.end()) &#123;\tcout &lt;&lt; it-&gt;first &lt;&lt; &quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; &quot;\\n&quot;;\tit ++;&#125;\n\n结果：\n1 22 33 4\n\nmp.rbegin()和mp.rend()用法：\n用于逆向遍历map\nmap&lt;int,int&gt; mp;mp[1] = 2;mp[2] = 3;mp[3] = 4;auto it = mp.rbegin();while(it != mp.rend()) &#123;\tcout &lt;&lt; it-&gt;first &lt;&lt; &quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; &quot;\\n&quot;;\tit ++;&#125;\n\n结果：\n3 42 31 2\n\n二分查找二分查找lower_bound() upper_bound()\n\nmap的二分查找以第一个元素（即键为准），对键进行二分查找返回值为map迭代器类型\n\n#include&lt;bits/stdc++.h&gt;using namespace std;int main() &#123;\tmap&lt;int, int&gt; m&#123;&#123;1, 2&#125;, &#123;2, 2&#125;, &#123;1, 2&#125;, &#123;8, 2&#125;, &#123;6, 2&#125;&#125;;//有序\tmap&lt;int, int&gt;::iterator it1 = m.lower_bound(2);\tcout &lt;&lt; it1-&gt;first &lt;&lt; &quot;\\n&quot;;//it1-&gt;first=2\tmap&lt;int, int&gt;::iterator it2 = m.upper_bound(2);\tcout &lt;&lt; it2-&gt;first &lt;&lt; &quot;\\n&quot;;//it2-&gt;first=6\treturn 0;&#125;\n\n添加元素//先声明map&lt;string, string&gt; mp;\n\n\n方式一：\nmp[&quot;学习&quot;] = &quot;看书&quot;;mp[&quot;玩耍&quot;] = &quot;打游戏&quot;;\n\n方式二：插入元素构造键值对\nmp.insert(make_pair(&quot;vegetable&quot;,&quot;蔬菜&quot;));\n\n方式三：\nmp.insert(pair&lt;string,string&gt;(&quot;fruit&quot;,&quot;水果&quot;));\n\n方式四:\nmp.insert(&#123;&quot;hahaha&quot;,&quot;wawawa&quot;&#125;);\n\n访问元素下标访问(大部分情况用于访问单个元素)\nmp[&quot;菜哇菜&quot;] = &quot;强哇强&quot;;cout &lt;&lt; mp[&quot;菜哇菜&quot;] &lt;&lt; &quot;\\n&quot;;//只是简写的一个例子，程序并不完整\n\n遍历访问\n方式一：迭代器访问\nmap&lt;string,string&gt;::iterator it;for(it = mp.begin(); it != mp.end(); it++) &#123;\t//      键                 值 \t// it是结构体指针访问所以要用 -&gt; 访问\tcout &lt;&lt; it-&gt;first &lt;&lt; &quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; &quot;\\n&quot;;\t//*it是结构体变量 访问要用 . 访问\t//cout&lt;&lt;(*it).first&lt;&lt;&quot; &quot;&lt;&lt;(*it).second;&#125;\n\n方式二：智能指针访问\nfor(auto i : mp)cout &lt;&lt; i.first &lt;&lt; &quot; &quot; &lt;&lt; i.second &lt;&lt; endl;//键，值\n\n方式三：对指定单个元素访问\nmap&lt;char,int&gt;::iterator it = mp.find(&#x27;a&#x27;);cout &lt;&lt; it -&gt; first &lt;&lt; &quot; &quot; &lt;&lt;  it-&gt;second &lt;&lt; &quot;\\n&quot;;\n\n方式四：c++17特性才具有\nfor(auto [x, y] : mp)\tcout &lt;&lt; x &lt;&lt; &quot; &quot; &lt;&lt; y &lt;&lt; &quot;\\n&quot;;//x,y对应键和值\n\n与unordered_map的比较这里就不单开一个大目录讲unordered_map了，直接在map里面讲了。\n内部实现原理map：内部用红黑树实现，具有自动排序（按键从小到大）功能。\nunordered_map：内部用哈希表实现，内部元素无序杂乱。\n效率比较map：\n\n优点：内部用红黑树实现，内部元素具有有序性，查询删除等操作复杂度为O ( l o g N)\n缺点：占用空间，红黑树里每个节点需要保存父子节点和红黑性质等信息，空间占用较大。\n\nunordered_map：\n\n优点：内部用哈希表实现，查找速度非常快（适用于大量的查询操作）。\n缺点：建立哈希表比较耗时。\n\n\n两者方法函数基本一样，差别不大。\n注意：\n\n随着内部元素越来越多，两种容器的插入删除查询操作的时间都会逐渐变大，效率逐渐变低。\n\n使用[]查找元素时，如果元素不存在，两种容器都是创建一个空的元素；如果存在，会正常索引对应的值。所以如果查询过多的不存在的元素值，容器内部会创建大量的空的键值对，后续查询创建删除效率会大大降低。\n\n查询容器内部元素的最优方法是：先判断存在与否，再索引对应值（适用于这两种容器）\n// 以 map 为例map&lt;int, int&gt; mp;int x = 999999999;if(mp.count(x)) // 此处判断是否存在x这个键    cout &lt;&lt; mp[x] &lt;&lt; &quot;\\n&quot;;   // 只有存在才会索引对应的值，避免不存在x时多余空元素的创建\n\n\n另外：\n\n还有一种映射：multimap\n键可以重复，即一个键对应多个值，如要了解，可以自行搜索。\n\nset 集合介绍set容器中的元素不会重复，当插入集合中已有的元素时，并不会插入进去，而且set容器里的元素自动从小到大排序。\n即：set里面的元素不重复 且有序\n\n头文件\n//头文件#include&lt;set&gt;\n\n初始化\n//初始化定义set&lt;int&gt; s;\n\n函数方法\n\n\n代码\n含义\n\n\n\ns.begin()\n返回set容器的第一个元素的地址（迭代器）O ( 1 )\n\n\ns.end()\n返回set容器的最后一个元素的下一个地址（迭代器）O ( 1 )\n\n\ns.rbegin()\n返回逆序迭代器，指向容器元素最后一个位置O ( 1 )\n\n\ns.rend()\n返回逆序迭代器，指向容器第一个元素前面的位置O ( 1 )\n\n\ns.clear()\n删除set容器中的所有的元素\n\n\ns.empty()\n判断set容器是否为空O ( 1 )\n\n\ns.insert()\n插入一个元素\n\n\ns.size()\n返回当前set容器中的元素个数O ( 1 )\n\n\nerase(iterator)\n删除定位器iterator指向的值\n\n\nerase(first,second）\n删除定位器first和second之间的值\n\n\nerase(key_value)\n删除键值key_value的值\n\n\ns.find(element)\n查找set中的某一元素，有则返回该元素对应的迭代器，无则返回结束迭代器\n\n\ns.count(element)\n查找set中的元素出现的个数，由于set中元素唯一，此函数相当于查询element是否出现\n\n\ns.lower_bound(k)\n返回&gt;&#x3D;k的第一个元素的迭代器O ( l o g N )\n\n\ns.upper_bound(k)\n返回&gt;k的第一个元素的迭代器O ( l o g N )\n\n\n访问\n迭代器访问\nfor(set&lt;int&gt;::iterator it = s.begin(); it != s.end(); it++)\tcout &lt;&lt; *it &lt;&lt; &quot; &quot;;\n\n智能指针\nfor(auto i : s)\tcout &lt;&lt; i &lt;&lt; endl;\n\n访问最后一个元素\n//第一种cout &lt;&lt; *s.rbegin() &lt;&lt; endl;\n\n //第二种set&lt;int&gt;::iterator iter = s.end();iter--;cout &lt;&lt; (*iter) &lt;&lt; endl; //打印2;\n\n//第三种cout &lt;&lt; *(--s.end()) &lt;&lt; endl;\n\n重载&lt;运算符\n基础数据类型\n方式一：改变set排序规则，set中默认使用less比较器，即从小到大排序。（常用）\nset&lt;int&gt; s1; // 默认从小到大排序set&lt;int, greater&lt;int&gt; &gt; s2; // 从大到小排序\n\n方式二：重载运算符。（很麻烦，不太常用，没必要）\n//重载 &lt; 运算符struct cmp &#123;    bool operator () (const int&amp; u, const int&amp; v) const &#123;       // return + 返回条件       return u &gt; v;    &#125;&#125;;set&lt;int, cmp&gt; s; for(int i = 1; i &lt;= 10; i++)    s.insert(i);for(auto i : s)    cout &lt;&lt; i &lt;&lt; &quot; &quot;;// 10 9 8 7 6 5 4 3 2 1\n\n方式三：初始化时使用匿名函数定义比较规则\nset&lt;int, function&lt;bool(int, int)&gt;&gt; s([&amp;](int i, int j)&#123;    return i &gt; j; // 从大到小&#125;);for(int i = 1; i &lt;= 10; i++)    s.insert(i);for(auto x : s)    cout &lt;&lt; x &lt;&lt; &quot; &quot;;\n\n高级数据类型（结构体）\n直接重载结构体运算符即可，让结构体可以比较。\nstruct Point &#123;\tint x, y;\tbool operator &lt; (const Point &amp;p) const &#123;\t\t// 按照点的横坐标从小到大排序,如果横坐标相同,纵坐标从小到大\t\tif(x == p.x)\t\t\treturn y &lt; p.y;\t\treturn x &lt; p.x;\t&#125;&#125;;set&lt;Point&gt; s;for(int i = 1; i &lt;= 5; i++) &#123;    int x, y;    cin &gt;&gt; x &gt;&gt; y;    s.insert(&#123;x, y&#125;);&#125;\t/* 输入5 45 23 73 54 8*/for(auto i : s)    cout &lt;&lt; i.x &lt;&lt; &quot; &quot; &lt;&lt; i.y &lt;&lt; &quot;\\n&quot;;/* 输出3 53 74 85 25 4*/\n\n其它setmultiset:元素可以重复，且元素有序\nunordered_set ：元素无序且只能出现一次\nunordered_multiset ： 元素无序可以出现多次\npair 二元组介绍pair只含有两个元素，可以看作是只有两个元素的结构体。\n应用：\n\n头文件\n//头文件#include&lt;utility&gt;\n\n初始化\n//1.初始化定义pair&lt;string, int&gt; p(&quot;zenith32&quot;,1);//带初始值的pair&lt;string, int&gt; p;//不带初始值的\n\n赋值\n//2.赋值p = &#123;&quot;zenith32&quot;, 18&#125;;p = make_pair(&quot;zenith32&quot;, 18);p = pair&lt;string, int&gt;(&quot;zenith32&quot;, 18);\n\n代替二元结构体\n\n作为map键值对进行插入（代码如下）\nmap&lt;string, int&gt; mp;mp.insert(pair&lt;string, int&gt;(&quot;zenith32&quot;,1));// mp.insert(make_pair(&quot;zenith32&quot;, 1));// mp.insert(&#123;&quot;zenith32&quot;, 1&#125;);\n\n访问//定义结构体数组pair&lt;int,int&gt; p[20];for(int i = 0; i &lt; 20; i++) &#123;\t//和结构体类似，first代表第一个元素，second代表第二个元素\tcout &lt;&lt; p[i].first &lt;&lt; &quot; &quot; &lt;&lt; p[i].second;&#125;\n\nstring 字符串介绍string是一个字符串类，和char型字符串类似。\n可以把string理解为一个字符串类型，像int一样可以定义\n初始化及定义\n头文件\n//头文件#include&lt;string&gt;\n\n初始化\n//1.string str1; //生成空字符串//2.string str2(&quot;123456789&quot;); //生成&quot;123456789&quot;的复制品 //3.string str3(&quot;12345&quot;, 0, 3);//结果为&quot;123&quot; ，从0位置开始，长度为3//4.string str4(&quot;123456&quot;, 5); //结果为&quot;12345&quot; ，长度为5//5.string str5(5, &#x27;2&#x27;); //结果为&quot;22222&quot; ,构造5个字符&#x27;2&#x27;连接而成的字符串//6.string str6(str2, 2); //结果为&quot;3456789&quot;，截取第三个元素（2对应第三位）到最后\n\n访问单个字符：\n#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;int main() &#123;\tstring s = &quot;zenith!!!&quot;;\tfor(int i = 0; i &lt; s.size(); i++)\t\tcout &lt;&lt; s[i] &lt;&lt; &quot; &quot;;\treturn 0;&#125;\n\nstring数组使用：\n#include&lt;iostream&gt;#include&lt;string&gt;using namespace std;int main() &#123;\tstring s[10];\tfor(int i = 1; i &lt; 10; i++) &#123;\t\ts[i] = &quot;loading...  &quot; ;\t\tcout &lt;&lt; s[i] &lt;&lt; i &lt;&lt; &quot;\\n&quot;;\t&#125; \treturn 0;&#125;//结果://loading...  1//loading...  2//loading...  3//loading...  4//loading...  5//loading...  6//loading...  7//loading...  8//loading...  9\n\nstring 特性\n支持比较运算符\nstring字符串支持常见的比较操作符（&gt;,&gt;&#x3D;,&lt;,&lt;&#x3D;,&#x3D;&#x3D;,!&#x3D;），支持string与C-string的比较（如 str &lt; “hello”）。\n在使用&gt;,&gt;&#x3D;,&lt;,&lt;&#x3D;这些操作符的时候是根据“当前字符特性”将字符按 字典顺序 进行逐一得 比较。字典排序靠前的字符小， 比较的顺序是从前向后比较，遇到不相等的字符就按这个位置上的两个字符的比较结果确定两个字符串的大小（前面减后面）。\n同时，string (&quot;aaaa&quot;) &lt;string(&quot;aaaaa&quot;)。\n\n支持+运算符，代表拼接字符串string字符串可以拼接，通过”+”运算符进行拼接。\nstring s1 = &quot;123&quot;;string s2 = &quot;456&quot;;string s = s1 + s2;cout &lt;&lt; s;   //123456\n\n读入详解读入字符串，遇空格，回车结束\nstring s;cin &gt;&gt; s;\n\n读入一行字符串（包括空格），遇回车结束\nstring s;getline(cin, s);\n\n注意: getline(cin, s)会获取前一个输入的换行符，需要在前面添加读取换行符的语句。如：getchar() 或 cin.get()\n错误读取：\nint n;string s;cin &gt;&gt; n;getline(cin, s); //此时读取相当于读取了前一个回车字符\n\n正确读取：\nint n;string s;cin &gt;&gt; n;getchar(); //cin.get() 读取前一个回车字符getline(cin, s);//可正确读入下一行的输入\n\n\ncin与cin.getline()混用\ncin输入完后，回车，cin遇到回车结束输入，但回车还在输入流中，cin并不会清除，导致getline()读取回车，结束。需要在cin后面加cin.ignore()；主动删除输入流中的换行符。（不常用）\n\ncin和cout解锁\n代码（写在main函数开头）：\nios::sync_with_stdio(false);cin.tie(0),cout.tie(0);\n\n\n为什么要进行cin和cout的解锁，原因是：\n在一些题目中，读入的数据量很大，往往超过了1e5（105）的数据量,而cin和cout的读入输出的速度很慢（是因为cin和cout为了兼容C语言的读入输出在性能上做了妥协），远不如scanf和printf的速度，具体原因可以搜索相关的博客进行了解。\n所以对cin和cout进行解锁使cin和cout的速度几乎接近scanf和printf，避免输入输出超时。\n\n注意：cin cout解锁使用时，不能与 scanf,getchar, printf,cin.getline()混用，一定要注意，会出错。\n\nstring与C语言字符串（C-string）的区别\nstring是C++的一个类，专门实现字符串的相关操作。具有丰富的操作方法，数据类型为string，字符串结尾没有\\0字符C-stringC语言中的字符串，用char数组实现，类型为const char *,字符串结尾以\\0结尾\n\n一般来说string向char数组转换会出现一些问题，所以为了能够实现转换，string有一个方法c_str()实现string向char数组的转换。\nstring s = &quot;zenith&quot;;const char *s2 = s.c_str();\n\n函数方法\n获取字符串长度\n\n\n\n代码\n含义\n\n\n\ns.size()和s.length()\n返回string对象的字符个数，他们执行效果相同。\n\n\ns.max_size()\n返回string对象最多包含的字符数，超出会抛出length_error异常\n\n\ns.capacity()\n重新分配内存之前，string对象能包含的最大字符数\n\n\n\n插入\n\n\n\n代码\n含义\n\n\n\ns.push_back(element)\n在末尾插入\n\n\ns.insert(pos,element)\n在pos位置插入element\n\n\ns.append(str)\n在s字符串结尾添加str字符串\n\n\n例\n\n\n\n代码\n含义\n\n\n\ns.push_back(‘a’)\n末尾插入一个字符a\n\n\ns.insert(s.begin(),’1’)\n在第一个位置插入1字符\n\n\ns.append(“abc”)\n在s字符串末尾添加字符串“abc”\n\n\n\n删除\n\n\n\n代码\n含义\n\n\n\nerase(iterator p)\n删除字符串中p所指的字符\n\n\nerase(iterator first, iterator last)\n删除字符串中迭代器区间[first,last)上所有字符\n\n\nerase(pos, len)\n删除字符串中从索引位置pos开始的len个字符\n\n\nclear()\n删除字符串中所有字符\n\n\n\n字符替换\n\n\n\n代码\n含义\n\n\n\ns.replace(pos,n,str)\n把当前字符串从索引pos开始的n个字符替换为str\n\n\ns.replace(pos,n,n1,c)\n把当前字符串从索引pos开始的n个字符替换为n1个字符c\n\n\ns.replace(it1,it2,str)\n把当前字符串[it1,it2)区间替换为str it1 ,it2为迭代器（iterator）\n\n\n\n大小写转换\n法一：\n\n\n\n代码\n含义\n\n\n\ntolower(s[i])\n转换为小写\n\n\ntoupper(s[i])\n转换为大写\n\n\n法二：\n通过stl的transform算法配合tolower 和toupper 实现。有4个参数，前2个指定要转换的容器的起止范围，第3个参数是结果存放容器的起始位置，第4个参数是一元运算。\nstring s;transform(s.begin(),s.end(),s.begin(),::tolower);//转换小写transform(s.begin(),s.end(),s.begin(),::toupper);//转换大写\n\n分割\n\n\n\n代码\n含义\n\n\n\ns.substr(pos,n)\n截取从pos索引开始的n个字符\n\n\n\n查找\n\n\n\n代码\n含义\n\n\n\ns.find (str, pos)\n在当前字符串的pos索引位置（默认为0）开始，查找子串str，返回找到的位置索引，-1表示查找不到子串\n\n\ns.find (c, pos)\n在当前字符串的pos索引位置（默认为0）开始，查找字符c，返回找到的位置索引，-1表示查找不到字符\n\n\ns.rfind (str, pos)\n在当前字符串的pos索引位置开始，反向查找子串s，返回找到的位置索引，-1表示查找不到子串\n\n\ns.rfind (c,pos)\n在当前字符串的pos索引位置开始，反向查找字符c，返回找到的位置索引，-1表示查找不到字符\n\n\ns.find_first_of (str, pos)\n在当前字符串的pos索引位置（默认为0）开始，查找子串s的字符，返回找到的位置索引，-1表示查找不到字符\n\n\ns.find_first_not_of (str,pos)\n在当前字符串的pos索引位置（默认为0）开始，查找第一个不位于子串s的字符，返回找到的位置索引，-1表示查找不到字符\n\n\ns.find_last_of(str, pos)\n在当前字符串的pos索引位置开始，查找最后一个位于子串s的字符，返回找到的位置索引，-1表示查找不到字符\n\n\ns.find_last_not_of ( str, pos)\n在当前字符串的pos索引位置开始，查找最后一个不位于子串s的字符，返回找到的位置索引，-1表示查找不到子串\n\n\n#include&lt;string&gt;#include&lt;iostream&gt;int main() &#123;    string s(&quot;dog bird chicken bird cat&quot;);//字符串查找-----找到后返回首字母在字符串中的下标// 1. 查找一个字符串    cout &lt;&lt; s.find(&quot;chicken&quot;) &lt;&lt; endl;// 结果是：9    // 2. 从下标为6开始找字符&#x27;i&#x27;，返回找到的第一个i的下标    cout &lt;&lt; s.find(&#x27;i&#x27;,6) &lt;&lt; endl;// 结果是：11    // 3. 从字符串的末尾开始查找字符串，返回的还是首字母在字符串中的下标    cout &lt;&lt; s.rfind(&quot;chicken&quot;) &lt;&lt; endl;// 结果是：9    // 4. 从字符串的末尾开始查找字符    cout &lt;&lt; s.rfind(&#x27;i&#x27;) &lt;&lt; endl;// 结果是：18 因为是从末尾开始查找，所以返回第一次找到的字符    // 5. 在该字符串中查找第一个属于字符串s的字符    cout &lt;&lt; s.find_first_of(&quot;13br98&quot;) &lt;&lt; endl;// 结果是：4---b    // 6. 在该字符串中查找第一个不属于字符串s的字符------先匹配dog，然后bird匹配不到，所以打印4    cout &lt;&lt; s.find_first_not_of(&quot;hello dog 2006&quot;) &lt;&lt; endl; // 结果是：4    cout &lt;&lt; s.find_first_not_of(&quot;dog bird 2006&quot;) &lt;&lt; endl;  // 结果是：9    // 7. 在该字符串最后中查找第一个属于字符串s的字符    cout &lt;&lt; s.find_last_of(&quot;13r98&quot;) &lt;&lt; endl;// 结果是：19// 8. 在该字符串最后中查找第一个不属于字符串s的字符------先匹配t--a---c，然后空格匹配不到，所以打印21    cout &lt;&lt; s.find_last_not_of(&quot;teac&quot;) &lt;&lt; endl;// 结果是：21&#125;\n\n排序\nsort(s.begin(),s.end());  //按ASCII码排序\n\nbitset介绍bitset 在 bitset 头文件中，它类似数组，并且每一个元素只能是０或１，每个元素只用１bit空间\n\n头文件\n//头文件#include&lt;bitset&gt;\n\n初始化定义\n初始化方法\nbitset&lt;n&gt; a;//a有n位，每位都为0bitset&lt;n&gt; a(b);//a是unsigned long型b的一个二进制副本bitset&lt;n&gt; a(s);//a是string对象s中含有的位串的副本bitset&lt;n&gt; a(s,pos,n);//a是s中从位置pos开始的n个位的副本\n\n\n注意：n必须为常量表达式\n\n演示代码：\n#include&lt;bits/stdc++.h&gt;using namespace std;int main() &#123;\tbitset&lt;4&gt; bitset1;　　  //无参构造，长度为４，默认每一位为0bitset&lt;9&gt; bitset2(12);　//长度为9，二进制保存，前面用0补充string s = &quot;100101&quot;;bitset&lt;10&gt; bitset3(s);　　//长度为10，前面用0补充char s2[] = &quot;10101&quot;;bitset&lt;13&gt; bitset4(s2);　　//长度为13，前面用0补充cout &lt;&lt; bitset1 &lt;&lt; endl;　　//0000cout &lt;&lt; bitset2 &lt;&lt; endl;　　//000001100cout &lt;&lt; bitset3 &lt;&lt; endl;　　//0000100101cout &lt;&lt; bitset4 &lt;&lt; endl;　//0000000010101return 0;&#125;\n特性bitset可以进行位操作\nbitset&lt;4&gt; foo (string(&quot;1001&quot;));bitset&lt;4&gt; bar (string(&quot;0011&quot;));cout &lt;&lt; (foo^=bar) &lt;&lt; endl;// 1010 (foo对bar按位异或后赋值给foo)cout &lt;&lt; (foo&amp;=bar) &lt;&lt; endl;// 0001 (按位与后赋值给foo)cout &lt;&lt; (foo|=bar) &lt;&lt; endl;// 1011 (按位或后赋值给foo)cout &lt;&lt; (foo&lt;&lt;=2) &lt;&lt; endl;// 0100 (左移2位，低位补0，有自身赋值)cout &lt;&lt; (foo&gt;&gt;=1) &lt;&lt; endl;// 0100 (右移1位，高位补0，有自身赋值)cout &lt;&lt; (~bar) &lt;&lt; endl;// 1100 (按位取反)cout &lt;&lt; (bar&lt;&lt;1) &lt;&lt; endl;// 0110 (左移，不赋值)cout &lt;&lt; (bar&gt;&gt;1) &lt;&lt; endl;// 0001 (右移，不赋值)cout &lt;&lt; (foo==bar) &lt;&lt; endl;// false (1001==0011为false)cout &lt;&lt; (foo!=bar) &lt;&lt; endl;// true  (1001!=0011为true)cout &lt;&lt; (foo&amp;bar) &lt;&lt; endl;// 0001 (按位与，不赋值)cout &lt;&lt; (foo|bar) &lt;&lt; endl;// 1011 (按位或，不赋值)cout &lt;&lt; (foo^bar) &lt;&lt; endl;// 1010 (按位异或，不赋值)\n\n访问\n//可以通过 [ ] 访问元素(类似数组)，注意最低位下标为０，如下：bitset&lt;4&gt; foo (&quot;1011&quot;); cout &lt;&lt; foo[0] &lt;&lt; endl;　　//1cout &lt;&lt; foo[1] &lt;&lt; endl;　　//0cout &lt;&lt; foo[2] &lt;&lt; endl;　　//1\n\n方法函数\n\n\n代码\n含义\n\n\n\nb.any()\nb中是否存在置为1的二进制位，有 返回true\n\n\nb.none()\nb中是否没有1，没有 返回true\n\n\nb.count()\nb中为1的个数\n\n\nb.size()\nb中二进制位的个数\n\n\nb.test(pos)\n测试b在pos位置是否为1，是 返回true\n\n\nb[pos]\n返回b在pos处的二进制位\n\n\nb.set()\n把b中所有位都置为1\n\n\nb.set(pos)\n把b中pos位置置为1\n\n\nb.reset()\n把b中所有位都置为0\n\n\nb.reset(pos)\n把b中pos位置置为0\n\n\nb.flip()\n把b中所有二进制位取反\n\n\nb.flip(pos)\n把b中pos位置取反\n\n\nb.to_ulong()\n用b中同样的二进制位返回一个unsigned long值\n\n\narray 数组介绍\n头文件\n#include&lt;array&gt;\n\narray是C++11新增的容器，效率与普通数据相差无几，比vector效率要高，自身添加了一些成员函数。\n和其它容器不同，array 容器的大小是固定的，无法动态的扩展或收缩，只允许访问或者替换存储的元素。\n注意：\narray的使用要在std命名空间里\n使用声明和初始化\n基础数据类型\n声明一个大小为100的int型数组，元素的值不确定\narray&lt;int, 100&gt; a;\n\n声明一个大小为100的int型数组，初始值均为0(初始值与默认元素类型等效)\narray&lt;int, 100&gt; a&#123;&#125;;\n声明一个大小为100的int型数组，初始化部分值，其余全部为0\narray&lt;int, 100&gt; a&#123;1, 2, 3&#125;;\n或者可以用等号\narray&lt;int, 100&gt; a = &#123;1, 2, 3&#125;;\n\n高级数据类型不同于数组的是对元素类型不做要求，可以套结构体\narray&lt;string, 2&gt; s = &#123;&quot;ha&quot;, string(&quot;haha&quot;)&#125;;array&lt;node, 2&gt; a;\n\n取存元素值\n修改元素\narray&lt;int, 4&gt; a = &#123;1, 2, 3, 4&#125;;a[0] = 4;\n\n访问元素\n下标访问\narray&lt;int, 4&gt; a = &#123;1, 2, 3, 4&#125;;for(int i = 0; i &lt; 4; i++)     cout &lt;&lt; a[i] &lt;&lt; &quot; \\n&quot;[i == 3];\n\n利用auto访问\nfor(auto i : a)    cout &lt;&lt; i &lt;&lt; &quot; &quot;;\n\n迭代器访问\nauto it = a.begin();for(; it != a.end(); it++)     cout &lt;&lt; *it &lt;&lt; &quot; &quot;;\n\nat()函数访问\n//下标为1的元素 加上 下标为2的元素，答案为5array&lt;int, 4&gt; a = &#123;1, 2, 3, 4&#125;;int res = a.at(1) + a.at(2);cout &lt;&lt; res &lt;&lt; &quot;\\n&quot;;\n\nget方法访问\n//将a数组下标为1位置处的值改为xget&lt;1&gt;(a) = x;//注意 获取的下标只能写数字，不能填变量\n\n成员函数\n\n\n成员函数\n功能\n\n\n\nbegin()\n返回容器中第一个元素的访问迭代器（地址）\n\n\nend()\n返回容器最后一个元素后一个位置的访问迭代器（地址）\n\n\nrbegin()\n返回最后一个元素的访问迭代器（地址）\n\n\nrend()\n返回第一个元素前一个位置的访问迭代器（地址）\n\n\nsize()\n返回容器中元素的数量，其值等于初始化 array 类的第二个模板参数N\n\n\nmax_size()\n返回容器可容纳元素的最大数量，其值始终等于初始化 array 类的第二个模板参数 N\n\n\nempty()\n判断容器是否为空\n\n\nat(n)\n返回容器中 n 位置处元素的引用，函数会自动检查 n 是否在有效的范围内，如果不是则抛出 out_of_range 异常\n\n\nfront()\n返回容器中第一个元素的直接引用，函数不适用于空的 array 容器\n\n\nback()\n返回容器中最后一个元素的直接引用，函数不适用于空的 array 容器。\n\n\ndata()\n返回一个指向容器首个元素的指针。利用该指针，可实现复制容器中所有元素等类似功能\n\n\nfill(x)\n将 x 这个值赋值给容器中的每个元素,相当于初始化\n\n\narray1.swap(array2)\n交换 array1 和 array2 容器中的所有元素，但前提是它们具有相同的长度和类型\n\n\n部分用法示例data()指向底层元素存储的指针。对于非空容器，返回的指针与首元素地址比较相等。\nat()下标为1的元素加上下标为2的元素，答案为5\narray&lt;int, 4&gt; a = &#123;1, 2, 3, 4&#125;;int res = a.at(1) + a.at(2);cout &lt;&lt; res &lt;&lt; &quot;\\n&quot;;\n\nfill()array的fill()函数，将a数组全部元素值变为x\na.fill(x);\n\n另外还有其它的fill()函数:将a数组[begin,end)全部值变为x\nfill(a.begin(), a.end(), x);\n\nget方法获取元素值将a数组下标为1位置处的值改为x\n注意 获取的下标只能写数字，不能填变量\nget&lt;1&gt;(a) = x;\n\n排序sort(a.begin(), a.end());\n\ntuple 元组介绍tuple模板是pair的泛化，可以封装不同类型任意数量的对象。\n可以把tuple理解为pair的扩展，tuple可以声明二元组，也可以声明三元组。\ntuple可以等价为结构体使用\n\n头文件\n#include&lt;tuple&gt;\n\n基础用法声明及初始化\n声明一个空的tuple三元组\ntuple&lt;int, int, string&gt; t1;\n\n赋值\nt1 = make_tuple(1, 1, &quot;hahaha&quot;);\n\n创建的同时初始化\ntuple&lt;int, int, int, int&gt; t2(1, 2, 3, 4);\n\n可以使用pair对象构造tuple对象，但tuple对象必须是两个元素\nauto p = make_pair(&quot;wang&quot;, 1);tuple&lt;string, int&gt; t3 &#123;p&#125;; //将pair对象赋给tuple对象\n\n元素操作\n获取tuple对象t的第一个元素\nint first = get&lt;0&gt;(t);\n修改tuple对象t的第一个元素\nget&lt;0&gt;(t) = 1;\n\n函数操作\n获取元素个数\ntuple&lt;int, int, int&gt; t(1, 2, 3);cout &lt;&lt; tuple_size&lt;decltype(t)&gt;::value &lt;&lt; &quot;\\n&quot;; // 3\n\n获取对应元素的值\n//通过`get&lt;n&gt;(obj)`方法获取,`n`必须为数字不能是变量tuple&lt;int, int, int&gt; t(1, 2, 3);cout &lt;&lt; get&lt;0&gt;(t) &lt;&lt; &#x27;\\n&#x27;; // 1cout &lt;&lt; get&lt;1&gt;(t) &lt;&lt; &#x27;\\n&#x27;; // 2cout &lt;&lt; get&lt;2&gt;(t) &lt;&lt; &#x27;\\n&#x27;; // 3\n\n通过tie解包 获取元素值\n//tie可以让tuple变量中的三个值依次赋到tie中的三个变量中int one, three;string two; tuple&lt;int, string, int&gt; t(1, &quot;hahaha&quot;, 3);tie(one, two, three) = t;cout &lt;&lt; one &lt;&lt; two &lt;&lt; three &lt;&lt; &quot;\\n&quot;; // 1hahaha3\n\n\n后记stl 的总结就到这里先结束了，也算是按时提前完成此次任务了吧\n后续应该会补充一些其他常用的函数，例如 sort 等\n","categories":["学习"],"tags":["知识总结","算法"]},{"title":"使用BearPi-Pico H3863驱动3.52inch e-Paper HAT","url":"/2025/02/07/%E4%BD%BF%E7%94%A8BearPi-Pico%20H3863%E9%A9%B1%E5%8A%A83.52inch%20e-Paper%20HAT/","content":"\n先祝大家新年快乐🎉\n\n\n微雪的官网已经给出了常见单片机使用3.52inch e-Paper的例程，我们在此基础上对其中的库文件以及例程进行了修改，使其能够适配BearPi-Pico H3863，下面先给出修改完后的文件包\n点击下载\n在下载完之后进行解压，打开海思HiSpark Studio IDE，在BearPi-Pico H3863的SDK工程的 &#x2F;application&#x2F;samples&#x2F; 下新建文件夹E-paper，然后再将刚刚解压的文件夹的内容都拷贝进来\n&#x2F;application&#x2F;samples&#x2F; 下的文件目录如下图所示\n\n在 &#x2F;application&#x2F;samples&#x2F; 下的Kconfig文件的最后添加如下代码\nconfig ENABLE_EPAPER_SAMPLE bool prompt &quot;Enable the Sample of E-paper.&quot; default n depends on SAMPLE_ENABLE help     This option means enable the sample of E-paper.if ENABLE_EPAPER_SAMPLEosource &quot;application/samples/E-paper/Kconfig&quot;endif\n\n在 &#x2F;application&#x2F;samples&#x2F; 下的CMakeLists.txt文件中添加如下代码\nif(DEFINED CONFIG_ENABLE_EPAPER_SAMPLE) add_subdirectory_if_exist(E-paper)endif()\n\n之后打开系统配置，通过修改编译宏配置改模块参与编译，如下图所示\n\n保存关闭之后对该文件进行重编译\n接下来就是使用杜邦线将BearPi-Pico H3863与3.52inch e-Paper HAT连接，\n对应关系如下\n\n\n\nBearPi-Pico H3863\n3.52inch e-Paper HAT\n\n\n\nGP12\nBUSY\n\n\nGP02\nRST\n\n\nGP10\nDC\n\n\nGP08\nCS\n\n\nGP07\nSCLK\n\n\nGP09\nDIN\n\n\nGND\nGND\n\n\n3.3V\nVCC\n\n\n具体连线还需根据设置进行调整\n然后将程序加载到目标板，待加载完成后运行，在墨水屏上输出测试图案，且运行过程中LED亮起即为成功。\n\n","categories":["学习"],"tags":["知识总结","硬件","华为"]},{"title":"基于Ubuntu编译内核并添加内核模块","url":"/2025/03/26/%E5%9F%BA%E4%BA%8EUbuntu%E7%BC%96%E8%AF%91%E5%86%85%E6%A0%B8%E5%B9%B6%E6%B7%BB%E5%8A%A0%E5%86%85%E6%A0%B8%E6%A8%A1%E5%9D%97/","content":"本文详细记录在 Ubuntu 24.10 系统上编译 Linux 内核、创建最小化运行环境，并添加自定义内核模块的全过程。所有操作均在 VMware 虚拟机环境下验证通过。\n\n\n\n使用的系统镜像是 ubuntu-24.10-desktop-amd64.iso \n\n一、环境准备与内核编译首先第一步是在桌面创建一个文件夹，这里我就取名为 linux ，在 linux 文件夹中打开终端\n接着我们需要获取内核的源码，去 官网 https://kernel.org 下载最新的稳定版，这里我们就下载 stable:6.13.8 ，复制 tarball 的链接后，到前面在linux文件夹中打开的终端，输入：\n# 下载稳定版内核源码（以6.13.8为例）wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.13.8.tar.xz\n\n在下载完成之后我们需要对文件夹进行解压缩，输入：\n# 解压源码包tar -xf linux-6.13.8.tar.xz\n\n解压完成后进入该文件夹，输入：\n# 进入源码目录cd linux-6.13.8\n\n此时内核的源代码中已经有 Makefile ，因此可以直接 make \n这里我们使用默认配置，输入：\n# 生成默认配置（使用x86_64架构的默认配置）make defconfig\n\n接着就开始内核的编译，因为我的虚拟机就两核因此使用双线程，大家可以根据自己的配置进行调整，输入：\n# 开始编译内核（-j参数根据CPU核心数设置，双核示例）make -j 2\n\n接着就是漫长的等待，编译完成后会生成 arch/x86/boot/bzImage 内核文件\n二、最小化环境测试接着我们使用 QEMU 这个模拟器进行内核功能的测试，输入：\nqemu-system-x86_64 -kernel arch/x86/boot/bzImage\n\n但是只有内核本身是跑不起来的，此时我们要返回 linux 文件夹，并在 linux 文件夹内创建 shell 文件夹，然后在 shell 文件夹内创建 shell.c 文件，输入：\n# 返回工程目录并创建shell环境cd ..mkdir shellcd shell# 编写测试程序（使用vim或任意编辑器）vim shell.c\n\n接着可以编写一个简单的 c 程序试验一下，输入：\n/* 最小化交互程序 */#include&lt;stdio.h&gt;int main()&#123;    char a;    while(1)    &#123;        printf(&quot;Are you OK?&quot;);        scanf(&quot;%c&quot;,&amp;a);    &#125;    return 0;&#125;\n\n接着编译并运行，输入：\ngcc shell.c./a.out\n\n现在已经可以顺利运行该 shell.c 文件了，为了使编译生成的文件不被动态地链接到其他无关的库，则在编译时使用 -static ，输入：\n# 静态编译（避免动态链接依赖）gcc shell.c -static\n\n 接着将可运行文件重命名为 init ，这是 linux 内核默认搜索的一个文件名，输入：\nmv ./a.out init# 也可以在上一步直接 gcc shell.c -static -o init\n\n然后再将其打包成一个 cpio 格式的压缩包，输入：\n# 打包为initramfs（需包含名为init的可执行文件）echo &quot;init&quot; | cpio -H newc -o &gt; init.cpio\n\n在文件压缩成功之后再使用 qemu 尝试启动，输入：\n# 使用QEMU启动自定义内核qemu-system-x86_64 -kernel ../linux-6.13.8/arch/x86/boot/bzImage -initrd init.cpio\n\n运行后输出是：\n\n此时 QEMU 已成功启动自定义内核，编译内核至此已经完成了，接下来将是添加内核模块\n三、添加内核模块此时的目录结构应为：\n~/桌面/linux/├── linux-6.13.8/          ├── shell/                │   ├── init             │   ├── init.cpio        │   └── shell.c          \n\n接着开始编写内核模块，在 shell/ 目录下新建文件 hello.c，编写模块的源码：\n#include &lt;linux/init.h&gt;#include &lt;linux/module.h&gt;#include &lt;linux/kernel.h&gt;MODULE_LICENSE(&quot;GPL&quot;);MODULE_AUTHOR(&quot;Your Name&quot;);MODULE_DESCRIPTION(&quot;A simple Linux kernel module&quot;);/* 模块加载函数 */static int __init hello_init(void) &#123;    printk(KERN_INFO &quot;Hello, Kernel Module loaded!\\n&quot;);  // 内核日志输出    return 0;&#125;/* 模块卸载函数 */static void __exit hello_exit(void) &#123;    printk(KERN_INFO &quot;Goodbye, Kernel Module unloaded.\\n&quot;);&#125;/* 注册模块入口/出口 */module_init(hello_init);  // 模块加载时调用 hello_initmodule_exit(hello_exit);  // 模块卸载时调用 hello_exit\n\n然后是编写模块的 Makefile ，在同一目录下创建 Makefile ：\n# 指定模块名称（需与源码文件名一致）obj-m := hello.o# 内核源码路径（根据实际位置修改）KDIR := ~/桌面/linux/linux-6.13.8  # 指向你的内核源码目录# 当前模块路径PWD := $(shell pwd)all:\tmake -C $(KDIR) M=$(PWD) modulesclean:\tmake -C $(KDIR) M=$(PWD) clean\n\n接着开始编译内核模块，进入shell/ 目录并编译，输入：\ncd ~/桌面/linux/shell# 执行编译（生成hello.ko内核模块）make\n\n此时若成功则会输出：\nmake -C ~/桌面/linux/linux-6.13.8 M=~/桌面/linux/shell modules  CC [M]  ~/桌面/linux/shell/hello.o  MODPOST 1 modules  CC      ~/桌面/linux/shell/hello.mod.o  LD [M]  ~/桌面/linux/shell/hello.ko\n\n检查模块信息，应包含许可证、作者等信息，输入：\n# 查看模块信息modinfo hello.ko\n\n四、集成与完整测试修改用户态 init 程序，更新 shell.c ，使其加载内核模块并交互：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main() &#123;    printf(&quot;=== My Minimal Shell ===\\n&quot;);        // 1. 加载内核模块    system(&quot;insmod /hello.ko&quot;);    printf(&quot;Kernel module loaded. Check dmesg.\\n&quot;);    // 2. 模拟用户交互    int input;    while (1) &#123;        printf(&quot;Enter &#x27;0&#x27; to exit: &quot;);        scanf(&quot;%d&quot;, &amp;input);        if (input == 0) break;    &#125;    // 3. 卸载模块    system(&quot;rmmod hello&quot;);    printf(&quot;Kernel module unloaded.\\n&quot;);    return 0;&#125;\n\n接着编译并打包新的 initramfs ，输入：\n# 静态编译gcc -static shell.c -o init  # 确保可执行chmod +x init               cd ~/桌面/linux/shell# 打包包含模块的initramfs（必须包含init和hello.ko）echo -e &quot;init\\nhello.ko&quot; | cpio -o -H newc &gt; init.cpio  \n\n最后是通过 QEMU 启动完整测试，输入：\n# 带控制台输出的启动方式qemu-system-x86_64 \\    -kernel ~/桌面/linux/linux-6.13.8/arch/x86/boot/bzImage \\    -initrd ~/桌面/linux/shell/init.cpio \\    -nographic -append &quot;console=ttyS0&quot;\n\n输出：\n=== My Minimal Shell ===Kernel module loaded. Check dmesg.Enter &#x27;0&#x27; to exit: \n\n输入 0 退出程序后，检查卸载日志，输入：\n# 过滤内核日志中的卸载信息dmesg | grep Goodbye\n\n输出：\nGoodbye, Kernel Module unloaded.\n\n运行后的输出是：\n\n通过以上步骤，即可完成从内核编译到模块开发的完整流程。\n但是目前仍存在部分小问题，等待后续学习修正。\n","categories":["学习"],"tags":["知识总结","操作系统"]},{"title":"基于鲲鹏数学库的高性能数学计算加速方法研究与实践","url":"/2024/12/21/%E5%9F%BA%E4%BA%8E%E9%B2%B2%E9%B9%8F%E6%95%B0%E5%AD%A6%E5%BA%93%E7%9A%84%E9%AB%98%E6%80%A7%E8%83%BD%E6%95%B0%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95%E7%A0%94%E7%A9%B6%E4%B8%8E%E5%AE%9E%E8%B7%B5/","content":"本博客介绍了我撰写的《基于鲲鹏数学库的高性能数学计算加速方法研究与实践》，因为实际操作过程截图涉及个人信息，故图片已被屏蔽\n基于鲲鹏数学库的高性能数学计算加速方法研究与实践1 实验目的1. 验证鲲鹏数学库的性能优化效果\n核心目标：通过一系列数学计算实验，系统验证基于鲲鹏架构的 Kunpeng Math Library (KML) 相较传统实现方式的性能提升程度。\n细化目标\n验证 KML 在不同数学计算任务中的加速效果，包括基础数学运算（如三角函数计算）、矩阵计算（如矩阵乘法）和高级线性代数问题（如特征值分解）。\n比较 KML 在单线程和多线程模式下的性能表现，探索其并行能力。\n\n\n\n2. 探索鲲鹏架构的硬件适配性\n硬件架构支持验证\n检验 KML 对鲲鹏处理器的硬件特性（如 SIMD 指令集、多核并行）和内存架构（如 L1&#x2F;L2 缓存优化）的适配程度。\n探索基于 ARM 架构优化的数学库在高性能计算（HPC）场景中的实际表现。\n\n\n平台优势探索\n评估 KML 在典型计算任务（如矩阵运算、快速傅里叶变换）中对其他平台（如 x86 架构）的相对性能优势，为基于鲲鹏的数学计算方案提供参考。\n\n\n\n3. 优化实际科学计算任务\n面向工程计算和科学研究\n通过 KML 的高性能计算加速，解决实际工程和科研中的计算瓶颈问题。例如，优化数据分析、机器学习训练中的矩阵运算，加速信号处理中的傅里叶变换等。\n\n\n扩展应用场景\n在本实验中探索 KML 在不同任务中的适配性，为其在更多计算场景（如气象模拟、分子动力学模拟等）提供基础。\n\n\n\n4. 提升鲲鹏生态的实践经验\n用户指导与案例积累\n总结使用 KML 的安装、配置、调试方法，以及在各类任务中的具体实现步骤，为开发者提供实践指南。\n为鲲鹏生态的推广提供优化实践案例，进一步推动基于 ARM 架构的高性能计算技术在行业中的普及。\n\n\n性能优化经验总结\n通过对比实验，提炼出优化数学计算性能的经验，如向量化处理、多线程并行优化、内存管理优化等，为后续开发高效的数学计算程序提供理论和实践依据。\n\n\n\n5. 评估性能与准确性的平衡\n性能测试\n在数学运算中，尤其是高级运算（如特征值分解、快速傅里叶变换），性能与准确性可能存在一定平衡点。实验目标之一是分析 KML 在保持高精度的同时实现性能提升的能力。\n\n\n结果一致性验证\n确保使用 KML 计算的结果在科学研究或工程应用中具有可接受的准确性，并验证其与传统实现方式的一致性。\n\n\n\n6. 推动数学计算领域的技术进步\n实践新算法\n利用鲲鹏架构和 KML 优化数学运算的能力，探索传统算法在新型硬件架构下的优化潜力。\n\n\n高性能计算的技术转化\n将 KML 的优势推广到实际的工业和学术计算任务中，为数学计算领域的技术进步提供支持。\n\n\n\n2 实验设备\n华为鲲鹏云服务器；\n\n具备网络连接的个人电脑。\n\n\n3 实验原理1. 数学库优化的核心思想鲲鹏数学库（KML）的设计理念是通过充分利用硬件特性提升数学运算的性能。以下是其核心优化思想：\n\n指令级优化\nKML 借助 ARMv8 架构的 SIMD（Single Instruction Multiple Data）指令集，能够在单次指令操作中对多个数据元素进行并行处理，从而显著提升运算速度。\n使用如 Neon 指令等优化数学函数（如三角函数、对数函数等）的批量处理能力。\n\n\n多线程并行\n通过 pthread 和 OpenMP 等多线程技术，KML 可高效分解计算任务，充分利用多核处理器的计算资源。\n\n\n内存访问优化\n避免频繁的内存读取与写入，通过对内存对齐、缓存友好型算法等优化策略，减少数据传输瓶颈。\n\n\n\n2. 硬件架构与性能优化的关系鲲鹏服务器基于 ARM 架构，具备以下硬件特性，KML 在设计时针对这些特性进行了针对性优化：\n\n高密度核心： 鲲鹏处理器具有高核数的特点，非常适合高并发计算任务，KML 可在矩阵运算、FFT 中有效分摊任务到多个核心，降低单核压力。\n宽向量寄存器： ARM 的 SIMD 技术利用宽向量寄存器，使得多数据并行计算成为可能。例如，KML_SVML 的优化实现可一次性处理多个向量元素。\n内存子系统优化： 鲲鹏架构的 L1 和 L2 缓存对矩阵计算中常见的密集存储访问模式进行了专门优化。KML 的矩阵运算函数充分利用了这一特性，通过块状处理减少了内存访问延迟。\n\n3. 数学计算的多层次优化方法KML 的优化覆盖了从低级指令到高级数学库的多个层次：\n\n基础数学函数优化： 优化基本数学函数（如三角函数、指数函数）的实现，通过硬件寄存器和流水线指令集实现批量处理。\nBLAS 和 LAPACK 优化\nBLAS：优化矩阵-向量运算、矩阵-矩阵运算等基础线性代数运算，广泛用于科学计算中。\nLAPACK：在更高级别的线性代数操作（如特征值问题、奇异值分解）中，KML 将关键计算步骤分解为高效的 BLAS 调用，并结合硬件特性进行细粒度优化。\n\n\n快速傅里叶变换（FFT）： FFT 算法中涉及复杂的递归和循环结构，KML 通过流水线技术和分块计算优化了时间复杂度，同时减少了内存访问次数。\n\n4. 实验的对比设计与性能评估策略为了全面评估 KML 的性能，实验采用了“传统实现”和“优化实现”的对比方式：\n\n传统实现：直接使用标准数学库（如 math.h）或手动实现算法，模拟常规的计算方式。\n优化实现：基于 KML 提供的库函数完成相同计算任务。\n性能评估\n时间复杂度：记录不同方法的执行时间，量化性能提升。\n准确性：验证 KML 的计算结果是否与传统实现一致，确保在优化性能的同时保证结果的可靠性。\n资源利用率：观察 CPU、内存的使用情况，分析 KML 如何在硬件资源利用上占据优势。\n\n\n\n5. 典型优化场景\n矩阵运算： 矩阵计算（如矩阵-向量乘法、矩阵分解）是科学计算中的核心任务。KML 针对矩阵密集型计算进行了特殊优化，减少了循环嵌套带来的性能瓶颈。\n高维向量运算： 例如三角函数计算，普通实现逐元素计算效率低下，而 KML 利用向量化技术和批量计算方法，可显著加速处理大规模数据。\n特征值问题： 对称矩阵特征值与特征向量计算涉及复杂的迭代算法，KML 在 LAPACK 的基础上进一步优化了矩阵操作的并行性。\n\n6. KML 的接口设计与易用性\n动态库链接： 用户可通过简单的编译选项链接 KML 提供的动态库，从而快速完成性能优化。\n模块化功能： 不同的子模块（如 BLAS、VML、SPBLAS 等）满足了从基础运算到高级线性代数的多种需求，提供了良好的兼容性和可扩展性。\n\n4 实验任务操作指导4.1安装KML下面介绍如何安装KML\n首先使用远程登录工具，登录到鲲鹏 ECS 服务器上\n下载 WinSCP 客户端并安装。\n启动WinSCP，启动后界面如下：\n\n看不见是正常的，别担心\n\n填写说明：\n\n协议：选填 SFTP 或者 SCP 均可。\n\n主机名：云服务器的公网 IP。登录管理控制台即可查看对应云服务器的公网 IP。\n\n端口：默认 22。\n\n用户名：云服务器的用户名。\n\n使用“SSH密钥方式”登录云服务器时：\n\n如果是“CoreOS”的公共镜像，用户名为“core”。\n\n如果是“非CoreOS”的公共镜像，用户名为“root”。\n\n\n\n使用“密码方式”登录云服务器，公共镜像（包括CoreOS）的用户名为：root。\n\n密码：购买云服务器设置的密码或通过密钥方式转化后的密码。\n\n单击“登录”，进入 “WinSCP” 文件传输界面。\n\n登录成功之后，您可以选择左侧本地计算机的文件，拖拽到右侧的远程云服务器，完成文件上传到云服务器。\n\n\n具体操作可以参考：\n本地Windows主机使用WinSCP上传文件到Linux云服务器 https://support.huaweicloud.com/ecs_faq/zh-cn_topic_0166284971.html\n 然后到https://www.hikunpeng.com/developer/boostkit/library/detail?subtab=%E6%95%B0%E5%AD%A6%E5%BA%93获取KML软件包（GCC版本）\n\n看不见是正常的，别担心\n\n\n看不见是正常的，别担心\n\n下载软件包后解压得到此文件：\n\n看不见是正常的，别担心\n\n再通过“本地Windows主机使用WinSCP上传文件到Linux云服务器https://support.huaweicloud.com/ecs_faq/zh-cn_topic_0166284971.html”中所述的远程登录将该文件上传到云服务器\n接下来安装KML。\n步骤1 登录云服务器，进入刚刚上传文件所在的目录，输入\nrpm -ivh kml-xxxx.aarch64.rpm\n\n安装软件包，其中命令中涉及的xxxx代表版本号，下图示中的版本号是2.4.0-1\n \n看不见是正常的，别担心\n\n步骤 2 安装后验证\n执行source命令或重新登录终端让环境变量生效。\nsource /etc/profile\n\n\n看不见是正常的，别担心\n\n查看环境变量LD_LIBRARY_PATH是否包含KML的安装路径“&#x2F;usr&#x2F;local&#x2F;kml&#x2F;lib”。\nenv | grep LD_LIBRARY_PATH\n\n如果变量包含安装路径，说明安装成功。\n\n看不见是正常的，别担心\n\n安装成功后在安装路径（默认路径是“&#x2F;usr&#x2F;local&#x2F;kml”）下生成相应文件，其中，include文件夹包含子库的头文件，lib文件夹包含了数学库的动态库文件。\n\n看不见是正常的，别担心\n\n使用时，请在GCC编译选项中添加动态库所在路径，链接需要使用的动态库文件，添加编译选项后用ldd命令检查程序依赖库是否准确链接。\n若需要使用KML_BLAS请添加如下代码，此处对官方给出的代码进行适当修改以正常使用：\n单线程不加锁版本：-L /usr/local/kml/lib/kblas/nolocking -lkblas -I /usr/local/kml/include -pthread单线程加锁版本：-L /usr/local/kml/lib/kblas/locking -lkblas -I /usr/local/kml/include -pthreadpthread实现多线程版本：-L /usr/local/kml/lib/kblas/pthread -lkblas -I /usr/local/kml/include -pthreadOpenMP实现多线程版本：-L /usr/local/kml/lib/kblas/omp -lkblas -I /usr/local/kml/include -pthread\n若需要使用KML_VML请添加：\n单线程版本：-L /usr/local/kml/lib/kvml/single -lkvml -L /usr/local/kml/lib -lkm -I /usr/local/kml/include -lm多线程版本：-L /usr/local/kml/lib/kvml/multi -lkvml -L /usr/local/kml/lib -lkm -I /usr/local/kml/include -lm -fopenmp\n若需要使用KML_SPBLAS请添加：\n单线程版本：-L /usr/local/kml/lib/kspblas/single -lkspblas -I /usr/local/kml/include -pthread多线程版本：-L /usr/local/kml/lib/kspblas/multi -lkspblas -I /usr/local/kml/include -pthread\n若需要使用KML_FFT请添加：\n单精度版本：-L /usr/local/kml/lib -lkfftf -I /usr/local/kml/include -pthread双精度版本：-L /usr/local/kml/lib -lkfft -I /usr/local/kml/include -pthread\n若需要使用KML_MATH请添加：\n高性能版本：-L /usr/local/kml/lib -lkm -lm -I /usr/local/kml/include -pthread高精度版本：-L /usr/local/kml/lib -lkm_l9 -lm -I /usr/local/kml/include -pthread\n若需要使用KML_SVML请添加：\n-L /usr/local/kml/lib -lksvml -lm -I /usr/local/kml/include -pthread\n若需要使用KML_VSL请添加：\n-L /usr/local/kml/lib -lkvsl -I /usr/local/kml/include -pthread -lm\n若需要使用KML_LAPACK：\n先生成完整的LAPACK，然后添加：\nexport KML_LAPACK_ROOT=/usr/local/kml/libexport ADAPT_ROOT=/home/lapack_adaptexport KML_BLAS_ROOT=/usr/local/kml/lib/kblas/ompgcc test.c -o test -fopenmp -I $KML_LAPACK_ROOT/include/kml-0.3.0 -L /usr/local/kml/lib -lklapack -L $ADAPT_ROOT -l:liblapack_adapt.a -L $KML_BLAS_ROOT -lkblas -lgfortran -lm -lkservice -I /usr/local/kml/include\n若需要使用KML_IPL请添加：\n-L /usr/local/kml/lib -lkipl -lklapack_full -L /usr/local/kml/lib/kblas/pthread -lkblas -lm -I /usr/local/kml/include -pthread\n若需要使用KML_SCALAPACK ：先生成完整的SCALAPACK，然后添加：\n# 动态gcc test.c -o app  -fopenmp -I /usr/local/kml/lib/kblas/omp/include/kml-0.3.0 -L /usr/local/kml/lib -l:libkscalapack.a -L /home/scalapack_adapt -l:libscalapack_adapt.a -L /usr/local/kml/lib/kblas/omp -l kblas -L /usr/local/kml/lib  -l:libkservice.a -L /home/lapack_adapt -l:liblapack_adapt.a  -lm -I /usr/local/kml/include# 静态export KML_LAPACK_ROOT=/usr/local/kml/libexport ADAPT_ROOT=/home/scalapack_adaptexport KML_BLAS_ROOT=/usr/local/kml/lib/kblas/ompgcc test.c -o app  -fopenmp -I $KML_LAPACK_ROOT/include/kml-0.3.0 -L /usr/local/kml/lib -l:libkscalapack.a -L $ADAPT_ROOT -l:libscalapack_adapt.a -L $KML_BLAS_ROOT -L /home/lapack_adapt -l:liblapack_adapt.a -l:libkservice.a -lm -I /usr/local/kml/include\n\n下面给出两个基础的测试程序用于测试是否已经成功安装\n使用mkdir创建文件夹FFTTEST，使用cd FFTTEST进入，vim test.c创建测试文件\n#include &lt;stdio.h&gt;#include &quot;km.h&quot;int main()&#123;    double pi = acos(-1);     // typical usage     double a = pi/6, b = 1.0, c = -3*pi/4, d = pi/3;     // print result     printf(&quot;sin(pi/6) = %.15f\\n&quot;, sin(a));     printf(&quot;sin(1.0) = %.15f\\n&quot;, sin(b));     printf(&quot;sin(-3*pi/4) = %.15f\\n&quot;, sin(c));      /*      *  sin(pi/6) = 0.500000000000000      *  sin(1.0) = 0.841470984807897      *  sin(-3*pi/4) = -0.707106781186548      *  sin(pi/3) = 0.866025403784438      * */        return 0;&#125;\n\n利用\ngcc test.c -I /usr/local/kml/include -L /usr/local/kml/lib -lkm_l9 -lm\n\n编译，生成a.out\n\n看不见是正常的，别担心\n\n输入\n./a.out\n\n运行，结果如下\n\n看不见是正常的，别担心\n\n接下来尝试用牛顿迭代法求解非线性方程的根\n依次执行命令 mkdir NEWTON、cd NEWTON 创建并进入到 NEWTON 目录。\n创建 sum.c 文件，编写内容如下：\n//牛顿迭代法求解非线性方程的根#include &lt;stdio.h&gt;#include &quot;km.h&quot;double f(double x) &#123;    return x * x - 2; // 函数 f(x) = x^2 - 2&#125;double df(double x) &#123;    return 2 * x; // 函数的导数 f&#x27;(x) = 2x&#125;double newton(double initial_guess, double tolerance, int max_iterations) &#123;    double x = initial_guess;    int iteration = 0;        while (iteration &lt; max_iterations) &#123;        double fx = f(x);        if (fabs(fx) &lt; tolerance) &#123;            return x; // 找到根，返回当前值        &#125;double dfx = df(x);        if (dfx == 0) &#123;            printf(&quot;Error: Derivative is zero. No solution found.\\n&quot;);            return x; // 导数为零，无法继续        &#125;         x = x - fx / dfx; // 牛顿迭代公式        iteration++;    &#125;    printf(&quot;Max iterations reached. Last approximation: %f\\n&quot;, x);    return x; // 返回最后的近似值&#125;int main() &#123;    double initial_guess = 1.0; // 初始猜测    double tolerance = 1e-7; // 容忍度    int max_iterations = 100; // 最大迭代次数    double root;    printf(&quot;With KML:\\n&quot;);    root = newton(initial_guess, tolerance, max_iterations);    printf(&quot;Root found: %f\\n&quot;, root);    return 0;&#125;\n\n输入\ngcc NEWTON_KML.c -I /usr/local/kml/include -L /usr/local/kml/lib -lkm -lm -o NEWTON_KML./NEWTON_KML\n\n运行之，结构如下：\n\n看不见是正常的，别担心\n\n至此说明kml安装成功\n4.2 矩阵-向量乘加运算对比实验该代码主要进行了如下工作：初始化规模为1000*300的矩阵A，长度为300的向量x，长度为1000的向量y1和y2。分别用两种方法求矩阵-向量乘加运算，即y&#x3D;alpha*A*x+beta*y： \n（1）按照矩阵-向量的乘加规则实现算法求解 \n（2）调用KML_BLAS提供的函数cblas_dgemv求解 分别用计时器记录两种方法消耗的时间，对比KML_BLAS与手动实现矩阵乘加的性能。 \n编写代码如下：\n#include&lt;stdio.h&gt;#include&lt;time.h&gt;#include &quot;kblas.h&quot;#define M 1000#define N 300int main()&#123;    double A[M*N]=&#123;0&#125;;double x[N]=&#123;0&#125;;double y1[M]=&#123;0&#125;;double y2[M]=&#123;0&#125;;for (int i=0;i&lt;M*N;i++)&#123;   A[i]=i;&#125;for (int i=0;i&lt;N;i++)&#123;   x[i]=i;&#125;for (int i=0;i&lt;M;i++)&#123;   y1[i]=1;   y2[i]=1;&#125; double alpha=1.2;double beta=2.5;struct timespec t1,t2;    //定义初始与结束时间printf(&quot;Without KML:\\n&quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。for(int i=0;i&lt;M;i++)&#123;   double tmp=0;    for(int j=0;j&lt;N;j++)    &#123;         tmp+=(A[i*N+j]*x[j]);    &#125;    y1[i]=alpha*tmp+beta*y1[i];&#125;clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);  printf(&quot;With KML:\\n&quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。cblas_dgemv(CblasColMajor,CblasNoTrans, M, N, alpha, A, M, x, 1, beta, y2, 1); clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);  return 0;&#125;\n\n输入：\ngcc kblas.c -o kblas -L /usr/local/kml/lib/kblas/nolocking -lkblas -I /usr/local/kml/include\n\n运行之，得到运行结果如下：\n\n看不见是正常的，别担心\n\n可知KML_BLAS提供的函数cblas_dgemv对矩阵-向量乘加运算的优化效果十分显著\n4.3 调用KML_VML库计算100000个数的sin值和普通循环对比体现优化使用多线程版本\n#include&lt;stdio.h&gt;#include&lt;time.h&gt;#include&lt;math.h&gt;#include&quot;kvml.h&quot;#define LEN 100000int main()&#123;   double src[LEN]=&#123;0&#125;;   double dst1[LEN]=&#123;0&#125;;   double dst2[LEN]=&#123;0&#125;;   for(int i=0;i&lt;LEN;i++)       src[i]=i;    struct timespec t1,t2;    //定义初始与结束时间    printf(&quot;Without KML_VML &quot;);    clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。    for(int i=0;i&lt;LEN;i++)       dst1[i]=sin(src[i]);    clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。    printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);  //得出目标代码段的执行时间。    printf(&quot;With KML_VML &quot;);    clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。    vdsin(LEN,src,dst2);    clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。    printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);  //得出目标代码段的执行时间。return 0;&#125;\n\n输入\ngcc vsin.c -o vsin -L /usr/local/kml/lib/kvml/multi -lkvml -L /usr/local/kml/lib -lkm -I /usr/local/kml/include -lm -fopenmp./vsin\n\n运行结果如下所示：\n\n看不见是正常的，别担心\n\n可知KML_VML库对三角函数运算的优化效果十分显著\n4.4 体现LAPACK库性能的对比实验首先要生成完整的LAPACK用到的脚本\n接下来的程序需要脚本才能正确运行\n在&#x2F;home目录下创建sh.sh文件，接着编写如下代码：\nset -eEecho &quot;LAPACK_SRC_DIR         $&#123;LAPACK_SRC_DIR:-&lt;undefined&gt;&#125;&quot;echo &quot;LAPACK_TGZ             $&#123;LAPACK_TGZ:=/home/lapack-3.12.0.tar.gz&#125;&quot;echo &quot;LIBKLAPACK_A           $&#123;LIBKLAPACK_A:=/usr/local/kml/lib/libklapack.a&#125;&quot;echo &quot;LIBKSERVICE_A          $&#123;LIBKSERVICE_A:=$&#123;LIBKLAPACK_A/klapack/kservice&#125;&#125;&quot;echo &quot;ADAPT_DIR              $&#123;ADAPT_DIR:=./lapack_adapt&#125;&quot;echo &quot;CMAKE_BUILD_TYPE       $&#123;CMAKE_BUILD_TYPE:=Release&#125;&quot;echo &quot;LIBLAPACK_ADAPT_A      $&#123;LIBLAPACK_ADAPT_A:=liblapack_adapt.a&#125;&quot;echo &quot;LIBKLAPACK_FULL_SO     $&#123;LIBKLAPACK_FULL_SO:=libklapack_full.so&#125;&quot;echo &quot;CC                     $&#123;CC:=gcc&#125;&quot;echo &quot;FC                     $&#123;FC:=gfortran&#125;&quot;mkdir -p $&#123;ADAPT_DIR&#125;ZQcd $&#123;ADAPT_DIR&#125;# build netlib lapackif [ ! -r &quot;$&#123;LAPACK_SRC_DIR&#125;/CMakeLists.txt&quot; ]; then    mkdir -p netlib    ( cd netlib ; tar xzpf $&#123;LAPACK_TGZ&#125; )    LAPACK_SRC_DIR=$(cd netlib/l* ; pwd)fimkdir -p buildcmake_flags=(    -DCMAKE_BUILD_TYPE=$&#123;CMAKE_BUILD_TYPE&#125;    -DCMAKE_POSITION_INDEPENDENT_CODE=ON    -DCMAKE_C_COMPILER=$&#123;CC&#125;    -DCMAKE_Fortran_COMPILER=$&#123;FC&#125;    -DCMAKE_RULE_MESSAGES=off    -DBUILD_DEPRECATED=on    -DBUILD_TESTING=off)( cd build ; cmake $&#123;cmake_flags[*]&#125; $&#123;LAPACK_SRC_DIR&#125; )( cd build ; make -j )cp build/lib/liblapack.a $&#123;LIBLAPACK_ADAPT_A&#125;# get symbols defined both in klapack and netlib lapacknm -g $&#123;LIBLAPACK_ADAPT_A&#125; | grep &#x27;T &#x27; | grep -oP &#x27;\\K\\w+(?=_$)&#x27; | sort | uniq &gt; netlib.symnm -g $&#123;LIBKLAPACK_A&#125; | grep &#x27;T &#x27; | grep -oP &#x27;\\K\\w+(?=_$)&#x27; | sort | uniq &gt; klapack.symcomm -12 klapack.sym netlib.sym &gt; comm.sym# update symbols name of $&#123;LIBLAPACK_ADAPT_A&#125;while read sym; do    (        if ! nm $&#123;LIBLAPACK_ADAPT_A&#125; | grep -qe &quot; T $&#123;sym&#125;_\\$&quot;; then            continue        fi        ar x $&#123;LIBLAPACK_ADAPT_A&#125; $&#123;sym&#125;.f.o        mv $&#123;sym&#125;.f.o $&#123;sym&#125;_netlib.f.o        objcopy --redefine-sym $&#123;sym&#125;_=$&#123;sym&#125;_netlib_ $&#123;sym&#125;_netlib.f.o    ) &amp;done &lt; comm.symwaitar d $&#123;LIBLAPACK_ADAPT_A&#125; $(sed -ne &#x27;s/$/.f.o/p&#x27; comm.sym)ar d $&#123;LIBLAPACK_ADAPT_A&#125; xerbla.f.oar ru $&#123;LIBLAPACK_ADAPT_A&#125; *_netlib.f.orm *_netlib.f.o\n\n在&#x2F;home目录下输入\nsh sh.sh\n\n运行之，得到如下结果：\n\n看不见是正常的，别担心\n\n\n看不见是正常的，别担心\n\n至此LAPACK用到的脚本已经生成完毕\n接下来先展示如何使用一般c语言代码计算实对称矩阵的特征值与特征向量\n编写eigenNoOpt.c文件，文件内容如下：\n#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;math.h&gt;#include&lt;time.h&gt;float** Matrix_Jac_Eig(float **array, int n, float *eig);int Matrix_Free(float **tmp, int m, int n);int main(void)&#123;    int n;    printf(&quot;请输入矩阵维度:\\n&quot;);    scanf(&quot;%d&quot;, &amp;n);    float **array = (float **)malloc(n * sizeof(float *));    if (array == NULL)    &#123;        printf(&quot;error :申请数组内存空间失败\\n&quot;);        return -1;    &#125;    for (int i = 0; i &lt; n; i++)    &#123;        array[i] = (float *)malloc(n * sizeof(float));        if (array[i] == NULL)        &#123;            printf(&quot;error :申请数组子内存空间失败\\n&quot;);            return -1;        &#125;    &#125;    printf(&quot;请输入矩阵元素:\\n&quot;);    for (int i = 0; i &lt; n; i++)    &#123;        for (int j = 0; j &lt; n; j++)        &#123;            scanf(&quot;%f&quot;, &amp;array[i][j]);        &#125;    &#125;    float *eig = (float *)malloc(n * sizeof(float));        struct timespec t1,t2;    printf(&quot;Without KML:\\n&quot;);    clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。    float **Result = Matrix_Jac_Eig(array, n, eig);    clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。    printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);      printf(&quot;特征矩阵元素:\\n&quot;);    for (int i = 0; i &lt; n; i++)    &#123;        for (int j = 0; j &lt; n; j++)        &#123;            printf(&quot;%f &quot;, Result[i][j]);        &#125;        printf(&quot;\\n&quot;);    &#125;    printf(&quot;特征根:\\n&quot;);    for (int i = 0; i &lt; n; i++)    &#123;        printf(&quot;%f \\n&quot;, eig[i]);    &#125;    Matrix_Free(Result, n, n);    free(eig);    eig = NULL;    return 0;&#125;float** Matrix_Jac_Eig(float **array, int n, float *eig)&#123;    int i, j, flag, k;    flag = 0;    k = 0;    float sum = 0;    float **temp_mat = (float **)malloc(n * sizeof(float *));    for (i = 0; i &lt; n; i++)    &#123;        temp_mat[i] = (float *)malloc(n * sizeof(float));    &#125;    for (i = 0; i &lt; n; i++)    &#123;        for (j = 0; j &lt; n; j++)        &#123;            temp_mat[i][j] = array[i][j];        &#125;    &#125;    //判断是否为对称矩阵    for (i = 0; i &lt; n; i++)    &#123;        for (j = i; j &lt; n; j++)        &#123;            if (array[i][j] != array[j][i])            &#123;                flag = 1;                break;            &#125;        &#125;    &#125;    if (flag == 1)    &#123;        printf(&quot;error in Matrix_Eig: 输入并非是对称矩阵:\\n&quot;);        return NULL;    &#125;    else    &#123;        //开始执行算法        int p, q;        float thresh = 0.0000000001;        float max = array[0][1];        float tan_angle, sin_angle, cos_angle;        float **result = (float **)malloc(n * sizeof(float *));        if (result == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **result_temp = (float **)malloc(n * sizeof(float *));        if (result_temp == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **rot = (float **)malloc(n * sizeof(float *));        if (rot == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **mat = (float **)malloc(n * sizeof(float *));        if (mat == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            result[i] = (float *)malloc(n * sizeof(float));            if (result[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            result_temp[i] = (float *)malloc(n * sizeof(float));            if (result_temp[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            rot[i] = (float *)malloc(n * sizeof(float));            if (rot[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            mat[i] = (float *)malloc(n * sizeof(float));            if (mat[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    result[i][j] = 1;                &#125;                else                &#123;                    result[i][j] = 0;                &#125;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    mat[i][j] = 1;                &#125;                else                &#123;                    mat[i][j] = 0;                &#125;            &#125;        &#125;        max = array[0][1];        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    continue;                &#125;                else                &#123;                    if (fabs(array[i][j]) &gt;= fabs(max))                    &#123;                        max = array[i][j];                        p = i;                        q = j;                    &#125;                    else                    &#123;                        continue;                    &#125;                &#125;            &#125;        &#125;        while (fabs(max) &gt; thresh)        &#123;            if (fabs(max) &lt; thresh)            &#123;                break;            &#125;            tan_angle = -2 * array[p][q] / (array[q][q] - array[p][p]);            sin_angle = sin(0.5*atan(tan_angle));            cos_angle = cos(0.5*atan(tan_angle));            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    if (i == j)                    &#123;                        mat[i][j] = 1;                    &#125;                    else                    &#123;                        mat[i][j] = 0;                    &#125;                &#125;            &#125;            mat[p][p] = cos_angle;            mat[q][q] = cos_angle;            mat[q][p] = sin_angle;            mat[p][q] = -sin_angle;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    rot[i][j] = array[i][j];                &#125;            &#125;            for (j = 0; j &lt; n; j++)            &#123;                rot[p][j] = cos_angle*array[p][j] + sin_angle*array[q][j];                rot[q][j] = -sin_angle*array[p][j] + cos_angle*array[q][j];                rot[j][p] = cos_angle*array[j][p] + sin_angle*array[j][q];                rot[j][q] = -sin_angle*array[j][p] + cos_angle*array[j][q];            &#125;            rot[p][p] = array[p][p] * cos_angle*cos_angle +                array[q][q] * sin_angle*sin_angle +                2 * array[p][q] * cos_angle*sin_angle;            rot[q][q] = array[q][q] * cos_angle*cos_angle +                array[p][p] * sin_angle*sin_angle -                2 * array[p][q] * cos_angle*sin_angle;            rot[p][q] = 0.5*(array[q][q] - array[p][p]) * 2 * sin_angle*cos_angle +                array[p][q] * (2 * cos_angle*cos_angle - 1);            rot[q][p] = 0.5*(array[q][q] - array[p][p]) * 2 * sin_angle*cos_angle +                array[p][q] * (2 * cos_angle*cos_angle - 1);            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    array[i][j] = rot[i][j];                &#125;            &#125;            max = array[0][1];            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    if (i == j)                    &#123;                        continue;                    &#125;                    else                    &#123;                        if (fabs(array[i][j]) &gt;= fabs(max))                        &#123;                            max = array[i][j];                            p = i;                            q = j;                        &#125;                        else                        &#123;                            continue;                        &#125;                    &#125;                &#125;            &#125;            for (i = 0; i &lt; n; i++)            &#123;                eig[i] = array[i][i];            &#125;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    sum = 0;                    for (k = 0; k &lt; n; k++)                    &#123;                        sum = sum + result[i][k] * mat[k][j];                    &#125;                    result_temp[i][j] = sum;                &#125;            &#125;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    result[i][j] = result_temp[i][j];                &#125;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                array[i][j] = temp_mat[i][j];            &#125;        &#125;        Matrix_Free(result_temp, n, n);        Matrix_Free(rot, n, n);        Matrix_Free(mat, n, n);        Matrix_Free(temp_mat, n, n);        return result;    &#125;&#125;int Matrix_Free(float **tmp, int m, int n)&#123;    int i, j;    if (tmp == NULL)    &#123;        return(1);    &#125;    for (i = 0; i &lt; m; i++)    &#123;        if (tmp[i] != NULL)        &#123;            free(tmp[i]);            tmp[i] = NULL;        &#125;    &#125;    if (tmp != NULL)    &#123;        free(tmp);        tmp = NULL;    &#125;    return(0);&#125;\n\n输入如下代码对其进行编译并运行：\ngcc eigenNoOpt.c -o eigenNoOpt -lm./eigenNoOpt    \n\n得到运行结果如下：\n\n看不见是正常的，别担心\n\n对其进行改进，并作体现LAPACK库性能的对比实验如下：\n将传统C语言算法的代码改为如下：\n#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;#include&lt;math.h&gt;#include&lt;time.h&gt;float** Matrix_Jac_Eig(float **array, int n, float *eig);int Matrix_Free(float **tmp, int m, int n);int main(void)&#123;    int n;    printf(&quot;请输入矩阵维度:\\n&quot;);    scanf(&quot;%d&quot;, &amp;n);    float **array = (float **)malloc(n * sizeof(float *));    if (array == NULL)    &#123;        printf(&quot;error :申请数组内存空间失败\\n&quot;);        return -1;    &#125;    for (int i = 0; i &lt; n; i++)    &#123;        array[i] = (float *)malloc(n * sizeof(float));        if (array[i] == NULL)        &#123;            printf(&quot;error :申请数组子内存空间失败\\n&quot;);            return -1;        &#125;    &#125;    printf(&quot;请输入矩阵元素:\\n&quot;);    for (int i = 0; i &lt; n; i++)    &#123;        for (int j = 0; j &lt; n; j++)        &#123;            scanf(&quot;%f&quot;, &amp;array[i][j]);        &#125;    &#125;    float *eig = (float *)malloc(n * sizeof(float));        struct timespec t1,t2;    printf(&quot;Without KML:\\n&quot;);    clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。    float **Result = Matrix_Jac_Eig(array, n, eig);    clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。    printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);      Matrix_Free(Result, n, n);    free(eig);    eig = NULL;    return 0;&#125;float** Matrix_Jac_Eig(float **array, int n, float *eig)&#123;    int i, j, flag, k;    flag = 0;    k = 0;    float sum = 0;    float **temp_mat = (float **)malloc(n * sizeof(float *));    for (i = 0; i &lt; n; i++)    &#123;        temp_mat[i] = (float *)malloc(n * sizeof(float));    &#125;    for (i = 0; i &lt; n; i++)    &#123;        for (j = 0; j &lt; n; j++)        &#123;            temp_mat[i][j] = array[i][j];        &#125;    &#125;    //判断是否为对称矩阵    for (i = 0; i &lt; n; i++)    &#123;        for (j = i; j &lt; n; j++)        &#123;            if (array[i][j] != array[j][i])            &#123;                flag = 1;                break;            &#125;        &#125;    &#125;    if (flag == 1)    &#123;        printf(&quot;error in Matrix_Eig: 输入并非是对称矩阵:\\n&quot;);        return NULL;    &#125;    else    &#123;        //开始执行算法        int p, q;        float thresh = 0.0000000001;        float max = array[0][1];        float tan_angle, sin_angle, cos_angle;        float **result = (float **)malloc(n * sizeof(float *));        if (result == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **result_temp = (float **)malloc(n * sizeof(float *));        if (result_temp == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **rot = (float **)malloc(n * sizeof(float *));        if (rot == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        float **mat = (float **)malloc(n * sizeof(float *));        if (mat == NULL)        &#123;            printf(&quot;error in Matrix_Eig:申请空间失败\\n&quot;);            return NULL;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            result[i] = (float *)malloc(n * sizeof(float));            if (result[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            result_temp[i] = (float *)malloc(n * sizeof(float));            if (result_temp[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            rot[i] = (float *)malloc(n * sizeof(float));            if (rot[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;            mat[i] = (float *)malloc(n * sizeof(float));            if (mat[i] == NULL)            &#123;                printf(&quot;error in Matrix_Eig:申请子空间失败\\n&quot;);                return NULL;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    result[i][j] = 1;                &#125;                else                &#123;                    result[i][j] = 0;                &#125;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    mat[i][j] = 1;                &#125;                else                &#123;                    mat[i][j] = 0;                &#125;            &#125;        &#125;        max = array[0][1];        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                if (i == j)                &#123;                    continue;                &#125;                else                &#123;                    if (fabs(array[i][j]) &gt;= fabs(max))                    &#123;                        max = array[i][j];                        p = i;                        q = j;                    &#125;                    else                    &#123;                        continue;                    &#125;                &#125;            &#125;        &#125;        while (fabs(max) &gt; thresh)        &#123;            if (fabs(max) &lt; thresh)            &#123;                break;            &#125;            tan_angle = -2 * array[p][q] / (array[q][q] - array[p][p]);            sin_angle = sin(0.5*atan(tan_angle));            cos_angle = cos(0.5*atan(tan_angle));            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    if (i == j)                    &#123;                        mat[i][j] = 1;                    &#125;                    else                    &#123;                        mat[i][j] = 0;                    &#125;                &#125;            &#125;            mat[p][p] = cos_angle;            mat[q][q] = cos_angle;            mat[q][p] = sin_angle;            mat[p][q] = -sin_angle;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    rot[i][j] = array[i][j];                &#125;            &#125;            for (j = 0; j &lt; n; j++)            &#123;                rot[p][j] = cos_angle*array[p][j] + sin_angle*array[q][j];                rot[q][j] = -sin_angle*array[p][j] + cos_angle*array[q][j];                rot[j][p] = cos_angle*array[j][p] + sin_angle*array[j][q];                rot[j][q] = -sin_angle*array[j][p] + cos_angle*array[j][q];            &#125;            rot[p][p] = array[p][p] * cos_angle*cos_angle +                array[q][q] * sin_angle*sin_angle +                2 * array[p][q] * cos_angle*sin_angle;            rot[q][q] = array[q][q] * cos_angle*cos_angle +                array[p][p] * sin_angle*sin_angle -                2 * array[p][q] * cos_angle*sin_angle;            rot[p][q] = 0.5*(array[q][q] - array[p][p]) * 2 * sin_angle*cos_angle +                array[p][q] * (2 * cos_angle*cos_angle - 1);            rot[q][p] = 0.5*(array[q][q] - array[p][p]) * 2 * sin_angle*cos_angle +                array[p][q] * (2 * cos_angle*cos_angle - 1);            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    array[i][j] = rot[i][j];                &#125;            &#125;            max = array[0][1];            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    if (i == j)                    &#123;                        continue;                    &#125;                    else                    &#123;                        if (fabs(array[i][j]) &gt;= fabs(max))                        &#123;                            max = array[i][j];                            p = i;                            q = j;                        &#125;                        else                        &#123;                            continue;                        &#125;                    &#125;                &#125;            &#125;            for (i = 0; i &lt; n; i++)            &#123;                eig[i] = array[i][i];            &#125;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    sum = 0;                    for (k = 0; k &lt; n; k++)                    &#123;                        sum = sum + result[i][k] * mat[k][j];                    &#125;                    result_temp[i][j] = sum;                &#125;            &#125;            for (i = 0; i &lt; n; i++)            &#123;                for (j = 0; j &lt; n; j++)                &#123;                    result[i][j] = result_temp[i][j];                &#125;            &#125;        &#125;        for (i = 0; i &lt; n; i++)        &#123;            for (j = 0; j &lt; n; j++)            &#123;                array[i][j] = temp_mat[i][j];            &#125;        &#125;        Matrix_Free(result_temp, n, n);        Matrix_Free(rot, n, n);        Matrix_Free(mat, n, n);        Matrix_Free(temp_mat, n, n);        return result;    &#125;&#125;int Matrix_Free(float **tmp, int m, int n)&#123;    int i, j;    if (tmp == NULL)    &#123;        return(1);    &#125;    for (i = 0; i &lt; m; i++)    &#123;        if (tmp[i] != NULL)        &#123;            free(tmp[i]);            tmp[i] = NULL;        &#125;    &#125;    if (tmp != NULL)    &#123;        free(tmp);        tmp = NULL;    &#125;    return(0);&#125;\n\n将调用KML库的那段代码中改为：\n#include&lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include&lt;time.h&gt;#include&lt;stdlib.h&gt;#include &quot;klapack.h&quot;int main()&#123;      char jobz = &#x27;V&#x27;;     char uplo = &#x27;L&#x27;;     int n = 10;     int lda = 10;     int info = 0;     double w[10];     double *work = NULL;     double qwork;     int lwork = -1;     int *iwork = NULL;     int qiwork;     int liwork = -1;     double a[] =     &#123;  1.23, 2.75, 3.10, 4.56, 5.92, 7.01, 8.40, 9.88, 6.34, 4.59, 2.75, 1.56, 2.49, 3.31, 4.47, 5.90, 6.55, 7.10, 8.22, 5.78,  3.10, 2.49, 1.88, 5.39, 6.23, 7.68, 3.79, 4.12, 6.44, 7.85,  4.56, 3.31, 5.39, 8.94, 4.58, 2.53, 6.83, 7.46, 1.56, 3.21,  5.92, 4.47, 6.23, 4.58, 9.76, 8.90, 5.12, 3.98, 2.63, 6.34,  7.01, 5.90, 7.68, 2.53, 8.90, 6.75, 4.80, 1.94, 3.55, 2.88,  8.40, 6.55, 3.79, 6.83, 5.12, 4.80, 1.64, 9.20, 5.90, 4.75,  9.88, 7.10, 4.12, 7.46, 3.98, 1.94, 9.20, 7.44, 2.38, 6.71,  6.34, 8.22, 6.44, 1.56, 2.63, 3.55, 5.90, 2.38, 0.76, 2.13,  4.59, 5.78, 7.85, 3.21, 6.34, 2.88, 4.75, 6.71, 2.13, 9.32    &#125;;     struct timespec t1,t2;    //定义初始与结束时间    /* Query optimal work size */     dsyevd_(&amp;jobz, &amp;uplo, &amp;n, a, &amp;lda, w, &amp;qwork, &amp;lwork, &amp;qiwork, &amp;liwork, &amp;info);     if (info != 0)     &#123;         return -1;     &#125;     lwork = (int)qwork;     work = (double *)malloc(sizeof(double) * lwork);     liwork = (int)qiwork;     iwork = (int *)malloc(sizeof(int) * liwork);     /* Calculate eigenvalues and eigenvectors */     printf(&quot;With KML:\\n&quot;);    clock_gettime(CLOCK_MONOTONIC,&amp;t1);      //计算开始时间。    dsyevd_(&amp;jobz, &amp;uplo, &amp;n, a, &amp;lda, w, work, &amp;lwork, iwork, &amp;liwork, &amp;info);     clock_gettime(CLOCK_MONOTONIC,&amp;t2);    //计算结束时间。      printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec);      free(work);     free(iwork);           return 0;&#125;\n\n编译并运行，得到结果如下：\n\n看不见是正常的，别担心\n\n可知LAPACK库对运算的优化效果十分显著\n4.5 使用KML库函数实现R2R变换优化首先是使用一般C语言实现R2R变换\n编写without.c文件，文件内容如下：\n#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;void r2r_fft(double *in, double *out, int n) &#123;    int k, m, j;    double wr, wi, arg, c, s;    double *temp = (double*)malloc(n * sizeof(double));        // 实数的 R2R FFT 变换实现    for (k = 0; k &lt; n; k++) &#123;        temp[k] = in[k];    &#125;    // R2R FFT 变换    for (m = 1; m &lt;= n / 2; m *= 2) &#123;        wr = cos(M_PI / m);        wi = sin(M_PI / m);        for (k = 0; k &lt; n; k += 2 * m) &#123;            for (j = 0; j &lt; m; j++) &#123;                arg = j * (2 * M_PI / (2 * m));                c = cos(arg);                s = sin(arg);                double u1 = temp[k + j];                double u2 = temp[k + j + m];                double v1 = temp[k + j + m + 1];                out[k + j] = u1 + u2 * c - v1 * s;                out[k + j + 1] = u1 * s + u2 * v1 * c;            &#125;        &#125;    &#125;    free(temp);&#125;int main() &#123;    int rank = 2;     int *n;     struct timespec t1, t2;     n = (int*)malloc(sizeof(int) * rank);     n[0] = 128;  // 修改数据规模    n[1] = 128;  // 修改数据规模    double *in = (double*)malloc(sizeof(double) * n[0] * n[1]);     for (int i = 0; i &lt; n[0] * n[1]; i++) &#123;         in[i] = (double)(i % 10);  // 用一些基本的数值初始化输入数据    &#125;     double *out = (double*)malloc(sizeof(double) * n[0] * n[1]);    clock_gettime(CLOCK_MONOTONIC, &amp;t1);      // 计算开始时间    r2r_fft(in, out, n[0] * n[1]);            // 执行 R2R FFT    clock_gettime(CLOCK_MONOTONIC, &amp;t2);      // 计算结束时间    printf(&quot;Without KML:\\n&quot;);    printf(&quot;Time: %11u ns\\n&quot;, t2.tv_nsec - t1.tv_nsec);      free(n);    free(in);     free(out);    return 0;&#125;\n\n使用如下代码编译并运行\ngcc without.c -o without -lm./without    \n\n得到结果如下：\n\n看不见是正常的，别担心\n\n接着再使用KML_FFT库函数进行优化：\n编写FFT.c文件，内容如下：\n#include &lt;stdio.h&gt;#include &lt;time.h&gt;#include &lt;math.h&gt;#include &quot;kfft.h&quot;int main() &#123;    int rank = 2;     int *n;     struct timespec t1, t2;    // 定义初始与结束时间    n = (int*)kml_fft_malloc(sizeof(int) * rank);     n[0] = 128;  // 修改数据规模    n[1] = 128;  // 修改数据规模    double *in = (double*)kml_fft_malloc(sizeof(double) * n[0] * n[1]);     for (int i = 0; i &lt; n[0] * n[1]; i++) &#123;         in[i] = (double)(i % 10);  // 用一些基本的数值初始化输入数据    &#125;     double *out = (double*)kml_fft_malloc(sizeof(double) * n[0] * n[1]);     kml_fft_r2r_kind *kind = (kml_fft_r2r_kind*)kml_fft_malloc(sizeof(kml_fft_r2r_kind) * rank);     kind[0] = KML_FFT_DHT;     kind[1] = KML_FFT_DHT;     kml_fft_plan plan;     clock_gettime(CLOCK_MONOTONIC, &amp;t1);      // 计算开始时间    plan = kml_fft_plan_r2r(rank, n, in, out, kind, KML_FFT_ESTIMATE);     kml_fft_execute_r2r(plan, in, out);     clock_gettime(CLOCK_MONOTONIC, &amp;t2);      // 计算结束时间     printf(&quot;With KML:\\n&quot;);    printf(&quot;Time: %11u ns\\n&quot;, t2.tv_nsec - t1.tv_nsec);      printf(&quot;\\n&quot;);    kml_fft_destroy_plan(plan);     kml_fft_free(n);     kml_fft_free(kind);     kml_fft_free(in);     kml_fft_free(out);     return 0;&#125;\n\n使用如下代码编译并运行\ngcc FFT.c -o FFT -L /usr/local/kml/lib -lkfft -I /usr/local/kml/include -pthread./FFT\n\n得到运行结果如下：\n\n看不见是正常的，别担心\n\n可知KML库对R2R FFT运算的优化效果十分显著\n5.实验结果分析1. 牛顿迭代法求解非线性方程的根\n实现了牛顿迭代法，通过简单的非线性方程（如 $f(x)&#x3D;x2−2$）验证计算结果的准确性。\n传统实现和 KML 的计算结果一致，说明 KML 提供的数学库可以准确求解非线性问题。\n\n2. 矩阵-向量乘加运算性能对比\n在矩阵规模为 1000×300 的情况下，KML 的矩阵乘加操作（cblas_dgemv）相比手动实现加速显著。\n时间数据\n手动实现耗时较长，主要由于逐元素计算导致的循环开销。\n调用 KML 提供的 BLAS 库后，耗时明显减少，充分利用了向量化和并行化。\n\n\n结论：KML 在矩阵计算场景中展现了出色的性能提升。\n\n3. KML_VML 向量数学运算优化\n比较普通循环与 KML 的矢量数学库处理大规模向量（如 100,000 元素）的性能。\n时间数据\n传统实现逐元素计算，耗时较长。\nKML 利用硬件寄存器和 SIMD 指令对数据进行批量处理，极大缩短了运算时间。\n\n\n分析：适合高频调用数学函数的场景，例如模拟计算和信号处理。\n\n4. 快速傅里叶变换（FFT）优化\n对比一般 FFT 算法和 KML_FFT 实现的性能。\n时间数据\n手动实现 FFT 的时间复杂度较高。\nKML 的 kml_fft_plan_r2r 方法不仅加速了计算，还简化了实现过程。\n\n\n结论：KML 的 FFT 模块对高维变换计算尤为高效。\n\n5. LAPACK 在实对称矩阵特征值计算中的优化\n测试任务：计算 $10\\times10$ 实对称矩阵的特征值和特征向量。\n结果分析\n传统实现（如 Jacobi 方法）存在显著计算瓶颈。\n调用 KML 提供的 LAPACK 接口后，计算时间大幅缩短，进一步展示了 KML 在线性代数中的优化潜力。\n\n\n\n通过上述实验，验证了鲲鹏数学库（KML）的性能和适用性。无论是基础数学运算、矩阵计算，还是更复杂的快速变换与特征值问题，KML 的表现均优于传统实现。同时，实验中总结出的优化方法对未来的高性能计算实践提供了有力支持。\n6 思考题使用KML_SVML进行短向量的数学运算优化KML_SVML是短向量的数学运算，包括幂函数、三角函数、指数函数、双曲函数、对数函数等。 KML_SVML通过Neon指令优化、内联汇编等方法，对输入向量进行批量处理，充分利用了鲲鹏架构下的寄存器特点，实现了在鲲鹏服务器上的性能提升。\n请在下面代码空缺处将调用KML_SVML库函数对短向量的数学运算进行优化的代码补充完整\n#include&lt;stdio.h&gt;#include&lt;time.h&gt;#include&lt;math.h&gt;#include&quot;ksvml.h&quot;#define LEN 100000int main()&#123;double src[LEN]=&#123;0&#125;;double dst1[LEN]=&#123;0&#125;;double dst2[LEN]=&#123;0&#125;;float32x4_t src2;float32x4_t dst;struct timespec t1,t2; //定义初始与结束时间printf(&quot;Without KML_SVML &quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1); //计算开始时间。for(int i=0;i&lt;LEN;i++)src[i]=i;for(int i=0;i&lt;LEN;i++)dst1[i]=sin(src[i]);clock_gettime(CLOCK_MONOTONIC,&amp;t2); //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec); //得出目标代码段的执行时间。printf(&quot;With KML_SVML &quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1); //计算开始时间。  for(int i=0;i&lt;LEN;i+=4)&#123;   \t//请在此处补充调用KML_SVML库函数对短向量的数学运算进行优化的代码    &#125;clock_gettime(CLOCK_MONOTONIC,&amp;t2); //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec); //得出目标代码段的执行时间。return 0;&#125;\n\n答案如下：\n#include&lt;stdio.h&gt;#include&lt;time.h&gt;#include&lt;math.h&gt;#include&quot;ksvml.h&quot;#define LEN 100000int main()&#123;double src[LEN]=&#123;0&#125;;double dst1[LEN]=&#123;0&#125;;double dst2[LEN]=&#123;0&#125;;float32x4_t src2;float32x4_t dst;struct timespec t1,t2; //定义初始与结束时间printf(&quot;Without KML_SVML &quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1); //计算开始时间。for(int i=0;i&lt;LEN;i++)src[i]=i;for(int i=0;i&lt;LEN;i++)dst1[i]=sin(src[i]);clock_gettime(CLOCK_MONOTONIC,&amp;t2); //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec); //得出目标代码段的执行时间。printf(&quot;With KML_SVML &quot;);clock_gettime(CLOCK_MONOTONIC,&amp;t1); //计算开始时间。  for(int i=0;i&lt;LEN;i+=4)&#123;    src2[0]=i;    src2[1]=i+1;    src2[2]=i+2;    src2[3]=i+3;    dst = svml128_sin_f32(src2);&#125;clock_gettime(CLOCK_MONOTONIC,&amp;t2); //计算结束时间。printf(&quot;Time:%11u ns\\n&quot;,t2.tv_nsec-t1.tv_nsec); //得出目标代码段的执行时间。return 0;&#125;\n\n输入\ngcc svsin.c -o svsin -I /usr/local/kml/include -L /usr/local/kml/lib -lksvml -lm./svsin\n\n编译并运行得到运行结果如下：\n\n看不见是正常的，别担心\n\n通过对比可知使用KML_SVML进行短向量的数学运算优化的优化效果十分显著\n","categories":["学习"],"tags":["华为","计算机组成原理","论文","鲲鹏"]},{"title":"不推荐购买树莓派小车拓展套件","url":"/2025/08/26/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%B0%8F%E8%BD%A6%E6%8B%93%E5%B1%95%E5%A5%97%E4%BB%B6/","content":"不推荐购买树莓派小车拓展套件\n\n\n之前买了一块树莓派五，暑假一直闲置着，就想着重新拿出来玩一玩，刚好逛淘宝时看见了一款小车拓展板及配件，就一时上头买了回来，组装，烧录专门的系统，上手玩，一个下午就把树莓派小车跑了起来，可以做简单的OpenCV视觉追踪，可以巡线，可以全向移动，但是总觉得很空虚，因为所有的一切都是现成的，更是基于商家提供的拓展板的，而不是直接通过树莓派的gpio，我从这个“玩具”里学不到任何与树莓派或者单片机相关的知识，唯一只有与OpenCV相关的内容是不基于商家提供的拓展板。于是就有一种说不上来的无力感。感觉这就是单纯的玩具，没有任何使用价值。玩这个我甚至学不到任何一个外设驱动的开发，因为一切都是包装好的。就两天时间，我恍然体验到了我买他的原因与实际的体验的巨大落差，于是他又被我搁置到了一边。\n今天在知乎逛看到了一篇讲嵌入式Linux开发相关的内容，内容如下\n网上那些教程，顺序全都不对，是奸商为了卖板子，搞出来的变相营销。这里的关键词首先是“电路开发”，其次才是”Linux”。学这个图的是啥？图的是自己选元件，自己画板子，PCB打样做成电路板，把元件焊在板子上。你需要什么样的板子，就画什么样的板子。你需要什么样的元件，你就焊什么样的元件。板子做好通电测试正常之后，才是网上教程开头教你的那些，烧录Uboot，内核，根文件系统。如果你不会画板子，原理图都看不懂，元器件选型一无所知，板子根本没做出来，你学Linux干啥？你想让它跑在哪？就专门跑在奸商卖给你的那块板子上吗？\n商家提供的根本不是一个“开发平台”，而是一个成品的“玩具”。他们卖的不是教育和探索的可能性，而是一种“即时满足”的体验，无需理解底层，无需面对混乱和错误，只需按照说明书组装，烧录他们提供的镜像，就能立刻获得“成功”的反馈，看到小车跑起来。\n这种体验的设计初衷是降低门槛，但同时也无情地剥夺了学习过程中最宝贵的东西：从无到有的创造，以及从失败到成功的挣扎。我就像在玩一个“嵌入式”的乐高套装，所有的零件都是专用的，所有的步骤都是预设的。我并没有在驱动电机，并没有在读取传感器，我只是在调用一个又一个的黑箱函数，运行一段又一段现成的代码。\n这个小车拓展套件，提供的是答案，而不是问题。它用一块高度集成的拓展板，把所有硬件问题都解决了；它用一个现成的系统镜像，把所有软件环境都配置好了。\n只能说他不适合我，他适合有钱的，希望能省下时间直接品尝成品玩具的玩家。\n","categories":["学习"],"tags":["树莓派"]},{"title":"基于华为云服务器与frp实现内网穿透连接树莓派","url":"/2025/01/16/%E5%9F%BA%E4%BA%8E%E5%8D%8E%E4%B8%BA%E4%BA%91%E4%B8%8Efrp%E5%AE%9E%E7%8E%B0%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E8%BF%9E%E6%8E%A5%E6%A0%91%E8%8E%93%E6%B4%BE/","content":"放寒假了~ 买了好久的树莓派，终于可以开始玩了。\n\n\n首先就是通过raspberry pi imager进行基本的系统下载，在下载系统时设置好wifi并打开ssh连接，然后树莓派开机连接wifi后就能用同一网络下的电脑使用ssh连接树莓派了，进一步的，如果下载的是有图形化界面的系统，就可以用VNC进行远程桌面操控。因为没有显示屏，所以不得不使用这种方法连接树莓派咳咳\n接着，就想到这种方法只能在同一局域网下通过电脑连接树莓派，如果我在其他地方要远程控制树莓派就行不通了。没有公网ip 悲 如果有公网ip就不用这么麻烦了。因此，就需要内网穿透技术，下面我将基于华为云服务器实现内网穿透通过ssh连接树莓派。\n1.准备工作\n一台具有公网IP的服务器：\n用于运行frp服务端（例如华为云服务器）。\n\n在购买华为云服务器时需要购买并绑定相应的弹性公网ip才能有网络连接\n华为云服务器的安全组的对应端口要打开，后面会提到\n\n\n树莓派：\n确保树莓派已连接到网络，并启用SSH。\n\n下载frp：\n访问 frp GitHub Releases 下载适合树莓派和服务器的版本。\n\n树莓派（ARM架构）：frp_0.xx.0_linux_arm.tar.gz（我下载时最新的版本是frp_0.61.1_linux_arm.tar.gz）\n服务器（x86架构）：frp_0.xx.0_linux_amd64.tar.gz（我下载时最新的版本是 frp_0.61.1_linux_amd64.tar.gz）\n\n\n\n2.在服务器上配置frp服务端\n登录服务器：\n 使用SSH连接到你的公网服务器。\n\n下载并解压frp：\nwget https://github.com/fatedier/frp/releases/download/v0.61.1/frp_0.61.1_linux_amd64.tar.gztar -zxvf frp_0.61.1_linux_amd64.tar.gzcd frp_0.61.1_linux_amd64\n注意，wget 在尝试下载 frp 时有几率遇到连接问题，可能是由于网络问题或 GitHub 的访问限制。此时可以在自己的电脑上下载，下载完后通过winSCP将文件传给华为云服务器，或者通过scp命令将文件传给服务器。\nscp frp_0.61.1_linux_amd64.tar.gz root@服务器公网IP:/root/\n\n配置frp服务端：\n编辑 frps.ini 文件：\n nano frps.ini\n\n 添加以下内容：\n  [common]bind_port = 7000\n\n\nbind_port 是frp服务端监听的端口。\n\n注意，此处的7000可以改成其他的端口，只要不冲突就行，也建议进行修改，在后续的安全组配置中要改成对应的端口号。\n\n\n保存并退出：\n\n保存文件：\n按下 Ctrl + O（即按住 Ctrl 键，然后按 O 键）。\n按 Enter 确认保存。\n\n退出 nano：\n   按下 Ctrl + X 退出编辑器。\n\n\n\n启动frp服务端：\n./frps -c frps.ini\n\n服务端会监听 7000 端口，等待客户端连接。\n\n保持服务端运行：\n可以使用 nohup 或 systemd 让frp服务端在后台运行：\nnohup ./frps -c frps.ini &gt; frps.log 2&gt;&amp;1 &amp;\n\n配置华为云安全组：\n\n登录华为云控制台，找到你的服务器实例。\n\n进入“安全组”配置，添加以下规则：\n\n协议：TCP\n端口范围：7000（或者更改为其他的合法端口）\n源地址：0.0.0.0&#x2F;0（或限制为你的电脑IP）\n\n\n保存规则。\n\n\n\n\n7.检查服务端是否运行：\n  ps aux | grep frps\n\n如果没有输出，说明 frp 服务端未运行，需要重新启动：\n ./frps -c frps.ini\n\n 补充：在ssh连接下可以用ctrl+D快速退出ssh连接，也能输入exit退出ssh连接\n3. 在树莓派上配置frp客户端\n登录树莓派：\n使用SSH连接到树莓派。\n\n下载并解压frp：\nwget https://github.com/fatedier/frp/releases/download/v0.61.1/frp_0.61.1_linux_arm.tar.gztar -zxvf frp_0.61.1_linux_arm.tar.gzcd frp_0.61.1_linux_arm\n注意，此处和上面的问题一样，在下载frp时可能会有一些问题，此时可以在自己的电脑上下载，下载完后通过winSCP将文件传给树莓派，或者通过scp命令将文件传给树莓派。\n\n使用 scp 上传文件\nscp 是一个基于 SSH 的文件传输工具，可以将本地文件上传到远程服务器（如树莓派）。\n在本地电脑上执行以下命令：\n\nMac&#x2F;Linux：\n\n打开终端，运行以下命令：\nscp /path/to/frp_0.61.1_linux_arm.tar.gz pi@树莓派IP:/home/pi/\n\n\n将 /path/to/frp_0.61.1_linux_arm.tar.gz 替换为文件的实际路径。\n将 树莓派IP 替换为树莓派的局域网 IP 地址（如 192.168.1.100）。\n默认上传到树莓派的 /home/pi/ 目录。\n\n\n\n\nWindows：\n\n如果你使用的是 PowerShell，可以运行以下命令：\nscp C:\\Users\\username\\Downloads\\frp_0.61.1_linux_arm.tar.gz pi@树莓派IP:/home/pi/\n\n\n将 C:\\Users\\username\\Downloads\\frp_0.61.1_linux_arm.tar.gz 替换为文件的实际路径。\n将 树莓派IP 替换为树莓派的局域网 IP 地址。\n\n\n\n\n输入密码：\n\n系统会提示你输入树莓派的密码（默认密码是 raspberry）。\n输入密码后，文件会上传到树莓派。\n\n\n\n\n\n配置frp客户端：\n编辑 frpc.ini 文件：\nnano frpc.ini\n\n添加以下内容：\n[common]server_addr = 服务器公网IPserver_port = 7000[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 6000\n\n\nserver_addr：填写你的服务器公网IP。\nserver_port：与服务端的 bind_port 一致（默认7000，如果之前有修改，此处也要进行相应的修改）。\n[ssh]：定义一个SSH隧道，将服务器的 6000 端口映射到树莓派的 22 端口。\n\n\n启动frp客户端：\n./frpc -c frpc.ini\n\n客户端会连接到服务器，并将服务器的 6000 端口映射到树莓派的SSH服务。\n\n保持客户端运行：\n 可以使用 nohup 或 systemd 让frp客户端在后台运行：\n nohup ./frpc -c frpc.ini &gt; frpc.log 2&gt;&amp;1 &amp;\n\n检查服务端是否运行：\n ps aux | grep frps\n\n  如果没有输出，说明 frp 客户端未运行，需要重新启动：\n  ./frpc -c frpc.ini\n  补充：在ssh连接下可以用ctrl+D快速退出ssh连接，也能输入exit退出ssh连接\n\n检查端口监听状态：\n 运行以下命令，检查 7000 端口是否被 frp 服务端监听：\n sudo netstat -tuln | grep 7000\n\n  如果看到类似以下输出，说明端口已监听：\n   tcp        0      0 0.0.0.0:7000            0.0.0.0:*               LISTEN\n\n  如果没有输出，说明 frp 服务端未正确监听端口。\n\n检查 frp 客户端日志：\n 查看 frp 客户端的日志文件：\n  cat frpc.log\n\n 如果日志中有错误信息（如连接失败），请根据错误信息进行排查。\n\n\n4. 远程SSH连接树莓派\n通过服务器连接树莓派：\n\n在自己的电脑上使用以下命令通过服务器的公网IP和映射端口连接树莓派：\nssh -p 6000 pi@服务器公网IP\n\n输入树莓派的用户名（默认 pi）和密码即可登录。\n\n\n\n直接连接（如果配置了DDNS）：\n\n如果服务器绑定了域名（如 mypi.ddns.net），可以使用域名连接：\nssh -p 6000 pi@mypi.ddns.net\n\n\n\n至此，应该就可以基于华为云与frp实现内网穿透连接树莓派了，下面给出一些实用性和安全性建议\n5. 设置开机自启动为了确保frp客户端在树莓派重启后自动运行，可以将其设置为系统服务。\n\n创建systemd服务文件：\nsudo nano /etc/systemd/system/frpc.service\n\n添加以下内容：\n[Unit]Description=Frp Client ServiceAfter=network.target[Service]ExecStart=/home/pi/frp_0.61.1_linux_arm/frpc -c /home/pi/frp_0.61.1_linux_arm/frpc.iniRestart=on-failure[Install]WantedBy=multi-user.target\n\n\n修改 ExecStart 路径为你的frp客户端实际路径。\n\n\n启用并启动服务：\nsudo systemctl enable frpcsudo systemctl start frpc\n\n检查服务状态：\nsudo systemctl status frpc\n\n6. 安全性建议\n修改默认SSH端口：\n在树莓派上修改SSH端口（如 2222），并在frp客户端配置中同步修改 local_port。\n\n使用密钥认证：\n禁用密码登录，使用SSH密钥认证。\n\n限制访问IP：\n在服务器防火墙中限制 6000 端口的访问IP。\n\n\n7. 同一局域网下使用VNC连接树莓派桌面重要前提：确保树莓派和你的电脑在同一个局域网内。\n\n打开树莓派配置工具：\n运行以下命令打开 raspi-config：\nsudo raspi-config\n\n选择合适的模式\n如果你的树莓派连接了物理显示器\n你的目标是远程看到和物理屏幕一模一样的内容。你需要使用 Service Mode。\n\n运行 sudo raspi-config。\n选择 Interfacing Options -&gt; VNC -&gt; Yes 启用。这默认启用的是 Service Mode。\n（可选，但推荐）为了获得最佳VNC兼容性，你可以强制系统使用X11：\n在 raspi-config 中，选择 Advanced Options -&gt; A6 Wayland -&gt; 选择 W1 X11。\n确认OK自动重启系统后，VNC正常工作。\n\n\n\n如果你的树莓派没有连接物理显示器（无头模式）\n你的目标是创建一个可以远程访问的虚拟桌面。你需要使用 Virtual Mode。\n\n通过SSH连接到树莓派。\n运行 sudo raspi-config。\n选择 Interfacing Options -&gt; VNC。\n系统会检测到没有显示器，并弹出提示：“Cannot currently show the VNC desktop. Would you like to enable virtual mode instead? ”。\n选择 Yes启用。这启用的是 Virtual Mode。\n\n\n配置 VNC 客户端：\n\n在你电脑上下载并安装 RealVNC Viewer。\n\n打开 VNC 客户端。\n\n在地址栏中输入树莓派的IP地址。\n\n点击连接。\n\n首次连接会有一个安全提示，选择Continue。\n\n输入树莓派的用户名（默认: pi）和密码（默认: raspberry）。\n\n\n\n\n8. 使用VNC远程连接树莓派桌面\n打开树莓派配置工具：\n运行以下命令打开 raspi-config：\nsudo raspi-config\n\n启用 VNC：\n\n在 raspi-config 菜单中，选择 Interfacing Options。\n选择 VNC，然后选择 Yes 启用 VNC。\n\n\n设置分辨率（可选）：\n\n在 raspi-config 菜单中，选择 Display Options。\n选择 Resolution，然后选择一个适合的分辨率（例如 1920x1080）\n\n\n完成配置：\n\n退出 raspi-config 并重启树莓派：\nsudo reboot\n\n\n启动 Virtual Mode 服务：\n\n运行以下命令启动 Virtual Mode 服务：\nsudo /etc/vnc/vncservice start vncserver-virtuald\n\n\n检查 Virtual Mode 状态：\n\n运行以下命令检查 Virtual Mode 服务是否正常运行：\nsudo /etc/vnc/vncservice status vncserver-virtuald\n\n如果服务未运行，尝试重启：\nsudo /etc/vnc/vncservice restart vncserver-virtuald\n\n\n确认 Virtual Mode 端口：\n\nVirtual Mode 默认使用 5901 端口。运行以下命令检查端口是否监听：\nsudo netstat -tuln | grep 5901\n\n如果看到类似以下输出，说明 Virtual Mode 正在监听：\ntcp        0      0 0.0.0.0:5901            0.0.0.0:*               LISTEN\n\n\n如果端口未监听：\n\n可能是 Virtual Mode 服务未正确启动。尝试重启服务：\nsudo /etc/vnc/vncservice restart vncserver-virtuald\n\n\n在本地计算机上创建 SSH 隧道：\n\n运行以下命令，将树莓派的 5901 端口转发到本地的 5901 端口：\nssh -L 5901:localhost:5901 -p 6000 pi@服务器公网ip\n\n\n保持 SSH 隧道连接：\n\n不要关闭这个 SSH 连接，保持它运行以维持隧道。\n\n\n配置 VNC 客户端：\n\n打开 VNC 客户端。\n在地址栏中输入 localhost:5901。\n点击连接。\n\n\n\n\nVirtual Mode 和 Service Mode (RealVNC) 详细对比Virtual Mode 和 Service Mode 是 RealVNC Server 为适应不同使用场景而设计的两种运行模式。它们的核心区别在于是否依赖物理图形显示硬件。\n1. Service Mode（服务模式 &#x2F; X11 模式）特点\n\n适用场景：\n用于远程访问当前正连接在树莓派上的物理显示器（如 HDMI 显示器或屏幕）所显示的桌面。\n适合需要与本地物理屏幕进行完全相同交互的场景，例如调试图形界面应用程序或进行演示。\n必须连接物理显示器才能正常工作，否则屏幕将为黑色或无法连接。\n\n\n运行方式：\n作为一个系统服务 (vncserver-x11-serviced) 在后台运行。\n直接共享当前的 X11 桌面会话。这意味着你看到的内容和物理显示器上的内容是完全一致的。\n\n\n性能：\n性能极佳，因为它可以直接利用树莓派的 GPU 进行硬件加速，处理图形渲染的效率很高。\n延迟低，流畅度高，适合播放视频或运行图形密集型应用。\n\n\n端口：\n不固定使用 5900 端口。RealVNC 使用一种自动发现机制，通常通过 VNC Viewer 直接输入树莓派的主机名（如 raspberrypi.local）进行连接，而非手动指定端口。\n如果必须使用端口，它通常显示为显示端口 0，对应的网络端口是 5900。\n\n\n\n优点\n\n提供与物理显示器完全一致的桌面体验。\n图形性能优秀，延迟低。\n无需创建新的桌面会话，开箱即用。\n\n缺点\n\n严重依赖物理显示器。如果显示器断电或被拔掉，远程连接可能会出现问题。\n\n2. Virtual Mode（虚拟模式）特点\n\n适用场景：\n用于为没有连接物理显示器的树莓派（即无头模式 &#x2F; Headless Mode）创建一个虚拟的桌面环境。\n适合纯粹的远程访问和管理，例如将树莓派作为服务器、家庭自动化主机或后台服务运行。\n\n\n运行方式：\n作为一个独立的系统服务 (vncserver-virtuald) 在后台运行。\n它会创建一个全新的虚拟桌面会话（默认使用 Wayland 或 X11），这个会话与物理显示器完全无关。\n\n\n性能：\n性能相对较差，因为它无法使用 GPU 硬件加速，所有图形渲染均由 CPU 完成，开销较大。\n延迟较高，在运行图形化应用时可能感到卡顿。\n\n\n端口：\n同样通过自动发现机制连接。\n它会创建新的显示端口（例如 :1），对应的网络端口为 5901。如果创建第二个虚拟模式会话，端口会变为 5902，以此类推。\n\n\n\n优点\n\n不需要物理显示器，是无头设置的理想选择。\n可以随时随地远程访问树莓派的独立桌面环境。\n可以创建多个独立的虚拟桌面会话。\n\n缺点\n\n图形性能较弱，不适合处理复杂的图形或视频。\n是一个独立会话，无法看到物理显示器上的内容。\n\n3. 对比总结\n\n\n特性\nService Mode（服务模式）\nVirtual Mode（虚拟模式）\n\n\n\n适用场景\n需要访问物理显示器内容\n无头模式，无需物理显示器\n\n\n运行方式\n共享现有的 X11 桌面会话\n创建新的虚拟桌面会话\n\n\n图形加速\n支持 (GPU 硬件加速)\n不支持 (纯 CPU 渲染)\n\n\n性能\n高，延迟低\n较低，延迟较高\n\n\n默认端口\n:0 (端口 5900)\n:1 (端口 5901)\n\n\n是否需要显示器\n是\n否\n\n\n会话独立性\n与物理显示会话一致\n独立的虚拟会话\n\n\n4. 如何选择？\n选择 Service Mode：\n树莓派连接了显示器，并且你希望远程看到和操作屏幕上正在显示的内容。\n需要运行图形化应用、播放视频或进行任何需要良好图形性能的操作。\n\n\n选择 Virtual Mode：\n树莓派没有连接任何显示器。\n你只需要一个远程桌面来安装软件、修改配置、运行基本程序，对图形性能要求不高。\n\n\n\n5. 如何启用和切换模式？这两种模式是互斥的。通常你只需要并只应启用其中一种。\n\n通过 raspi-config 工具配置（推荐）：\nsudo raspi-config\n\n\n进入 3 Interface Options -&gt; **I3 VNC**。\n选择是否启用 VNC Server。\n这里启用的是 Service Mode，因为它是最常见的用法。\n如果系统未检测到连接的显示器，它会提示你是否启用 Virtual Mode。\n\n\n通过 systemctl 命令手动控制：\n\n**启用 Service Mode (禁用 Virtual Mode)**：\nsudo systemctl enable vncserver-x11-serviced.service # 设置开机自启sudo systemctl start vncserver-x11-serviced.service  # 立即启动sudo systemctl disable vncserver-virtuald.service    # 禁止Virtual模式开机自启sudo systemctl stop vncserver-virtuald.service       # 立即停止Virtual模式\n\n**启用 Virtual Mode (禁用 Service Mode)**：\nsudo systemctl enable vncserver-virtuald.service     # 设置开机自启sudo systemctl start vncserver-virtuald.service      # 立即启动sudo systemctl disable vncserver-x11-serviced.service # 禁止Service模式开机自启sudo systemctl stop vncserver-x11-serviced.service    # 立即停止Service模式\n\n\n\n6. 注意事项\n不要同时运行两种模式：虽然它们的端口不同，但同时运行会占用更多系统资源，且完全没必要。根据你的显示器连接情况选择一种即可。\n无头模式首选 Virtual Mode：如果你的树莓派从不连接显示器，务必启用 Virtual Mode 并禁用 Service Mode。\n连接方式：对于家庭网络用户，最简单的方式是使用 VNC Viewer 并输入树莓派的主机名（例如 raspberrypi.local）。软件会自动发现可用的服务，无需手动指定端口。\n\n\n","categories":["学习"],"tags":["华为","树莓派"]},{"title":"环境变量变化复原方法","url":"/2025/02/12/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%8F%98%E5%8C%96%E5%A4%8D%E5%8E%9F%E6%96%B9%E6%B3%95/","content":"刚刚在使用 SSH 时，我发现系统提示无法找到相应的命令，随即尝试了 Git、Ping 等其他常见命令，结果都显示“找不到该命令”。此时我就意识到可能是系统环境变量出现了问题。经过一段时间的排查后，我发现系统环境变量中的 Path 值异常，它只包含了我一周前下载的某个软件的安装路径。这让我感到非常困扰，因为这意味着系统中其他重要的路径被意外移除。\n\n\n为了解决这一问题，我尝试手动将常见的路径一一添加回去，但由于记不得所有路径，手动恢复变得非常困难。经过一番查找解决方案后，我发现可以通过“系统还原”功能来恢复系统到先前的状态，进而恢复丢失的环境变量。以下是具体的操作步骤：\n系统还原操作步骤：\n\n打开运行窗口： 按 Win + R 打开运行框，在输入框中输入 rstrui，然后按 Enter 键。这将启动“系统还原”工具。\n选择还原点： 在“系统还原”界面中，点击“下一步”，选择一个还原点，通常选择一个接近环境变量丢失之前的日期。建议选择一个最近的还原点，以便恢复系统的稳定性和功能。\n确认还原点： 系统会列出你所选择的还原点，点击“完成”后，系统将开始恢复操作。在此过程中，所有操作系统设置、程序和注册表会被还原至该还原点的状态。注意，系统还原不会影响你的个人文件，但会撤销最近安装的程序和驱动。\n等待还原过程完成： 系统会自动进行重启，并根据所选的还原点恢复相关的配置设置。恢复过程可能需要一些时间，请耐心等待。\n重启并验证环境变量： 完成系统还原后，重启计算机，再次检查 Path 环境变量是否已经恢复到原有状态。此时，你应该可以恢复对 ssh、git、ping 等命令的访问，且环境变量中的 Path 路径应恢复正常。\n\n\n关于系统还原：\n下面简单介绍一下救了我一命的系统还原吧：系统还原是一种 Windows 提供的恢复功能，旨在帮助用户在遇到系统故障或配置错误时，恢复到先前的稳定状态。它通过创建“还原点”来保存系统的关键设置和文件，允许用户在系统出现问题时回到这些还原点。还原点通常会在安装新程序、更新驱动程序或进行系统更新时自动创建。系统还原操作不会影响到用户的个人文件和数据，但会撤销最近的系统更改。\n使用系统还原时的注意事项：\n时间选择：还原点应选择在问题发生前创建的时间。如果没有合适的还原点，则可能无法完全恢复到理想状态。\n程序影响：使用系统还原可能会导致最近安装的应用程序丢失，因此在操作前需要重新安装这些程序。\n文件安全性：系统还原不会影响用户个人数据，因此文件和文档通常不受影响。\n\n\n总结：\n系统还原功能为解决因系统配置错误或误操作引起的问题提供了有效的解决方案。对于环境变量丢失或被错误修改的情况，使用系统还原可以快速恢复到先前的正常状态，避免手动修复的复杂性。然而，在使用此功能时，确保选择合适的还原点，避免丢失不必要的数据。\n\n，\n","categories":["学习"],"tags":["知识总结"]},{"title":"编译时unused报错解决方案","url":"/2025/07/07/%E7%BC%96%E8%AF%91%E6%97%B6unused%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","content":"这两天在做一个C的项目，编译用到了CMake，遇到了挺多的问题。这里简单记录其中的一个小问题及其解决方案。今天发现了同一个文件相同的内容在一台电脑上可以编译通过，在另一台电脑上编译不通过。始终报的是error:xxx defined but not used  或者 error:unused parameter xxx 的错，经过查阅资料以及对CMakeLists的检查，发现是一台电脑上的CMake屏蔽了unused的报错，一台没屏蔽，在没屏蔽该报错的电脑加上如下内容后也可以正常编译了：\n# use this when you want to add ccflags like -include xxxset(COMPONENT_PUBLIC_CCFLAGS &quot;&quot;)# 设置不显示未使用警告set(COMPONENT_CCFLAGS    -Wno-unused-variable      # 禁止未使用变量警告    -Wno-unused-parameter     # 禁止未使用参数警告    -Wno-unused-function      # 禁止未使用函数警告    -Wno-error=unused-function # 确保未使用函数不会导致编译错误)\n\n","categories":["学习"],"tags":["资料"]},{"title":"基于阿里云服务器配置宝塔面板","url":"/2025/08/13/%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8-%E5%AE%9D%E5%A1%94%E9%9D%A2%E6%9D%BF/","content":"现在在阿里云购买服务器并配置宝塔面板十分简单，只需在购买服务器时选择安装应用镜像：宝塔Linux面板\n阿里云专享版 9.2.0，在购买并创建成功后进入该服务器的应用详情页面，跟着宝塔Linux面板使用步骤一步步来即可（基本每一步都是一键完成），就能直接配置完成并进入宝塔管理面板了\n在宝塔管理面板内安装环境也是一键安装，只需要在软件商店中找到对应的应用安装即可\n啊~又水了一期\n","categories":["学习"],"tags":["资料"]},{"title":"美赛苟活大法","url":"/2024/12/26/%E7%BE%8E%E8%B5%9B%E8%8B%9F%E6%B4%BB%E5%A4%A7%E6%B3%95/","content":"十分、万分感谢来自对外经济贸易大学的藏羚羊，本美赛苟活大法是由她编写的，此处仅搬运分享，再次表达感谢！！！\n美赛苟活大法\n下面是藏羚羊的微信公众号，请复制链接后在微信中打开😊 \n\n        \n        聆言'Econ小学二年级已修读完毕😎'","categories":["学习"],"tags":["资料"]},{"title":"IntelliJ全家桶和付费插件破解方法","url":"/2025/05/23/IntelliJ%E5%85%A8%E5%AE%B6%E6%A1%B6%E5%92%8C%E4%BB%98%E8%B4%B9%E6%8F%92%E4%BB%B6%E7%A0%B4%E8%A7%A3%E6%96%B9%E6%B3%95/","content":"使用方法:\n去官网安装对应的软件\n\n下载破解工具\n\n进入 ja-netfilter-all\\scripts 文件夹\n\n自动激活 macOS 或 Linux: \t执行 “scripts&#x2F;install.sh” Windows:\n\n\n\n双击执行 “scripts\\install-current-user.vbs” (当前用户)\n\n双击执行 “scripts\\install-all-users.vbs” (对所有用户)\n\n\n\n如果仍然提示输入激活码，进入 https://3.jetbra.in 复制最新激活码\n\n如果还是不行，则先依次执行”scripts\\uninstall-current-user.vbs”、”scripts\\uninstall-all-users.vbs”再再次依次执行”scripts\\install-current-user.vbs”、”scripts\\install-all-users.vbs”，在done后输入激活码即可，若还不行可以在安装后重启电脑后试试激活码\n\n\n","categories":["学习"],"tags":["资料","破解"]},{"title":"docker介绍","url":"/2025/07/18/docker/","content":"本教程是在 Windows 11 的 WSL2 上安装和配置 Docker ，如果不知道如何配置可以参照以下教程：WSL的安装与使用|Zenith 。\n\n\n安装 Docker Desktop for Windows1、下载 Docker Desktop：\n访问 Docker 官网 下载 Windows 版安装包。\n\n2、安装 Docker Desktop：\n双击安装包，按向导完成安装。\n安装时勾选 “Use WSL 2 instead of Hyper-V”。\n新版 Docker Desktop 会自动化判断你的系统是否启用 WSL 2 并进行对应的安装\n安装完成会自动重启电脑，注意文件保存\n\n3、启动 Docker Desktop：\n安装完成后启动 Docker Desktop。可以先不登录\n在设置（Settings） &gt; General 中确认勾选：（新版 Docker Desktop 默认强制勾选可以不做配置）\nUse the WSL 2 based engine\n\n\n\n4、检查确认 Docker 是否使用了 WSL 2\n在 PowerShell 中运行：\nwsl -l -v\n\n如果看到 docker-desktop ，且版本为 2，则证明 Docker 正在使用 WSL 2。\n\n打开 WSL 2 终端（Ubuntu），运行：\ndocker --version\n\n如果看到输出版本信息，说明 Docker 已成功运行在 WSL 2 中。\n\n\n直接在 ubuntu 中安装 Docker1、更新系统包索引：sudo apt update\n\n2、安装必要的包以允许apt通过HTTPS使用仓库：sudo apt install apt-transport-https ca-certificates curl software-properties-common# 用于设置系统，准备安装来自安全（HTTPS）存储库的软件，并确保下载的软件是经过验证和可信的\n\n3、添加 Docker 的官方 GPG 密钥：curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -# 用于验证从远程仓库下载的文件或软件包在传输过程中没有被篡改，确保包没有被篡改或损坏\n\n4、添加 Docker 的稳定仓库：sudo add-apt-repository &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot;# 在系统中添加 Docker 官方软件仓库，以便后续通过 apt 安装 Docker 及其更新\n\n5、再次更新系统包索引：sudo apt update\n\n6、安装Docker CE（社区版）：sudo apt install docker-ce# Docker Community Edition 简称 Docker CE\n\n7、验证Docker是否安装成功：sudo docker run hello-world\n\n下载镜像在 Docker Desktop 中下载镜像Docker Hub 是一个公共的 Docker 镜像仓库，其中包含了大量的镜像，用户可以从中拉取镜像到本地使用\n\n例如，要拉取一个名为 Nginx 的镜像，可以进行如下操作：\n\n启动 Docker Desktop 进入 Images\n搜索 Nginx pull 第一个镜像文件\n启动 Nginx 镜像\n配置名字（例如：nginxweb）\n配置端口映射（例如：80）\n选择将容器中的文件存储在主机中的位置（可选）（例如：D:\\nginxweb-storage）\n选择挂载到容器中的位置，实现容器与主机的文件共享（可选）（例如：&#x2F;nginxweb）\n运行\n\n\n\n\n在 ubuntu 中下载镜像也可以在ubuntu中使用命令行完成：\n\n例如，要拉取一个名为 opengauss 的镜像，可以进行如下操作：\n使用以下命令拉取镜像\ndocker pull opengauss/opengauss\n\n可以通过 docker images 命令查看当前已下载的镜像\n设置 Docker 镜像源在旧版本下设置 Docker 镜像源由于某些不可描述的问题，Docker 官方镜像经常会拉不下来，常用方式是通过设置镜像源的方式解决（但是大部分源都已经挂了），其他方式可以自行 bing 搜索\n在旧版本下 Docker Desktop 会自动创建两个 WSL2 发行版：\n\ndocker-desktop：运行 Docker Engine（守护进程）。\ndocker-desktop-data：存储镜像和容器数据。\n\n进入 docker-desktop 发行版：\nwsl -d docker-desktop\n\n首先修改 /etc/docker/daemon.json 文件为如下格式\n&#123;    &quot;registry-mirrors&quot;: [        &quot;https://docker.xuanyuan.me&quot;,        &quot;https://docker.mirrors.ustc.edu.cn&quot;,      \t&quot;https://mirror.ccs.tencentyun.com&quot;,        &quot;https://registry.docker-cn.com&quot;    ]&#125;\n\n上述镜像源只是一个示例，可以自行寻找或搭建其他源\n然后重启 Docker：service docker restart\n可以通过 docker info 命令查看配置是否生效\n在新版本下设置 Docker 镜像源在新版本 Docker Desktop 中进行了存储优化，Docker 团队合并了 docker-desktop 和 docker-desktop-data 的功能：**仅保留 docker-desktop**，数据和引擎合并到一个 WSL 2 发行版。\n在新版本中要通过 Docker Desktop 的 GUI 或 API 动态管理配置。\n进入 Settings &gt; Docker Engine。\n直接编辑 JSON 配置：\n&#123;    &quot;builder&quot;: &#123;        &quot;gc&quot;: &#123;            &quot;defaultKeepStorage&quot;: &quot;20GB&quot;,            &quot;enabled&quot;: true        &#125;    &#125;,    &quot;experimental&quot;: false,    &quot;registry-mirrors&quot;: [        &quot;https://docker.xuanyuan.me&quot;,        &quot;https://docker.mirrors.ustc.edu.cn&quot;,        &quot;https://mirror.ccs.tencentyun.com&quot;,        &quot;https://registry.docker-cn.com&quot;    ]&#125;\n\n点击 Apply &amp; Restart，Docker 会自动重启并应用新配置\n在终端运行以下命令，检查镜像源是否已加载：\ndocker info | grep -A 10 &quot;Registry Mirrors&quot;\n\n输出应包含你添加的镜像地址：\nRegistry Mirrors: https://docker.xuanyuan.me/ https://docker.mirrors.ustc.edu.cn/ https://mirror.ccs.tencentyun.com/ https://registry.docker-cn.com/\n\n上述镜像源只是一个示例，可以自行寻找或搭建其他源\n使用容器1、启动容器拉取镜像成功后就可以启动容器了\n或者也可以不拉取镜像直接启动容器，docker会自动下载对应的镜像文件\ndocker run -d \\\t--name opengauss_container \\\t-p 5432:5432 opengauss/opengaussdocker run --name opengauss_container \\\t--privileged=true \\\t-d \\\t-e GS_PASSWORD=your_password \\\t-e GS_USERNAME=your_username \\\t-p 5432:5432 opengauss/opengauss\n\n\n--privileged：赋予容器内的进程几乎相同的权限，容器内的进程可以访问宿主机的所有设备\n--name opengauss_container：给容器指定一个名称，这里是 opengauss_container\n-d：表示在后台运行容器\n-e：传递参数\nGS_PASSWORD=your_password -e GS_USERNAME=your_username：自定义数据库账号密码\n-p 5432:5432：将容器的 5432 端口映射到本机的 5432 端口\n\n如果你仅仅是想创建一个容器，暂时并不想启动他，可以使用 docker create 命令\n与 docker run 命令几乎一致，只是少了 -p 参数。使用 docker create 创建的容器，在用 docker start 启动时，默认总是以后台（detached）方式运行，不管有没有加 -d 参数\n2、查看容器状态docker ps -a 命令可以查看所有容器的状态\ndocker start &lt;容器名&gt;/&lt;容器id&gt; 和 docker stop &lt;容器名&gt;/&lt;容器id&gt; 可以启动 &#x2F; 停止已有容器\n\n使用 docker start 启动的容器是不需要添加参数的，会保留使用 docker run 创建时使用的参数\n\ndocker inspect &lt;容器名&gt;/&lt;容器id&gt;   可以查看容器的所有信息，其中就包括了创建时使用的参数\ndocker logs &lt;容器名&gt;/&lt;容器id&gt; 可以查看容器日志\n\n但是这种方式只能查看现有日志，不能刷新，可以在后面加 -f 参数使其滚动刷新追踪输出：docker logs &lt;容器名&gt;/&lt;容器id&gt; -f\n\n3、使用容器\n上面以 opengauss 数据库为例，所以接下来我们可以使用 gsql 或数据库管理工具来连接数据库。如果是其他项目，通过端口使用即可\n\n每个 Docker 容器都是一个独立的运行环境，每个容器内部表现的都像一个独立的 Linux 系统，可以使用 docker exec &lt;容器名&gt;/&lt;容器id&gt; &lt;想要执行的命令&gt; 在容器内部执行命令\n但是这样会非常的麻烦，可以通过 docker exec -it &lt;容器名&gt;/&lt;容器id&gt; /bin/sh 命令进入容器内部，获得一个交互式的命令行，之后可以用 exec 命令或者使用 Ctrl + D 快捷键退出到宿主机\n额外介绍：DockerfileDockerfile 是一个文件，用于描述镜像是如何制作的，之前用 docker pull 命令拉取的镜像就是用 Dockerfile 制作的\n可以看菜鸟教程 Docker Dockerfile-菜鸟教程\n额外介绍：Docker 网络Docker 容器不光环境和宿主机隔离，网络也和宿主机隔离\nDocker 主要有四种网络模式：Bridge、Host、Container、None。其中桥接模式（Bridge）和直连模式（Host）是最常用的，其余两种可以自行 bing 搜索\n桥接模式桥接模式是 Docker 的默认网路模式。所有容器都在一个子网内，通过网桥与宿主机连接，每个容器都分配了一个内部 ip 地址，容器网络与宿主机网络隔离，通过端口映射访问\n可以通过 docker network create &lt;子网名&gt; 创建新的子网，默认创建的子网也是桥接模式，可以将指定容器加入指定的子网，子网间也是相互隔离的。并且 Docker 子网内部有 DNS 机制，可以将容器名转换为子网 ip 地址\n直连模式直接使用宿主机的 ip 地址，通过宿主机端口可以直接访问容器，无需建立端口映射。可以通过这个命令启动一个直连模式的容器：\ndocker run -d network host mysql-server\n\n使用 docker network list 可以展示出 Docker 所有的网络\n使用 docker network rm &lt;网络id&gt; 可以删除一个子网\n额外介绍：Docker Compose如果我们要用 Docker 部署一个完整的包含前端、后端、中间件、数据库的项目，一种容易想到的方式是分别拉取不同镜像，分别创建容器，但是这样会有三个问题\n\n比较繁琐 复杂\n项目中可能存在容器互相依赖的情况\n容器的网络可能会有特殊要求\n\n可能这时候会想到，我把所有的项目都打包到一起，跑在一个巨大的容器里。这样也会有三个问题\n\n镜像太大\n如果有一个模块挂壁了，整个项目都直接挂壁了\n不方便扩容\n\n这时候就需要 Docker Compose 出场了\nDocker Compose 是一个容器编排技术，使用 yaml 文件管理多个容器，里面描述了容器之间是如何创建以及如何协同工作的，比如在启动后端项目前，需要先启动一个 MySQL 容器：\nversion: &#x27;3.8&#x27;services:  mysql-server:    image: mysql:8.4.5    container_name: mysql-server    restart: unless-stopped    environment:      MYSQL_ROOT_PASSWORD: rootpassword      MYSQL_DATABASE: mydb      MYSQL_USER: myuser      MYSQL_PASSWORD: mypassword    ports:      - &quot;3306:3306&quot;    volumes:      - mysql_data:/var/lib/mysql  backend:    build: ./backend    container_name: backend    depends_on:      - mysql-server    environment:      SPRING_DATASOURCE_URL: jdbc:mysql://mysql-server:3306/mydb      SPRING_DATASOURCE_USERNAME: myuser      SPRING_DATASOURCE_PASSWORD: mypassword    ports:      - &quot;8080:8080&quot;    restart: unless-stoppedvolumes:  mysql_data:\n\n这个 depends_on 字段就可以规定容器的启动顺序\n在写好了 docker-compose.yaml 文件后，就可以用 docker compose up -d 一键启动了，与 docker compose 相关的还有其他命令\n\ndocker compose stop: 停止所有容器\ndocker compose down: 停止并删除所有容器\ndocker compose start: 启动所有容器\n\n注意 docker compose up -d 只能识别名为 docker-compose.yaml 的文件，改个名字就无法识别了。如果要识别其他名字的 yaml 文件可以使用 -f 参数：\ndocker compose -f &lt;文件路径&gt; up -d\n\nDocker Compose 只适合简单项目启动，不适合大型项目启动。对于企业级大规模服务器集群的容器编排需求，通常会使用 Kubernetes\n🌧️\n上述内容参考自：\n高冷博学猫娘 AI\nDocker 常见命令与操作 | 你不定积分没加CのBlog\n使用 Docker 进行项目快速部署 | 你不定积分没加CのBlog\n10分钟掌握Docker Desktop安装及使用\n改变软件行业的技术！程序员、软件爱好者必须掌握的Docker，到底是什么？\n","categories":["学习"],"tags":["介绍"]},{"title":"大幅加速项目编译的方法","url":"/2025/07/10/%E5%A4%A7%E5%B9%85%E5%8A%A0%E9%80%9F%E9%A1%B9%E7%9B%AE%E7%BC%96%E8%AF%91%E7%9A%84%E6%96%B9%E6%B3%95/","content":"前言：之前以为主要是操作系统的问题导致编译速度的差异，使用了 wsl 后编译速度虽然有提高但是还是很慢，因此要继续想办法优化编译速度。在编译的过程中发现除了我修改的主要的代码外，其他的库文件以及一些不知道是什么的文件重复编译导致大量时间的浪费。又因为不知道这些文件有什么用因此不敢轻易将这些文件删除，故采用编译缓存的方式来提高文件的编译速度。\n\n\n以下是使用 ccache 加速 GCC&#x2F;G++ 编译的 详细步骤 和 注意事项，适用于 Ubuntu&#x2F;WSL 等 Linux 环境：\n1. 安装 ccache# 更新软件包列表（确保获取最新版本）sudo apt update# 安装 ccache 工具sudo apt install ccache\n\n2. 配置编译器别名（临时生效）在当前终端会话中，临时设置 ccache 包装 GCC&#x2F;G++：\n# 设置环境变量：让系统在调用 gcc 时实际使用 ccache 包装的 gccexport CC=&quot;ccache gcc&quot;# 设置环境变量：让系统在调用 g++ 时实际使用 ccache 包装的 g++export CXX=&quot;ccache g++&quot;\n\n验证环境变量是否生效：\n# 验证环境变量是否生效echo $CC    # 应输出 &quot;ccache gcc&quot;echo $CXX   # 应输出 &quot;ccache g++&quot;\n\n3. 永久生效配置（推荐）(1) 修改全局环境变量编辑 ~/.bashrc 或 ~/.zshrc（根据你的 Shell）：\n# 编辑 Shell 配置文件（如 ~/.bashrc 或 ~/.zshrc）vim ~/.bashrc\n\n在文件末尾添加：\n# 强制所有 gcc 调用走 ccacheexport CC=&quot;/usr/lib/ccache/gcc&quot; # 强制所有 g++ 调用走 ccacheexport CXX=&quot;/usr/lib/ccache/g++&quot;\n\n保存后加载配置：\n# 保存文件后，加载配置使其立即生效source ~/.bashrc\n\n(2) 或创建符号链接（更彻底）# 创建符号链接，将 gcc/g++ 指向 ccache（需要管理员权限）# 任何地方调用 gcc 都会先走 ccachesudo ln -s /usr/bin/ccache /usr/local/bin/gcc# 任何地方调用 g++ 都会先走 ccachesudo ln -s /usr/bin/ccache /usr/local/bin/g++# 覆盖 cc 编译器别名sudo ln -s /usr/bin/ccache /usr/local/bin/cc# 覆盖 c++ 编译器别名sudo ln -s /usr/bin/ccache /usr/local/bin/c++\n\n优先级检查：\n# 验证优先级which gcc  # 应显示 /usr/local/bin/gcc（表示符号链接生效）\n\n4. 验证 ccache 工作(1) 手动编译测试# 使用 ccache 编译一个测试文件ccache gcc -o test test.c # 直接调用 ccache# 或者（如果配置了环境变量/符号链接）gcc -o test test.c         # 隐式通过 ccache\n\n(2) 查看缓存统计ccache -s # 显示缓存命中率、缓存目录等信息\n\n输出示例：\n# 缓存存储位置cache directory                     /home/user/.ccache# 主配置文件primary config                      /home/user/.ccache/ccache.confsecondary config      (readonly)    /etc/ccache.conf# 直接命中缓存次数cache hit (direct)                  0# 预处理后命中次数cache hit (preprocessed)            0# 未命中次数（需重新编译）cache miss                          1...\n\n\n**cache miss**：首次编译未命中缓存，后续重复编译会显示 cache hit。\n\n5. 在构建系统中使用(1) CMake 项目在 CMakeLists.txt 或配置时指定编译器：\n# 方法1：通过环境变量传递# 在配置阶段指定编译器CC=&quot;ccache gcc&quot; CXX=&quot;ccache g++&quot; cmake ..\n\n或直接启用 ccache 支持：\n# 方法2：在 CMake 命令中直接启用 ccachecmake -DCMAKE_CXX_COMPILER_LAUNCHER=ccache -DCMAKE_C_COMPILER_LAUNCHER=ccake ..\n\n(2) Makefile 项目修改 Makefile 的编译器变量：\n# 修改 Makefile 中的编译器变量# 覆盖默认的 gccCC = ccache gcc# 覆盖默认的 g++CXX = ccache g++\n\n\n6. 高级配置（可选）(1) 调整缓存大小（默认 5GB）# 设置缓存最大为 10GB（默认 5GB）ccache --set-config=max_size=10G  # 设置为 10GB\n\n(2) 清空缓存# 清除所有缓存文件ccache -C\n\n(3) 缓存存储路径默认在 ~/.ccache，可通过环境变量修改：\n设置缓存存储到指定路径（默认在 ~/.ccache）export CCACHE_DIR=/path/to/your/cache\n","categories":["学习"],"tags":["教程","资料"]},{"title":"绝区零","url":"/2025/09/22/%E5%9B%BE%E7%89%87%E5%88%86%E4%BA%AB/","content":"\n本博客用于搬运绝区零壁纸\n","categories":["记录生活"],"tags":["杂谈"]}]